{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31ac2903",
   "metadata": {},
   "source": [
    "# Task 2.4 - Optimizing Hyperparameters - CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b54f03b",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "#### 1. Importing Libraries and Data\n",
    "- Cleaned weather observations from 2.2, pleasant weather (predictions)\n",
    "#### 2. Data Wrangling\n",
    "#### 3. Reshaping for Modeling\n",
    "#### 4. Data Split\n",
    "#### 5. Hyperparameter Optimization\n",
    "-  Bayesian optimization\n",
    "#### 6. Running CNN with Optimized Search Parameters\n",
    "#### 7. Creating Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8cf603",
   "metadata": {},
   "source": [
    "## 1. Importing Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b272bbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-13 11:54:35.935672: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/giadairene/anaconda3/lib/python3.11/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import operator\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from numpy import unique\n",
    "from numpy import reshape\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.layers import Conv1D, Conv2D, Dense, Dropout, BatchNormalization, Flatten, MaxPooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from math import floor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.layers import LeakyReLU\n",
    "LeakyReLU = LeakyReLU(alpha=0.1)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acaf1f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a path\n",
    "\n",
    "path = r'/Users/giadairene/Documents/CareerFoundry Data Analytics/Machine Learning with Python/ClimateWins'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f441852c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cleaned weather observations data\n",
    "\n",
    "X = pd.read_csv(os.path.join(path, '02 Data', 'Prepared', 'X_cleaned_date.csv'), index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04d0e70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import predictions data\n",
    "\n",
    "answers = pd.read_csv(os.path.join(path, '02 Data', 'Original', 'Dataset-Answers-Weather_Prediction_Pleasant_Weather.csv'), index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d49309ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>BASEL_cloud_cover</th>\n",
       "      <th>BASEL_humidity</th>\n",
       "      <th>BASEL_pressure</th>\n",
       "      <th>BASEL_global_radiation</th>\n",
       "      <th>BASEL_precipitation</th>\n",
       "      <th>BASEL_sunshine</th>\n",
       "      <th>BASEL_temp_mean</th>\n",
       "      <th>BASEL_temp_min</th>\n",
       "      <th>BASEL_temp_max</th>\n",
       "      <th>BELGRADE_cloud_cover</th>\n",
       "      <th>BELGRADE_humidity</th>\n",
       "      <th>BELGRADE_pressure</th>\n",
       "      <th>BELGRADE_global_radiation</th>\n",
       "      <th>BELGRADE_precipitation</th>\n",
       "      <th>BELGRADE_sunshine</th>\n",
       "      <th>BELGRADE_temp_mean</th>\n",
       "      <th>BELGRADE_temp_min</th>\n",
       "      <th>BELGRADE_temp_max</th>\n",
       "      <th>BUDAPEST_cloud_cover</th>\n",
       "      <th>BUDAPEST_humidity</th>\n",
       "      <th>BUDAPEST_pressure</th>\n",
       "      <th>BUDAPEST_global_radiation</th>\n",
       "      <th>BUDAPEST_precipitation</th>\n",
       "      <th>BUDAPEST_sunshine</th>\n",
       "      <th>BUDAPEST_temp_mean</th>\n",
       "      <th>BUDAPEST_temp_min</th>\n",
       "      <th>BUDAPEST_temp_max</th>\n",
       "      <th>DEBILT_cloud_cover</th>\n",
       "      <th>DEBILT_humidity</th>\n",
       "      <th>DEBILT_pressure</th>\n",
       "      <th>DEBILT_global_radiation</th>\n",
       "      <th>DEBILT_precipitation</th>\n",
       "      <th>DEBILT_sunshine</th>\n",
       "      <th>DEBILT_temp_mean</th>\n",
       "      <th>DEBILT_temp_min</th>\n",
       "      <th>DEBILT_temp_max</th>\n",
       "      <th>DUSSELDORF_cloud_cover</th>\n",
       "      <th>DUSSELDORF_humidity</th>\n",
       "      <th>DUSSELDORF_pressure</th>\n",
       "      <th>DUSSELDORF_global_radiation</th>\n",
       "      <th>DUSSELDORF_precipitation</th>\n",
       "      <th>DUSSELDORF_sunshine</th>\n",
       "      <th>DUSSELDORF_temp_mean</th>\n",
       "      <th>DUSSELDORF_temp_min</th>\n",
       "      <th>DUSSELDORF_temp_max</th>\n",
       "      <th>HEATHROW_cloud_cover</th>\n",
       "      <th>HEATHROW_humidity</th>\n",
       "      <th>HEATHROW_pressure</th>\n",
       "      <th>HEATHROW_global_radiation</th>\n",
       "      <th>HEATHROW_precipitation</th>\n",
       "      <th>HEATHROW_sunshine</th>\n",
       "      <th>HEATHROW_temp_mean</th>\n",
       "      <th>HEATHROW_temp_min</th>\n",
       "      <th>HEATHROW_temp_max</th>\n",
       "      <th>KASSEL_cloud_cover</th>\n",
       "      <th>KASSEL_humidity</th>\n",
       "      <th>KASSEL_pressure</th>\n",
       "      <th>KASSEL_global_radiation</th>\n",
       "      <th>KASSEL_precipitation</th>\n",
       "      <th>KASSEL_sunshine</th>\n",
       "      <th>KASSEL_temp_mean</th>\n",
       "      <th>KASSEL_temp_min</th>\n",
       "      <th>KASSEL_temp_max</th>\n",
       "      <th>LJUBLJANA_cloud_cover</th>\n",
       "      <th>LJUBLJANA_humidity</th>\n",
       "      <th>LJUBLJANA_pressure</th>\n",
       "      <th>LJUBLJANA_global_radiation</th>\n",
       "      <th>LJUBLJANA_precipitation</th>\n",
       "      <th>LJUBLJANA_sunshine</th>\n",
       "      <th>LJUBLJANA_temp_mean</th>\n",
       "      <th>LJUBLJANA_temp_min</th>\n",
       "      <th>LJUBLJANA_temp_max</th>\n",
       "      <th>MAASTRICHT_cloud_cover</th>\n",
       "      <th>MAASTRICHT_humidity</th>\n",
       "      <th>MAASTRICHT_pressure</th>\n",
       "      <th>MAASTRICHT_global_radiation</th>\n",
       "      <th>MAASTRICHT_precipitation</th>\n",
       "      <th>MAASTRICHT_sunshine</th>\n",
       "      <th>MAASTRICHT_temp_mean</th>\n",
       "      <th>MAASTRICHT_temp_min</th>\n",
       "      <th>MAASTRICHT_temp_max</th>\n",
       "      <th>MADRID_cloud_cover</th>\n",
       "      <th>MADRID_humidity</th>\n",
       "      <th>MADRID_pressure</th>\n",
       "      <th>MADRID_global_radiation</th>\n",
       "      <th>MADRID_precipitation</th>\n",
       "      <th>MADRID_sunshine</th>\n",
       "      <th>MADRID_temp_mean</th>\n",
       "      <th>MADRID_temp_min</th>\n",
       "      <th>MADRID_temp_max</th>\n",
       "      <th>MUNCHENB_cloud_cover</th>\n",
       "      <th>MUNCHENB_humidity</th>\n",
       "      <th>MUNCHENB_pressure</th>\n",
       "      <th>MUNCHENB_global_radiation</th>\n",
       "      <th>MUNCHENB_precipitation</th>\n",
       "      <th>MUNCHENB_sunshine</th>\n",
       "      <th>MUNCHENB_temp_mean</th>\n",
       "      <th>MUNCHENB_temp_min</th>\n",
       "      <th>MUNCHENB_temp_max</th>\n",
       "      <th>OSLO_cloud_cover</th>\n",
       "      <th>OSLO_humidity</th>\n",
       "      <th>OSLO_pressure</th>\n",
       "      <th>OSLO_global_radiation</th>\n",
       "      <th>OSLO_precipitation</th>\n",
       "      <th>OSLO_sunshine</th>\n",
       "      <th>OSLO_temp_mean</th>\n",
       "      <th>OSLO_temp_min</th>\n",
       "      <th>OSLO_temp_max</th>\n",
       "      <th>SONNBLICK_cloud_cover</th>\n",
       "      <th>SONNBLICK_humidity</th>\n",
       "      <th>SONNBLICK_pressure</th>\n",
       "      <th>SONNBLICK_global_radiation</th>\n",
       "      <th>SONNBLICK_precipitation</th>\n",
       "      <th>SONNBLICK_sunshine</th>\n",
       "      <th>SONNBLICK_temp_mean</th>\n",
       "      <th>SONNBLICK_temp_min</th>\n",
       "      <th>SONNBLICK_temp_max</th>\n",
       "      <th>STOCKHOLM_cloud_cover</th>\n",
       "      <th>STOCKHOLM_humidity</th>\n",
       "      <th>STOCKHOLM_pressure</th>\n",
       "      <th>STOCKHOLM_global_radiation</th>\n",
       "      <th>STOCKHOLM_precipitation</th>\n",
       "      <th>STOCKHOLM_sunshine</th>\n",
       "      <th>STOCKHOLM_temp_mean</th>\n",
       "      <th>STOCKHOLM_temp_min</th>\n",
       "      <th>STOCKHOLM_temp_max</th>\n",
       "      <th>VALENTIA_cloud_cover</th>\n",
       "      <th>VALENTIA_humidity</th>\n",
       "      <th>VALENTIA_pressure</th>\n",
       "      <th>VALENTIA_global_radiation</th>\n",
       "      <th>VALENTIA_precipitation</th>\n",
       "      <th>VALENTIA_sunshine</th>\n",
       "      <th>VALENTIA_temp_mean</th>\n",
       "      <th>VALENTIA_temp_min</th>\n",
       "      <th>VALENTIA_temp_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19600101</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.7</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.0195</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>7.9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.017</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>5.1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.0032</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>7.4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.0161</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>9.4</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.0094</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.6</td>\n",
       "      <td>7.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>9.4</td>\n",
       "      <td>8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0173</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.0063</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>8.5</td>\n",
       "      <td>11.1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.0260</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>7.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>10.8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>10.4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.0304</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.3</td>\n",
       "      <td>-5.9</td>\n",
       "      <td>-8.5</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.0114</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.0003</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.34</td>\n",
       "      <td>4.7</td>\n",
       "      <td>8.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19600102</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.0172</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.017</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.0056</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7.7</td>\n",
       "      <td>6.4</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.0161</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.2</td>\n",
       "      <td>7.4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.0051</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>10.6</td>\n",
       "      <td>8</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.0086</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>6.8</td>\n",
       "      <td>9.1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.0173</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.13</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>5.5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.0062</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.4</td>\n",
       "      <td>8.6</td>\n",
       "      <td>7.5</td>\n",
       "      <td>9.9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.0254</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>9.8</td>\n",
       "      <td>7.4</td>\n",
       "      <td>12.2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.30</td>\n",
       "      <td>5.1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>10.2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.0139</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>6</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.0292</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.5</td>\n",
       "      <td>-10.5</td>\n",
       "      <td>-8.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.0114</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.0007</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.7</td>\n",
       "      <td>8.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>12.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19600103</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.0179</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>6.4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.017</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>5.3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.0165</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>9.9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.0161</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>6.9</td>\n",
       "      <td>9.1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.0166</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8.4</td>\n",
       "      <td>6.1</td>\n",
       "      <td>12.2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.0129</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.0173</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>6.3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.0167</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>9.9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.0287</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>8.6</td>\n",
       "      <td>6.4</td>\n",
       "      <td>10.8</td>\n",
       "      <td>6</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1.0234</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.0320</td>\n",
       "      <td>0.21</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.5</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-8.9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1.0114</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.0096</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.5</td>\n",
       "      <td>8.1</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19600104</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>10.6</td>\n",
       "      <td>8</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.0268</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.017</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.0265</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.6</td>\n",
       "      <td>10.1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.0161</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.0230</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6.7</td>\n",
       "      <td>8.9</td>\n",
       "      <td>8</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.0290</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.0173</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.0277</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0281</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>10.3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>16.1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.0244</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.0443</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-11.5</td>\n",
       "      <td>-12.9</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.0114</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.0184</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.3</td>\n",
       "      <td>10.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19600105</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.14</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.0286</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.017</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.0243</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>11.2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.0161</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>6.2</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.0275</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.1</td>\n",
       "      <td>8.9</td>\n",
       "      <td>8.9</td>\n",
       "      <td>7.2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.0262</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.0173</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.0259</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.0269</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>12.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.96</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.0092</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0430</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.01</td>\n",
       "      <td>6.1</td>\n",
       "      <td>-9.3</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.0114</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.0328</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.7</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DATE  MONTH  BASEL_cloud_cover  BASEL_humidity  BASEL_pressure  \\\n",
       "0  19600101      1                  7            0.85           1.018   \n",
       "1  19600102      1                  6            0.84           1.018   \n",
       "2  19600103      1                  8            0.90           1.018   \n",
       "3  19600104      1                  3            0.92           1.018   \n",
       "4  19600105      1                  6            0.95           1.018   \n",
       "\n",
       "   BASEL_global_radiation  BASEL_precipitation  BASEL_sunshine  \\\n",
       "0                    0.32                 0.09             0.7   \n",
       "1                    0.36                 1.05             1.1   \n",
       "2                    0.18                 0.30             0.0   \n",
       "3                    0.58                 0.00             4.1   \n",
       "4                    0.65                 0.14             5.4   \n",
       "\n",
       "   BASEL_temp_mean  BASEL_temp_min  BASEL_temp_max  BELGRADE_cloud_cover  \\\n",
       "0              6.5             0.8            10.9                     1   \n",
       "1              6.1             3.3            10.1                     6   \n",
       "2              8.5             5.1             9.9                     6   \n",
       "3              6.3             3.8            10.6                     8   \n",
       "4              3.0            -0.7             6.0                     8   \n",
       "\n",
       "   BELGRADE_humidity  BELGRADE_pressure  BELGRADE_global_radiation  \\\n",
       "0               0.81             1.0195                       0.88   \n",
       "1               0.84             1.0172                       0.25   \n",
       "2               0.77             1.0179                       0.67   \n",
       "3               0.93             1.0268                       0.25   \n",
       "4               0.99             1.0286                       0.25   \n",
       "\n",
       "   BELGRADE_precipitation  BELGRADE_sunshine  BELGRADE_temp_mean  \\\n",
       "0                    0.00                7.0                 3.7   \n",
       "1                    0.00                0.0                 2.9   \n",
       "2                    0.00                3.5                 3.1   \n",
       "3                    0.00                0.0                 2.0   \n",
       "4                    0.06                0.0                 2.0   \n",
       "\n",
       "   BELGRADE_temp_min  BELGRADE_temp_max  BUDAPEST_cloud_cover  \\\n",
       "0               -0.9                7.9                     4   \n",
       "1                2.2                4.4                     4   \n",
       "2               -0.5                6.4                     4   \n",
       "3               -2.0                3.0                     4   \n",
       "4                0.7                2.8                     4   \n",
       "\n",
       "   BUDAPEST_humidity  BUDAPEST_pressure  BUDAPEST_global_radiation  \\\n",
       "0               0.67              1.017                       0.44   \n",
       "1               0.67              1.017                       0.18   \n",
       "2               0.67              1.017                       0.30   \n",
       "3               0.67              1.017                       0.19   \n",
       "4               0.67              1.017                       0.19   \n",
       "\n",
       "   BUDAPEST_precipitation  BUDAPEST_sunshine  BUDAPEST_temp_mean  \\\n",
       "0                    0.01                2.3                 2.4   \n",
       "1                    0.31                0.0                 2.3   \n",
       "2                    0.00                0.6                 2.7   \n",
       "3                    0.00                0.0                 2.0   \n",
       "4                    0.00                0.0                 2.5   \n",
       "\n",
       "   BUDAPEST_temp_min  BUDAPEST_temp_max  DEBILT_cloud_cover  DEBILT_humidity  \\\n",
       "0               -0.4                5.1                   7             0.85   \n",
       "1                1.4                3.1                   8             0.90   \n",
       "2                1.7                5.3                   6             0.92   \n",
       "3                0.4                4.4                   8             0.95   \n",
       "4                1.1                5.3                   6             0.90   \n",
       "\n",
       "   DEBILT_pressure  DEBILT_global_radiation  DEBILT_precipitation  \\\n",
       "0           1.0032                     0.07                  0.25   \n",
       "1           1.0056                     0.14                  0.06   \n",
       "2           1.0165                     0.28                  0.01   \n",
       "3           1.0265                     0.08                  0.09   \n",
       "4           1.0243                     0.04                  0.39   \n",
       "\n",
       "   DEBILT_sunshine  DEBILT_temp_mean  DEBILT_temp_min  DEBILT_temp_max  \\\n",
       "0              0.0               9.3              7.4             11.0   \n",
       "1              0.1               7.7              6.4              8.3   \n",
       "2              3.0               6.8              4.6              9.9   \n",
       "3              0.0               6.7              3.6             10.1   \n",
       "4              0.0               8.0              2.4             11.2   \n",
       "\n",
       "   DUSSELDORF_cloud_cover  DUSSELDORF_humidity  DUSSELDORF_pressure  \\\n",
       "0                       8                 0.83               1.0161   \n",
       "1                       8                 0.89               1.0161   \n",
       "2                       7                 0.95               1.0161   \n",
       "3                       8                 0.86               1.0161   \n",
       "4                       7                 0.92               1.0161   \n",
       "\n",
       "   DUSSELDORF_global_radiation  DUSSELDORF_precipitation  DUSSELDORF_sunshine  \\\n",
       "0                         0.12                      0.08                  0.0   \n",
       "1                         0.18                      0.66                  0.5   \n",
       "2                         0.12                      0.07                  0.0   \n",
       "3                         0.12                      0.02                  0.0   \n",
       "4                         0.12                      0.62                  0.0   \n",
       "\n",
       "   DUSSELDORF_temp_mean  DUSSELDORF_temp_min  DUSSELDORF_temp_max  \\\n",
       "0                  10.0                  7.0                 11.5   \n",
       "1                   8.2                  7.4                 11.0   \n",
       "2                   7.1                  6.9                  9.1   \n",
       "3                   6.8                  3.6                  8.0   \n",
       "4                   7.7                  6.2                 11.0   \n",
       "\n",
       "   HEATHROW_cloud_cover  HEATHROW_humidity  HEATHROW_pressure  \\\n",
       "0                     7               0.91             1.0010   \n",
       "1                     7               0.98             1.0051   \n",
       "2                     8               0.96             1.0166   \n",
       "3                     8               0.98             1.0230   \n",
       "4                     5               0.84             1.0275   \n",
       "\n",
       "   HEATHROW_global_radiation  HEATHROW_precipitation  HEATHROW_sunshine  \\\n",
       "0                       0.13                    0.22                0.0   \n",
       "1                       0.13                    0.23                0.0   \n",
       "2                       0.15                    0.07                0.1   \n",
       "3                       0.13                    0.00                0.0   \n",
       "4                       0.30                    0.00                2.1   \n",
       "\n",
       "   HEATHROW_temp_mean  HEATHROW_temp_min  HEATHROW_temp_max  \\\n",
       "0                10.6                9.4                8.3   \n",
       "1                 6.1                3.9               10.6   \n",
       "2                 8.4                6.1               12.2   \n",
       "3                 9.4                6.7                8.9   \n",
       "4                 8.9                8.9                7.2   \n",
       "\n",
       "   KASSEL_cloud_cover  KASSEL_humidity  KASSEL_pressure  \\\n",
       "0                   8             0.82           1.0094   \n",
       "1                   8             0.86           1.0086   \n",
       "2                   7             0.91           1.0129   \n",
       "3                   8             0.87           1.0290   \n",
       "4                   7             0.86           1.0262   \n",
       "\n",
       "   KASSEL_global_radiation  KASSEL_precipitation  KASSEL_sunshine  \\\n",
       "0                     0.28                  0.48              1.6   \n",
       "1                     0.12                  0.27              0.0   \n",
       "2                     0.12                  0.60              0.0   \n",
       "3                     0.12                  0.00              0.0   \n",
       "4                     0.13                  0.71              0.0   \n",
       "\n",
       "   KASSEL_temp_mean  KASSEL_temp_min  KASSEL_temp_max  LJUBLJANA_cloud_cover  \\\n",
       "0               7.9              3.9              9.4                      8   \n",
       "1               7.7              6.8              9.1                      6   \n",
       "2               6.5              6.0              8.0                      8   \n",
       "3               5.8              5.2              6.5                      6   \n",
       "4               5.4              3.7              6.0                      7   \n",
       "\n",
       "   LJUBLJANA_humidity  LJUBLJANA_pressure  LJUBLJANA_global_radiation  \\\n",
       "0                1.00              1.0173                        0.20   \n",
       "1                0.94              1.0173                        0.56   \n",
       "2                0.96              1.0173                        0.20   \n",
       "3                0.94              1.0173                        0.49   \n",
       "4                0.94              1.0173                        0.20   \n",
       "\n",
       "   LJUBLJANA_precipitation  LJUBLJANA_sunshine  LJUBLJANA_temp_mean  \\\n",
       "0                     0.00                 0.0                 -0.6   \n",
       "1                     0.13                 3.2                  2.1   \n",
       "2                     0.12                 0.0                  4.6   \n",
       "3                     0.00                 2.2                  3.2   \n",
       "4                     0.00                 0.0                  3.6   \n",
       "\n",
       "   LJUBLJANA_temp_min  LJUBLJANA_temp_max  MAASTRICHT_cloud_cover  \\\n",
       "0                -1.9                 0.5                       7   \n",
       "1                -1.3                 5.5                       8   \n",
       "2                 0.9                 6.3                       7   \n",
       "3                 1.0                 7.0                       7   \n",
       "4                 0.4                 4.8                       7   \n",
       "\n",
       "   MAASTRICHT_humidity  MAASTRICHT_pressure  MAASTRICHT_global_radiation  \\\n",
       "0                 0.83               1.0063                         0.22   \n",
       "1                 0.92               1.0062                         0.17   \n",
       "2                 0.97               1.0167                         0.12   \n",
       "3                 0.89               1.0277                         0.16   \n",
       "4                 0.92               1.0259                         0.12   \n",
       "\n",
       "   MAASTRICHT_precipitation  MAASTRICHT_sunshine  MAASTRICHT_temp_mean  \\\n",
       "0                      0.32                  1.0                   9.5   \n",
       "1                      1.34                  0.4                   8.6   \n",
       "2                      0.46                  0.0                   6.9   \n",
       "3                      0.00                  0.3                   7.0   \n",
       "4                      0.56                  0.0                   8.1   \n",
       "\n",
       "   MAASTRICHT_temp_min  MAASTRICHT_temp_max  MADRID_cloud_cover  \\\n",
       "0                  8.5                 11.1                   6   \n",
       "1                  7.5                  9.9                   7   \n",
       "2                  5.5                  9.9                   5   \n",
       "3                  3.0                 10.0                   0   \n",
       "4                  2.5                 11.1                   2   \n",
       "\n",
       "   MADRID_humidity  MADRID_pressure  MADRID_global_radiation  \\\n",
       "0             0.92           1.0260                     0.53   \n",
       "1             0.86           1.0254                     0.46   \n",
       "2             0.90           1.0287                     0.63   \n",
       "3             0.75           1.0281                     1.16   \n",
       "4             0.64           1.0269                     1.10   \n",
       "\n",
       "   MADRID_precipitation  MADRID_sunshine  MADRID_temp_mean  MADRID_temp_min  \\\n",
       "0                   0.0              1.4               7.6              4.4   \n",
       "1                   0.0              0.9               9.8              7.4   \n",
       "2                   0.0              2.3               8.6              6.4   \n",
       "3                   0.0              8.7              10.3              4.5   \n",
       "4                   0.0              7.8              12.1              8.2   \n",
       "\n",
       "   MADRID_temp_max  MUNCHENB_cloud_cover  MUNCHENB_humidity  \\\n",
       "0             10.8                     5               0.67   \n",
       "1             12.2                     6               0.72   \n",
       "2             10.8                     6               0.91   \n",
       "3             16.1                     6               0.90   \n",
       "4             16.0                     5               0.85   \n",
       "\n",
       "   MUNCHENB_pressure  MUNCHENB_global_radiation  MUNCHENB_precipitation  \\\n",
       "0              1.018                       0.20                    0.10   \n",
       "1              1.018                       0.61                    0.30   \n",
       "2              1.018                       0.20                    0.30   \n",
       "3              1.018                       0.20                    0.01   \n",
       "4              1.018                       0.65                    0.96   \n",
       "\n",
       "   MUNCHENB_sunshine  MUNCHENB_temp_mean  MUNCHENB_temp_min  \\\n",
       "0                0.0                 6.9                1.1   \n",
       "1                5.1                 6.2                4.2   \n",
       "2                0.0                 5.8                4.0   \n",
       "3                0.0                 3.9                3.2   \n",
       "4                5.6                 1.8               -3.0   \n",
       "\n",
       "   MUNCHENB_temp_max  OSLO_cloud_cover  OSLO_humidity  OSLO_pressure  \\\n",
       "0               10.4                 8           0.98         0.9978   \n",
       "1               10.2                 8           0.62         1.0139   \n",
       "2                8.0                 8           0.69         1.0234   \n",
       "3                5.4                 8           0.98         1.0244   \n",
       "4                6.0                 8           0.96         1.0092   \n",
       "\n",
       "   OSLO_global_radiation  OSLO_precipitation  OSLO_sunshine  OSLO_temp_mean  \\\n",
       "0                   0.04                1.14            0.0             4.9   \n",
       "1                   0.04                0.00            0.0             3.4   \n",
       "2                   0.04                0.08            0.0             1.9   \n",
       "3                   0.04                0.35            0.0             3.0   \n",
       "4                   0.05                0.26            0.0             3.7   \n",
       "\n",
       "   OSLO_temp_min  OSLO_temp_max  SONNBLICK_cloud_cover  SONNBLICK_humidity  \\\n",
       "0            3.8            5.9                      4                0.73   \n",
       "1            2.8            4.9                      6                0.97   \n",
       "2            0.6            3.1                      8                0.93   \n",
       "3            0.4            4.9                      5                0.93   \n",
       "4            2.9            4.9                      2                0.75   \n",
       "\n",
       "   SONNBLICK_pressure  SONNBLICK_global_radiation  SONNBLICK_precipitation  \\\n",
       "0              1.0304                        0.48                     0.01   \n",
       "1              1.0292                        0.21                     0.61   \n",
       "2              1.0320                        0.21                     3.20   \n",
       "3              1.0443                        0.22                     1.10   \n",
       "4              1.0430                        0.72                     0.01   \n",
       "\n",
       "   SONNBLICK_sunshine  SONNBLICK_temp_mean  SONNBLICK_temp_min  \\\n",
       "0                 2.3                 -5.9                -8.5   \n",
       "1                 0.0                 -9.5               -10.5   \n",
       "2                 0.0                 -9.5               -10.0   \n",
       "3                 0.0                -11.5               -12.9   \n",
       "4                 6.1                 -9.3               -12.0   \n",
       "\n",
       "   SONNBLICK_temp_max  STOCKHOLM_cloud_cover  STOCKHOLM_humidity  \\\n",
       "0                -3.2                      5                0.98   \n",
       "1                -8.5                      5                0.62   \n",
       "2                -8.9                      5                0.69   \n",
       "3               -10.0                      5                0.98   \n",
       "4                -6.5                      5                0.96   \n",
       "\n",
       "   STOCKHOLM_pressure  STOCKHOLM_global_radiation  STOCKHOLM_precipitation  \\\n",
       "0              1.0114                        0.05                     0.32   \n",
       "1              1.0114                        0.05                     0.06   \n",
       "2              1.0114                        0.05                     0.02   \n",
       "3              1.0114                        0.05                     0.00   \n",
       "4              1.0114                        0.05                     1.32   \n",
       "\n",
       "   STOCKHOLM_sunshine  STOCKHOLM_temp_mean  STOCKHOLM_temp_min  \\\n",
       "0                 0.0                  4.2                 2.2   \n",
       "1                 0.0                  4.0                 3.0   \n",
       "2                 0.0                  2.4                 1.3   \n",
       "3                 0.0                  1.2                 0.4   \n",
       "4                 0.0                  3.3                 0.8   \n",
       "\n",
       "   STOCKHOLM_temp_max  VALENTIA_cloud_cover  VALENTIA_humidity  \\\n",
       "0                 4.9                     5               0.88   \n",
       "1                 5.0                     7               0.91   \n",
       "2                 4.1                     7               0.91   \n",
       "3                 2.3                     7               0.86   \n",
       "4                 4.3                     3               0.80   \n",
       "\n",
       "   VALENTIA_pressure  VALENTIA_global_radiation  VALENTIA_precipitation  \\\n",
       "0             1.0003                       0.45                    0.34   \n",
       "1             1.0007                       0.25                    0.84   \n",
       "2             1.0096                       0.17                    0.08   \n",
       "3             1.0184                       0.13                    0.98   \n",
       "4             1.0328                       0.46                    0.00   \n",
       "\n",
       "   VALENTIA_sunshine  VALENTIA_temp_mean  VALENTIA_temp_min  VALENTIA_temp_max  \n",
       "0                4.7                 8.5                6.0               10.9  \n",
       "1                0.7                 8.9                5.6               12.1  \n",
       "2                0.1                10.5                8.1               12.9  \n",
       "3                0.0                 7.4                7.3               10.6  \n",
       "4                5.7                 5.7                3.0                8.4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac103755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22950, 137)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2a5225d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>BASEL_pleasant_weather</th>\n",
       "      <th>BELGRADE_pleasant_weather</th>\n",
       "      <th>BUDAPEST_pleasant_weather</th>\n",
       "      <th>DEBILT_pleasant_weather</th>\n",
       "      <th>DUSSELDORF_pleasant_weather</th>\n",
       "      <th>HEATHROW_pleasant_weather</th>\n",
       "      <th>KASSEL_pleasant_weather</th>\n",
       "      <th>LJUBLJANA_pleasant_weather</th>\n",
       "      <th>MAASTRICHT_pleasant_weather</th>\n",
       "      <th>MADRID_pleasant_weather</th>\n",
       "      <th>MUNCHENB_pleasant_weather</th>\n",
       "      <th>OSLO_pleasant_weather</th>\n",
       "      <th>SONNBLICK_pleasant_weather</th>\n",
       "      <th>STOCKHOLM_pleasant_weather</th>\n",
       "      <th>VALENTIA_pleasant_weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19600101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19600102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19600103</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19600104</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19600105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DATE  BASEL_pleasant_weather  BELGRADE_pleasant_weather  \\\n",
       "0  19600101                       0                          0   \n",
       "1  19600102                       0                          0   \n",
       "2  19600103                       0                          0   \n",
       "3  19600104                       0                          0   \n",
       "4  19600105                       0                          0   \n",
       "\n",
       "   BUDAPEST_pleasant_weather  DEBILT_pleasant_weather  \\\n",
       "0                          0                        0   \n",
       "1                          0                        0   \n",
       "2                          0                        0   \n",
       "3                          0                        0   \n",
       "4                          0                        0   \n",
       "\n",
       "   DUSSELDORF_pleasant_weather  HEATHROW_pleasant_weather  \\\n",
       "0                            0                          0   \n",
       "1                            0                          0   \n",
       "2                            0                          0   \n",
       "3                            0                          0   \n",
       "4                            0                          0   \n",
       "\n",
       "   KASSEL_pleasant_weather  LJUBLJANA_pleasant_weather  \\\n",
       "0                        0                           0   \n",
       "1                        0                           0   \n",
       "2                        0                           0   \n",
       "3                        0                           0   \n",
       "4                        0                           0   \n",
       "\n",
       "   MAASTRICHT_pleasant_weather  MADRID_pleasant_weather  \\\n",
       "0                            0                        0   \n",
       "1                            0                        0   \n",
       "2                            0                        0   \n",
       "3                            0                        0   \n",
       "4                            0                        0   \n",
       "\n",
       "   MUNCHENB_pleasant_weather  OSLO_pleasant_weather  \\\n",
       "0                          0                      0   \n",
       "1                          0                      0   \n",
       "2                          0                      0   \n",
       "3                          0                      0   \n",
       "4                          0                      0   \n",
       "\n",
       "   SONNBLICK_pleasant_weather  STOCKHOLM_pleasant_weather  \\\n",
       "0                           0                           0   \n",
       "1                           0                           0   \n",
       "2                           0                           0   \n",
       "3                           0                           0   \n",
       "4                           0                           0   \n",
       "\n",
       "   VALENTIA_pleasant_weather  \n",
       "0                          0  \n",
       "1                          0  \n",
       "2                          0  \n",
       "3                          0  \n",
       "4                          0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6f5eba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22950, 16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaec0cf",
   "metadata": {},
   "source": [
    "## 2. Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6a340fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "\n",
    "X.drop(['DATE', 'MONTH'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d658986c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22950, 135)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape # observations dataset has the correct shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b21097a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers.drop(columns = 'DATE', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fb612fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22950, 15)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers.shape # predictions dataset has the correct shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa00807b",
   "metadata": {},
   "source": [
    "## 3. Reshaping for Modeling\n",
    "- Your X shape will need to be in the form (22950, 15, 9)\n",
    "- Your y shape will need to be in the form (22950,)\n",
    "- You can use the argmax function to transform your y set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98ffe3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn X and answers from a df to arrays\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fbc1bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(-1,15,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a0e3944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22950, 15, 9)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify shape\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5cd12373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use argmax to transform y\n",
    "\n",
    "y =  np.argmax(y, axis = 1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3842442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22950,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "240fc6f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'multiclass'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check y layout\n",
    "\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "type_of_target(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa97ec78",
   "metadata": {},
   "source": [
    "#### The Bayesian optimization function only accepts y data in multiclass and binary layouts but not in multilabel-indicator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3190e56f",
   "metadata": {},
   "source": [
    "## 4. Data Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4464d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "511dee2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17212, 15, 9) (17212,)\n",
      "(5738, 15, 9) (5738,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e64ef01",
   "metadata": {},
   "source": [
    "## 5. Bayesian Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "234c9996",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = 15 # Number of weather stations\n",
    "# Make scorer accuracy\n",
    "score_acc = make_scorer(accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f4c7b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function\n",
    "\n",
    "def bay_area(neurons, activation, kernel, optimizer, learning_rate, batch_size, epochs,\n",
    "              layers1, layers2, normalization, dropout, dropout_rate): \n",
    "    optimizerL = ['SGD', 'Adam', 'RMSprop', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl','SGD']\n",
    "    #optimizerD= {'Adam':Adam(lr=learning_rate), 'SGD':SGD(lr=learning_rate),\n",
    "                 #'RMSprop':RMSprop(lr=learning_rate), 'Adadelta':Adadelta(lr=learning_rate),\n",
    "                 #'Adagrad':Adagrad(lr=learning_rate), 'Adamax':Adamax(lr=learning_rate),\n",
    "                 #'Nadam':Nadam(lr=learning_rate), 'Ftrl':Ftrl(lr=learning_rate)}\n",
    "    activationL = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu',\n",
    "                   'elu', 'exponential', LeakyReLU,'relu']\n",
    "    \n",
    "    neurons = round(neurons)\n",
    "    kernel = round(kernel)\n",
    "    activation = activationL[round(activation)]  #optimizerD[optimizerL[round(optimizer)]]\n",
    "    optimizer = optimizerL[round(optimizer)]\n",
    "    batch_size = round(batch_size)\n",
    "    \n",
    "    epochs = round(epochs)\n",
    "    layers1 = round(layers1)\n",
    "    layers2 = round(layers2)\n",
    "    \n",
    "    def cnn_model():\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(neurons, kernel_size=kernel,activation=activation, input_shape=(timesteps, input_dim)))\n",
    "        #model.add(Conv1D(32, kernel_size=1,activation='relu', input_shape=(timesteps, input_dim)))\n",
    "        \n",
    "        if normalization > 0.5:\n",
    "            model.add(BatchNormalization())\n",
    "        for i in range(layers1):\n",
    "            model.add(Dense(neurons, activation=activation)) #(neurons, activation=activation))\n",
    "        if dropout > 0.5:\n",
    "            model.add(Dropout(dropout_rate, seed=123))\n",
    "        for i in range(layers2):\n",
    "            model.add(Dense(neurons, activation=activation))\n",
    "        model.add(MaxPooling1D())\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(n_classes, activation='softmax')) #sigmoid softmax\n",
    "        #model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy']) #categorical_crossentropy\n",
    "        model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy']) #categorical_crossentropy\n",
    "        return model\n",
    "    es = EarlyStopping(monitor='accuracy', mode='max', verbose=2, patience=20)\n",
    "    nn = KerasClassifier(build_fn=cnn_model, epochs=epochs, batch_size=batch_size, verbose=2)\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "    score = cross_val_score(nn, X_train, y_train, scoring=score_acc, cv=kfold, fit_params={'callbacks':[es]}).mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3eb249e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | activa... | batch_... |  dropout  | dropou... |  epochs   |  kernel   |  layers1  |  layers2  | learni... |  neurons  | normal... | optimizer |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch 1/25\n",
      "15/15 - 4s - 276ms/step - accuracy: 0.6005 - loss: 2.7005\n",
      "Epoch 2/25\n",
      "15/15 - 2s - 115ms/step - accuracy: 0.6440 - loss: 2.7004\n",
      "Epoch 3/25\n",
      "15/15 - 2s - 109ms/step - accuracy: 0.6440 - loss: 2.6970\n",
      "Epoch 4/25\n",
      "15/15 - 2s - 106ms/step - accuracy: 0.6440 - loss: 2.6941\n",
      "Epoch 5/25\n",
      "15/15 - 2s - 102ms/step - accuracy: 0.6440 - loss: 2.6916\n",
      "Epoch 6/25\n",
      "15/15 - 1s - 98ms/step - accuracy: 0.6440 - loss: 2.6893\n",
      "Epoch 7/25\n",
      "15/15 - 1s - 99ms/step - accuracy: 0.6440 - loss: 2.6872\n",
      "Epoch 8/25\n",
      "15/15 - 1s - 97ms/step - accuracy: 0.6440 - loss: 2.6852\n",
      "Epoch 9/25\n",
      "15/15 - 3s - 193ms/step - accuracy: 0.6440 - loss: 2.6833\n",
      "Epoch 10/25\n",
      "15/15 - 2s - 121ms/step - accuracy: 0.6440 - loss: 2.6814\n",
      "Epoch 11/25\n",
      "15/15 - 2s - 111ms/step - accuracy: 0.6440 - loss: 2.6797\n",
      "Epoch 12/25\n",
      "15/15 - 2s - 126ms/step - accuracy: 0.6440 - loss: 2.6780\n",
      "Epoch 13/25\n",
      "15/15 - 2s - 108ms/step - accuracy: 0.6440 - loss: 2.6764\n",
      "Epoch 14/25\n",
      "15/15 - 2s - 163ms/step - accuracy: 0.6440 - loss: 2.6748\n",
      "Epoch 15/25\n",
      "15/15 - 2s - 125ms/step - accuracy: 0.6440 - loss: 2.6732\n",
      "Epoch 16/25\n",
      "15/15 - 2s - 147ms/step - accuracy: 0.6440 - loss: 2.6717\n",
      "Epoch 17/25\n",
      "15/15 - 3s - 181ms/step - accuracy: 0.6440 - loss: 2.6702\n",
      "Epoch 18/25\n",
      "15/15 - 2s - 108ms/step - accuracy: 0.6440 - loss: 2.6686\n",
      "Epoch 19/25\n",
      "15/15 - 3s - 175ms/step - accuracy: 0.6440 - loss: 2.6671\n",
      "Epoch 20/25\n",
      "15/15 - 3s - 171ms/step - accuracy: 0.6440 - loss: 2.6656\n",
      "Epoch 21/25\n",
      "15/15 - 2s - 111ms/step - accuracy: 0.6440 - loss: 2.6641\n",
      "Epoch 22/25\n",
      "15/15 - 1s - 99ms/step - accuracy: 0.6440 - loss: 2.6625\n",
      "Epoch 23/25\n",
      "15/15 - 3s - 168ms/step - accuracy: 0.6440 - loss: 2.6610\n",
      "Epoch 24/25\n",
      "15/15 - 2s - 102ms/step - accuracy: 0.6440 - loss: 2.6594\n",
      "Epoch 25/25\n",
      "15/15 - 2s - 102ms/step - accuracy: 0.6440 - loss: 2.6577\n",
      "4/4 - 0s - 65ms/step\n",
      "Epoch 1/25\n",
      "15/15 - 4s - 241ms/step - accuracy: 0.6008 - loss: 2.7076\n",
      "Epoch 2/25\n",
      "15/15 - 2s - 103ms/step - accuracy: 0.6440 - loss: 2.7004\n",
      "Epoch 3/25\n",
      "15/15 - 1s - 99ms/step - accuracy: 0.6440 - loss: 2.6970\n",
      "Epoch 4/25\n",
      "15/15 - 3s - 172ms/step - accuracy: 0.6440 - loss: 2.6942\n",
      "Epoch 5/25\n",
      "15/15 - 2s - 100ms/step - accuracy: 0.6440 - loss: 2.6917\n",
      "Epoch 6/25\n",
      "15/15 - 2s - 111ms/step - accuracy: 0.6440 - loss: 2.6894\n",
      "Epoch 7/25\n",
      "15/15 - 2s - 148ms/step - accuracy: 0.6440 - loss: 2.6873\n",
      "Epoch 8/25\n",
      "15/15 - 2s - 106ms/step - accuracy: 0.6440 - loss: 2.6853\n",
      "Epoch 9/25\n",
      "15/15 - 2s - 129ms/step - accuracy: 0.6440 - loss: 2.6834\n",
      "Epoch 10/25\n",
      "15/15 - 2s - 114ms/step - accuracy: 0.6440 - loss: 2.6816\n",
      "Epoch 11/25\n",
      "15/15 - 2s - 111ms/step - accuracy: 0.6440 - loss: 2.6799\n",
      "Epoch 12/25\n",
      "15/15 - 1s - 100ms/step - accuracy: 0.6440 - loss: 2.6783\n",
      "Epoch 13/25\n",
      "15/15 - 3s - 225ms/step - accuracy: 0.6440 - loss: 2.6767\n",
      "Epoch 14/25\n",
      "15/15 - 3s - 172ms/step - accuracy: 0.6440 - loss: 2.6752\n",
      "Epoch 15/25\n",
      "15/15 - 2s - 143ms/step - accuracy: 0.6440 - loss: 2.6737\n",
      "Epoch 16/25\n",
      "15/15 - 2s - 121ms/step - accuracy: 0.6440 - loss: 2.6722\n",
      "Epoch 17/25\n",
      "15/15 - 2s - 105ms/step - accuracy: 0.6440 - loss: 2.6707\n",
      "Epoch 18/25\n",
      "15/15 - 2s - 109ms/step - accuracy: 0.6440 - loss: 2.6693\n",
      "Epoch 19/25\n",
      "15/15 - 2s - 108ms/step - accuracy: 0.6440 - loss: 2.6679\n",
      "Epoch 20/25\n",
      "15/15 - 2s - 163ms/step - accuracy: 0.6440 - loss: 2.6665\n",
      "Epoch 21/25\n",
      "15/15 - 2s - 111ms/step - accuracy: 0.6440 - loss: 2.6651\n",
      "Epoch 22/25\n",
      "15/15 - 2s - 113ms/step - accuracy: 0.6440 - loss: 2.6636\n",
      "Epoch 23/25\n",
      "15/15 - 2s - 146ms/step - accuracy: 0.6440 - loss: 2.6622\n",
      "Epoch 24/25\n",
      "15/15 - 2s - 116ms/step - accuracy: 0.6440 - loss: 2.6608\n",
      "Epoch 25/25\n",
      "15/15 - 2s - 112ms/step - accuracy: 0.6440 - loss: 2.6593\n",
      "4/4 - 0s - 71ms/step\n",
      "Epoch 1/25\n",
      "15/15 - 4s - 291ms/step - accuracy: 0.6066 - loss: 2.7003\n",
      "Epoch 2/25\n",
      "15/15 - 3s - 167ms/step - accuracy: 0.6439 - loss: 2.7004\n",
      "Epoch 3/25\n",
      "15/15 - 2s - 145ms/step - accuracy: 0.6439 - loss: 2.6970\n",
      "Epoch 4/25\n",
      "15/15 - 2s - 103ms/step - accuracy: 0.6439 - loss: 2.6942\n",
      "Epoch 5/25\n",
      "15/15 - 1s - 100ms/step - accuracy: 0.6439 - loss: 2.6917\n",
      "Epoch 6/25\n",
      "15/15 - 2s - 122ms/step - accuracy: 0.6439 - loss: 2.6894\n",
      "Epoch 7/25\n",
      "15/15 - 2s - 106ms/step - accuracy: 0.6439 - loss: 2.6873\n",
      "Epoch 8/25\n",
      "15/15 - 1s - 100ms/step - accuracy: 0.6439 - loss: 2.6853\n",
      "Epoch 9/25\n",
      "15/15 - 1s - 98ms/step - accuracy: 0.6439 - loss: 2.6834\n",
      "Epoch 10/25\n",
      "15/15 - 3s - 171ms/step - accuracy: 0.6439 - loss: 2.6816\n",
      "Epoch 11/25\n",
      "15/15 - 3s - 170ms/step - accuracy: 0.6439 - loss: 2.6799\n",
      "Epoch 12/25\n",
      "15/15 - 1s - 99ms/step - accuracy: 0.6439 - loss: 2.6783\n",
      "Epoch 13/25\n",
      "15/15 - 1s - 99ms/step - accuracy: 0.6439 - loss: 2.6767\n",
      "Epoch 14/25\n",
      "15/15 - 1s - 98ms/step - accuracy: 0.6439 - loss: 2.6751\n",
      "Epoch 15/25\n",
      "15/15 - 2s - 104ms/step - accuracy: 0.6439 - loss: 2.6736\n",
      "Epoch 16/25\n",
      "15/15 - 2s - 116ms/step - accuracy: 0.6439 - loss: 2.6722\n",
      "Epoch 17/25\n",
      "15/15 - 1s - 99ms/step - accuracy: 0.6439 - loss: 2.6707\n",
      "Epoch 18/25\n",
      "15/15 - 1s - 97ms/step - accuracy: 0.6439 - loss: 2.6693\n",
      "Epoch 19/25\n",
      "15/15 - 1s - 99ms/step - accuracy: 0.6439 - loss: 2.6678\n",
      "Epoch 20/25\n",
      "15/15 - 2s - 101ms/step - accuracy: 0.6439 - loss: 2.6664\n",
      "Epoch 21/25\n",
      "15/15 - 1s - 99ms/step - accuracy: 0.6439 - loss: 2.6650\n",
      "Epoch 22/25\n",
      "15/15 - 2s - 112ms/step - accuracy: 0.6439 - loss: 2.6636\n",
      "Epoch 23/25\n",
      "15/15 - 2s - 113ms/step - accuracy: 0.6439 - loss: 2.6622\n",
      "Epoch 24/25\n",
      "15/15 - 2s - 100ms/step - accuracy: 0.6439 - loss: 2.6607\n",
      "Epoch 25/25\n",
      "15/15 - 1s - 97ms/step - accuracy: 0.6439 - loss: 2.6593\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x13d4baa20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x13d4baa20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "4/4 - 0s - 72ms/step\n",
      "Epoch 1/25\n",
      "15/15 - 3s - 216ms/step - accuracy: 0.5988 - loss: 2.7107\n",
      "Epoch 2/25\n",
      "15/15 - 3s - 178ms/step - accuracy: 0.6440 - loss: 2.7004\n",
      "Epoch 3/25\n",
      "15/15 - 1s - 99ms/step - accuracy: 0.6440 - loss: 2.6970\n",
      "Epoch 4/25\n",
      "15/15 - 3s - 171ms/step - accuracy: 0.6440 - loss: 2.6942\n",
      "Epoch 5/25\n",
      "15/15 - 3s - 172ms/step - accuracy: 0.6440 - loss: 2.6916\n",
      "Epoch 6/25\n",
      "15/15 - 2s - 101ms/step - accuracy: 0.6440 - loss: 2.6893\n",
      "Epoch 7/25\n",
      "15/15 - 2s - 101ms/step - accuracy: 0.6440 - loss: 2.6872\n",
      "Epoch 8/25\n",
      "15/15 - 1s - 97ms/step - accuracy: 0.6440 - loss: 2.6851\n",
      "Epoch 9/25\n",
      "15/15 - 1s - 99ms/step - accuracy: 0.6440 - loss: 2.6832\n",
      "Epoch 10/25\n",
      "15/15 - 2s - 107ms/step - accuracy: 0.6440 - loss: 2.6814\n",
      "Epoch 11/25\n",
      "15/15 - 2s - 116ms/step - accuracy: 0.6440 - loss: 2.6797\n",
      "Epoch 12/25\n",
      "15/15 - 2s - 101ms/step - accuracy: 0.6440 - loss: 2.6780\n",
      "Epoch 13/25\n",
      "15/15 - 1s - 99ms/step - accuracy: 0.6440 - loss: 2.6763\n",
      "Epoch 14/25\n",
      "15/15 - 1s - 97ms/step - accuracy: 0.6440 - loss: 2.6747\n",
      "Epoch 15/25\n",
      "15/15 - 1s - 99ms/step - accuracy: 0.6440 - loss: 2.6732\n",
      "Epoch 16/25\n",
      "15/15 - 1s - 100ms/step - accuracy: 0.6440 - loss: 2.6716\n",
      "Epoch 17/25\n",
      "15/15 - 1s - 99ms/step - accuracy: 0.6440 - loss: 2.6701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/25\n",
      "15/15 - 2s - 118ms/step - accuracy: 0.6440 - loss: 2.6685\n",
      "Epoch 19/25\n",
      "15/15 - 2s - 117ms/step - accuracy: 0.6440 - loss: 2.6670\n",
      "Epoch 20/25\n",
      "15/15 - 2s - 152ms/step - accuracy: 0.6440 - loss: 2.6655\n",
      "Epoch 21/25\n",
      "15/15 - 1s - 97ms/step - accuracy: 0.6440 - loss: 2.6639\n",
      "Epoch 22/25\n",
      "15/15 - 2s - 102ms/step - accuracy: 0.6440 - loss: 2.6623\n",
      "Epoch 23/25\n",
      "15/15 - 2s - 101ms/step - accuracy: 0.6440 - loss: 2.6607\n",
      "Epoch 24/25\n",
      "15/15 - 1s - 100ms/step - accuracy: 0.6440 - loss: 2.6591\n",
      "Epoch 25/25\n",
      "15/15 - 2s - 119ms/step - accuracy: 0.6440 - loss: 2.6574\n",
      "4/4 - 0s - 64ms/step\n",
      "Epoch 1/25\n",
      "15/15 - 3s - 224ms/step - accuracy: 0.6005 - loss: 2.7045\n",
      "Epoch 2/25\n",
      "15/15 - 1s - 99ms/step - accuracy: 0.6439 - loss: 2.7004\n",
      "Epoch 3/25\n",
      "15/15 - 1s - 98ms/step - accuracy: 0.6439 - loss: 2.6970\n",
      "Epoch 4/25\n",
      "15/15 - 1s - 98ms/step - accuracy: 0.6439 - loss: 2.6942\n",
      "Epoch 5/25\n",
      "15/15 - 3s - 169ms/step - accuracy: 0.6439 - loss: 2.6917\n",
      "Epoch 6/25\n",
      "15/15 - 1s - 99ms/step - accuracy: 0.6439 - loss: 2.6894\n",
      "Epoch 7/25\n",
      "15/15 - 2s - 105ms/step - accuracy: 0.6439 - loss: 2.6873\n",
      "Epoch 8/25\n",
      "15/15 - 2s - 113ms/step - accuracy: 0.6439 - loss: 2.6853\n",
      "Epoch 9/25\n",
      "15/15 - 1s - 96ms/step - accuracy: 0.6439 - loss: 2.6834\n",
      "Epoch 10/25\n",
      "15/15 - 1s - 98ms/step - accuracy: 0.6439 - loss: 2.6817\n",
      "Epoch 11/25\n",
      "15/15 - 2s - 100ms/step - accuracy: 0.6439 - loss: 2.6800\n",
      "Epoch 12/25\n",
      "15/15 - 2s - 102ms/step - accuracy: 0.6439 - loss: 2.6783\n",
      "Epoch 13/25\n",
      "15/15 - 1s - 100ms/step - accuracy: 0.6439 - loss: 2.6768\n",
      "Epoch 14/25\n",
      "15/15 - 1s - 100ms/step - accuracy: 0.6439 - loss: 2.6752\n",
      "Epoch 15/25\n",
      "15/15 - 2s - 100ms/step - accuracy: 0.6439 - loss: 2.6737\n",
      "Epoch 16/25\n",
      "15/15 - 1s - 98ms/step - accuracy: 0.6439 - loss: 2.6723\n",
      "Epoch 17/25\n",
      "15/15 - 1s - 99ms/step - accuracy: 0.6439 - loss: 2.6708\n",
      "Epoch 18/25\n",
      "15/15 - 1s - 98ms/step - accuracy: 0.6439 - loss: 2.6694\n",
      "Epoch 19/25\n",
      "15/15 - 1s - 98ms/step - accuracy: 0.6439 - loss: 2.6680\n",
      "Epoch 20/25\n",
      "15/15 - 1s - 98ms/step - accuracy: 0.6439 - loss: 2.6666\n",
      "Epoch 21/25\n",
      "15/15 - 1s - 97ms/step - accuracy: 0.6439 - loss: 2.6652\n",
      "Epoch 22/25\n",
      "15/15 - 1s - 97ms/step - accuracy: 0.6439 - loss: 2.6638\n",
      "Epoch 23/25\n",
      "15/15 - 3s - 183ms/step - accuracy: 0.6439 - loss: 2.6624\n",
      "Epoch 24/25\n",
      "15/15 - 1s - 99ms/step - accuracy: 0.6439 - loss: 2.6610\n",
      "Epoch 25/25\n",
      "15/15 - 1s - 99ms/step - accuracy: 0.6439 - loss: 2.6595\n",
      "4/4 - 0s - 62ms/step\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m0.644    \u001b[39m | \u001b[39m3.371    \u001b[39m | \u001b[39m960.6    \u001b[39m | \u001b[39m0.732    \u001b[39m | \u001b[39m0.1796   \u001b[39m | \u001b[39m24.68    \u001b[39m | \u001b[39m1.312    \u001b[39m | \u001b[39m1.116    \u001b[39m | \u001b[39m2.732    \u001b[39m | \u001b[39m0.6051   \u001b[39m | \u001b[39m73.73    \u001b[39m | \u001b[39m0.02058  \u001b[39m | \u001b[39m6.789    \u001b[39m |\n",
      "Epoch 1/29\n",
      "38/38 - 2s - 50ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 2/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 3/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 4/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 5/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 6/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 7/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 8/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 9/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 10/29\n",
      "38/38 - 0s - 9ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 11/29\n",
      "38/38 - 0s - 10ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 12/29\n",
      "38/38 - 0s - 10ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 13/29\n",
      "38/38 - 0s - 12ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 14/29\n",
      "38/38 - 0s - 11ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 15/29\n",
      "38/38 - 0s - 9ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 16/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 17/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 18/29\n",
      "38/38 - 0s - 9ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 19/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 20/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 21/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 22/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 23/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 24/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 25/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 26/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 27/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 28/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 29/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "10/10 - 0s - 18ms/step\n",
      "Epoch 1/29\n",
      "38/38 - 2s - 52ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 2/29\n",
      "38/38 - 1s - 16ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 3/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 4/29\n",
      "38/38 - 0s - 9ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 5/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 6/29\n",
      "38/38 - 1s - 16ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 7/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 8/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 9/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 10/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 11/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 12/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 13/29\n",
      "38/38 - 1s - 17ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 14/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 15/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 16/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 17/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 18/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 19/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 20/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 21/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 22/29\n",
      "38/38 - 1s - 16ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 23/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 24/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 25/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 26/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 27/29\n",
      "38/38 - 1s - 18ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 28/29\n",
      "38/38 - 0s - 10ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 29/29\n",
      "38/38 - 0s - 11ms/step - accuracy: 0.6440 - loss: nan\n",
      "10/10 - 0s - 21ms/step\n",
      "Epoch 1/29\n",
      "38/38 - 2s - 56ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 2/29\n",
      "38/38 - 1s - 16ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 3/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 4/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 5/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 6/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 7/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 8/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 9/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 10/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 11/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 12/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 13/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 14/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 15/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 16/29\n",
      "38/38 - 1s - 17ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 17/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 18/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 19/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 20/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 21/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 22/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 23/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 24/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 25/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 26/29\n",
      "38/38 - 0s - 9ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 27/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/29\n",
      "38/38 - 1s - 16ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 29/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "10/10 - 0s - 18ms/step\n",
      "Epoch 1/29\n",
      "38/38 - 2s - 56ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 2/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 3/29\n",
      "38/38 - 1s - 16ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 4/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 5/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 6/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 7/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 8/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 9/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 10/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 11/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 12/29\n",
      "38/38 - 0s - 9ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 13/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 14/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 15/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 16/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 17/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 18/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 19/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 20/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 21/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 22/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 23/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 24/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 25/29\n",
      "38/38 - 0s - 9ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 26/29\n",
      "38/38 - 0s - 9ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 27/29\n",
      "38/38 - 0s - 9ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 28/29\n",
      "38/38 - 0s - 9ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 29/29\n",
      "38/38 - 0s - 9ms/step - accuracy: 0.6440 - loss: nan\n",
      "10/10 - 0s - 18ms/step\n",
      "Epoch 1/29\n",
      "38/38 - 2s - 49ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 2/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 3/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 4/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 5/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 6/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 7/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 8/29\n",
      "38/38 - 1s - 16ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 9/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 10/29\n",
      "38/38 - 1s - 17ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 11/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 12/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 13/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 14/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 15/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 16/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 17/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 18/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 19/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 20/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 21/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 22/29\n",
      "38/38 - 0s - 12ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 23/29\n",
      "38/38 - 1s - 15ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 24/29\n",
      "38/38 - 0s - 11ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 25/29\n",
      "38/38 - 0s - 10ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 26/29\n",
      "38/38 - 1s - 15ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 27/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 28/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 29/29\n",
      "38/38 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "10/10 - 0s - 18ms/step\n",
      "| \u001b[39m2        \u001b[39m | \u001b[39m0.644    \u001b[39m | \u001b[39m7.492    \u001b[39m | \u001b[39m369.9    \u001b[39m | \u001b[39m0.1818   \u001b[39m | \u001b[39m0.05502  \u001b[39m | \u001b[39m29.13    \u001b[39m | \u001b[39m2.05     \u001b[39m | \u001b[39m1.864    \u001b[39m | \u001b[39m1.582    \u001b[39m | \u001b[39m0.6157   \u001b[39m | \u001b[39m22.55    \u001b[39m | \u001b[39m0.2921   \u001b[39m | \u001b[39m2.565    \u001b[39m |\n",
      "Epoch 1/38\n",
      "17/17 - 4s - 259ms/step - accuracy: 0.5521 - loss: 1.4671\n",
      "Epoch 2/38\n",
      "17/17 - 2s - 126ms/step - accuracy: 0.6856 - loss: 0.9291\n",
      "Epoch 3/38\n",
      "17/17 - 2s - 138ms/step - accuracy: 0.7173 - loss: 0.8268\n",
      "Epoch 4/38\n",
      "17/17 - 2s - 124ms/step - accuracy: 0.7437 - loss: 0.7645\n",
      "Epoch 5/38\n",
      "17/17 - 2s - 122ms/step - accuracy: 0.7601 - loss: 0.7143\n",
      "Epoch 6/38\n",
      "17/17 - 2s - 126ms/step - accuracy: 0.7752 - loss: 0.6718\n",
      "Epoch 7/38\n",
      "17/17 - 2s - 120ms/step - accuracy: 0.7863 - loss: 0.6311\n",
      "Epoch 8/38\n",
      "17/17 - 3s - 152ms/step - accuracy: 0.8000 - loss: 0.5896\n",
      "Epoch 9/38\n",
      "17/17 - 2s - 120ms/step - accuracy: 0.8098 - loss: 0.5518\n",
      "Epoch 10/38\n",
      "17/17 - 2s - 126ms/step - accuracy: 0.8183 - loss: 0.5182\n",
      "Epoch 11/38\n",
      "17/17 - 2s - 138ms/step - accuracy: 0.8282 - loss: 0.4873\n",
      "Epoch 12/38\n",
      "17/17 - 2s - 123ms/step - accuracy: 0.8390 - loss: 0.4605\n",
      "Epoch 13/38\n",
      "17/17 - 2s - 123ms/step - accuracy: 0.8448 - loss: 0.4391\n",
      "Epoch 14/38\n",
      "17/17 - 2s - 122ms/step - accuracy: 0.8555 - loss: 0.4139\n",
      "Epoch 15/38\n",
      "17/17 - 2s - 123ms/step - accuracy: 0.8672 - loss: 0.3885\n",
      "Epoch 16/38\n",
      "17/17 - 2s - 123ms/step - accuracy: 0.8693 - loss: 0.3776\n",
      "Epoch 17/38\n",
      "17/17 - 2s - 125ms/step - accuracy: 0.8791 - loss: 0.3556\n",
      "Epoch 18/38\n",
      "17/17 - 2s - 123ms/step - accuracy: 0.8766 - loss: 0.3529\n",
      "Epoch 19/38\n",
      "17/17 - 2s - 125ms/step - accuracy: 0.8855 - loss: 0.3365\n",
      "Epoch 20/38\n",
      "17/17 - 2s - 123ms/step - accuracy: 0.8892 - loss: 0.3248\n",
      "Epoch 21/38\n",
      "17/17 - 2s - 145ms/step - accuracy: 0.8937 - loss: 0.3146\n",
      "Epoch 22/38\n",
      "17/17 - 2s - 137ms/step - accuracy: 0.8996 - loss: 0.2959\n",
      "Epoch 23/38\n",
      "17/17 - 2s - 127ms/step - accuracy: 0.8921 - loss: 0.3050\n",
      "Epoch 24/38\n",
      "17/17 - 2s - 125ms/step - accuracy: 0.8964 - loss: 0.2958\n",
      "Epoch 25/38\n",
      "17/17 - 2s - 140ms/step - accuracy: 0.9041 - loss: 0.2819\n",
      "Epoch 26/38\n",
      "17/17 - 2s - 133ms/step - accuracy: 0.9071 - loss: 0.2770\n",
      "Epoch 27/38\n",
      "17/17 - 2s - 137ms/step - accuracy: 0.9099 - loss: 0.2645\n",
      "Epoch 28/38\n",
      "17/17 - 2s - 141ms/step - accuracy: 0.9100 - loss: 0.2664\n",
      "Epoch 29/38\n",
      "17/17 - 2s - 134ms/step - accuracy: 0.9112 - loss: 0.2626\n",
      "Epoch 30/38\n",
      "17/17 - 2s - 129ms/step - accuracy: 0.9163 - loss: 0.2504\n",
      "Epoch 31/38\n",
      "17/17 - 2s - 125ms/step - accuracy: 0.9183 - loss: 0.2426\n",
      "Epoch 32/38\n",
      "17/17 - 2s - 138ms/step - accuracy: 0.9222 - loss: 0.2352\n",
      "Epoch 33/38\n",
      "17/17 - 2s - 122ms/step - accuracy: 0.9246 - loss: 0.2308\n",
      "Epoch 34/38\n",
      "17/17 - 2s - 124ms/step - accuracy: 0.9190 - loss: 0.2370\n",
      "Epoch 35/38\n",
      "17/17 - 2s - 122ms/step - accuracy: 0.9231 - loss: 0.2284\n",
      "Epoch 36/38\n",
      "17/17 - 2s - 122ms/step - accuracy: 0.9135 - loss: 0.2605\n",
      "Epoch 37/38\n",
      "17/17 - 2s - 122ms/step - accuracy: 0.9187 - loss: 0.2340\n",
      "Epoch 38/38\n",
      "17/17 - 2s - 124ms/step - accuracy: 0.9285 - loss: 0.2145\n",
      "5/5 - 0s - 58ms/step\n",
      "Epoch 1/38\n",
      "17/17 - 4s - 258ms/step - accuracy: 0.5340 - loss: 1.6047\n",
      "Epoch 2/38\n",
      "17/17 - 2s - 122ms/step - accuracy: 0.6886 - loss: 0.9479\n",
      "Epoch 3/38\n",
      "17/17 - 2s - 133ms/step - accuracy: 0.7197 - loss: 0.8321\n",
      "Epoch 4/38\n",
      "17/17 - 2s - 130ms/step - accuracy: 0.7431 - loss: 0.7644\n",
      "Epoch 5/38\n",
      "17/17 - 2s - 124ms/step - accuracy: 0.7613 - loss: 0.7148\n",
      "Epoch 6/38\n",
      "17/17 - 2s - 125ms/step - accuracy: 0.7712 - loss: 0.6778\n",
      "Epoch 7/38\n",
      "17/17 - 2s - 126ms/step - accuracy: 0.7810 - loss: 0.6449\n",
      "Epoch 8/38\n",
      "17/17 - 2s - 140ms/step - accuracy: 0.7910 - loss: 0.6166\n",
      "Epoch 9/38\n",
      "17/17 - 2s - 129ms/step - accuracy: 0.7981 - loss: 0.5891\n",
      "Epoch 10/38\n",
      "17/17 - 2s - 125ms/step - accuracy: 0.8041 - loss: 0.5602\n",
      "Epoch 11/38\n",
      "17/17 - 2s - 123ms/step - accuracy: 0.8138 - loss: 0.5315\n",
      "Epoch 12/38\n",
      "17/17 - 2s - 125ms/step - accuracy: 0.8258 - loss: 0.5052\n",
      "Epoch 13/38\n",
      "17/17 - 2s - 126ms/step - accuracy: 0.8324 - loss: 0.4802\n",
      "Epoch 14/38\n",
      "17/17 - 2s - 121ms/step - accuracy: 0.8431 - loss: 0.4539\n",
      "Epoch 15/38\n",
      "17/17 - 2s - 120ms/step - accuracy: 0.8513 - loss: 0.4323\n",
      "Epoch 16/38\n",
      "17/17 - 2s - 123ms/step - accuracy: 0.8582 - loss: 0.4116\n",
      "Epoch 17/38\n",
      "17/17 - 2s - 127ms/step - accuracy: 0.8653 - loss: 0.3943\n",
      "Epoch 18/38\n",
      "17/17 - 2s - 130ms/step - accuracy: 0.8707 - loss: 0.3784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/38\n",
      "17/17 - 2s - 136ms/step - accuracy: 0.8738 - loss: 0.3652\n",
      "Epoch 20/38\n",
      "17/17 - 2s - 144ms/step - accuracy: 0.8813 - loss: 0.3481\n",
      "Epoch 21/38\n",
      "17/17 - 2s - 126ms/step - accuracy: 0.8792 - loss: 0.3526\n",
      "Epoch 22/38\n",
      "17/17 - 2s - 123ms/step - accuracy: 0.8885 - loss: 0.3261\n",
      "Epoch 23/38\n",
      "17/17 - 2s - 121ms/step - accuracy: 0.8908 - loss: 0.3183\n",
      "Epoch 24/38\n",
      "17/17 - 2s - 122ms/step - accuracy: 0.8869 - loss: 0.3244\n",
      "Epoch 25/38\n",
      "17/17 - 2s - 129ms/step - accuracy: 0.8948 - loss: 0.3058\n",
      "Epoch 26/38\n",
      "17/17 - 2s - 127ms/step - accuracy: 0.8974 - loss: 0.2975\n",
      "Epoch 27/38\n",
      "17/17 - 2s - 125ms/step - accuracy: 0.8985 - loss: 0.2924\n",
      "Epoch 28/38\n",
      "17/17 - 3s - 164ms/step - accuracy: 0.9078 - loss: 0.2724\n",
      "Epoch 29/38\n",
      "17/17 - 2s - 143ms/step - accuracy: 0.9061 - loss: 0.2728\n",
      "Epoch 30/38\n",
      "17/17 - 2s - 127ms/step - accuracy: 0.9083 - loss: 0.2676\n",
      "Epoch 31/38\n",
      "17/17 - 2s - 127ms/step - accuracy: 0.9083 - loss: 0.2685\n",
      "Epoch 32/38\n",
      "17/17 - 2s - 127ms/step - accuracy: 0.9109 - loss: 0.2620\n",
      "Epoch 33/38\n",
      "17/17 - 2s - 128ms/step - accuracy: 0.9124 - loss: 0.2520\n",
      "Epoch 34/38\n",
      "17/17 - 2s - 121ms/step - accuracy: 0.9174 - loss: 0.2457\n",
      "Epoch 35/38\n",
      "17/17 - 2s - 120ms/step - accuracy: 0.9178 - loss: 0.2424\n",
      "Epoch 36/38\n",
      "17/17 - 2s - 123ms/step - accuracy: 0.9115 - loss: 0.2495\n",
      "Epoch 37/38\n",
      "17/17 - 2s - 121ms/step - accuracy: 0.9249 - loss: 0.2219\n",
      "Epoch 38/38\n",
      "17/17 - 2s - 123ms/step - accuracy: 0.9237 - loss: 0.2224\n",
      "5/5 - 0s - 58ms/step\n",
      "Epoch 1/38\n",
      "17/17 - 5s - 285ms/step - accuracy: 0.5443 - loss: 1.4652\n",
      "Epoch 2/38\n",
      "17/17 - 2s - 130ms/step - accuracy: 0.6879 - loss: 0.9304\n",
      "Epoch 3/38\n",
      "17/17 - 2s - 128ms/step - accuracy: 0.7160 - loss: 0.8361\n",
      "Epoch 4/38\n",
      "17/17 - 2s - 126ms/step - accuracy: 0.7427 - loss: 0.7745\n",
      "Epoch 5/38\n",
      "17/17 - 2s - 124ms/step - accuracy: 0.7593 - loss: 0.7233\n",
      "Epoch 6/38\n",
      "17/17 - 3s - 162ms/step - accuracy: 0.7741 - loss: 0.6764\n",
      "Epoch 7/38\n",
      "17/17 - 2s - 137ms/step - accuracy: 0.7873 - loss: 0.6357\n",
      "Epoch 8/38\n",
      "17/17 - 2s - 125ms/step - accuracy: 0.7985 - loss: 0.5993\n",
      "Epoch 9/38\n",
      "17/17 - 2s - 127ms/step - accuracy: 0.8098 - loss: 0.5665\n",
      "Epoch 10/38\n",
      "17/17 - 2s - 127ms/step - accuracy: 0.8170 - loss: 0.5329\n",
      "Epoch 11/38\n",
      "17/17 - 2s - 125ms/step - accuracy: 0.8277 - loss: 0.5060\n",
      "Epoch 12/38\n",
      "17/17 - 2s - 128ms/step - accuracy: 0.8358 - loss: 0.4778\n",
      "Epoch 13/38\n",
      "17/17 - 2s - 130ms/step - accuracy: 0.8427 - loss: 0.4544\n",
      "Epoch 14/38\n",
      "17/17 - 2s - 127ms/step - accuracy: 0.8511 - loss: 0.4318\n",
      "Epoch 15/38\n",
      "17/17 - 2s - 138ms/step - accuracy: 0.8603 - loss: 0.4081\n",
      "Epoch 16/38\n",
      "17/17 - 2s - 135ms/step - accuracy: 0.8632 - loss: 0.3941\n",
      "Epoch 17/38\n",
      "17/17 - 2s - 143ms/step - accuracy: 0.8727 - loss: 0.3673\n",
      "Epoch 18/38\n",
      "17/17 - 2s - 123ms/step - accuracy: 0.8769 - loss: 0.3576\n",
      "Epoch 19/38\n",
      "17/17 - 2s - 126ms/step - accuracy: 0.8843 - loss: 0.3358\n",
      "Epoch 20/38\n",
      "17/17 - 2s - 129ms/step - accuracy: 0.8903 - loss: 0.3217\n",
      "Epoch 21/38\n",
      "17/17 - 2s - 125ms/step - accuracy: 0.8892 - loss: 0.3188\n",
      "Epoch 22/38\n",
      "17/17 - 2s - 130ms/step - accuracy: 0.8978 - loss: 0.2996\n",
      "Epoch 23/38\n",
      "17/17 - 2s - 131ms/step - accuracy: 0.8993 - loss: 0.2945\n",
      "Epoch 24/38\n",
      "17/17 - 2s - 129ms/step - accuracy: 0.9068 - loss: 0.2739\n",
      "Epoch 25/38\n",
      "17/17 - 2s - 127ms/step - accuracy: 0.9043 - loss: 0.2834\n",
      "Epoch 26/38\n",
      "17/17 - 2s - 128ms/step - accuracy: 0.9064 - loss: 0.2700\n",
      "Epoch 27/38\n",
      "17/17 - 2s - 137ms/step - accuracy: 0.9152 - loss: 0.2538\n",
      "Epoch 28/38\n",
      "17/17 - 2s - 139ms/step - accuracy: 0.9169 - loss: 0.2488\n",
      "Epoch 29/38\n",
      "17/17 - 2s - 136ms/step - accuracy: 0.9173 - loss: 0.2460\n",
      "Epoch 30/38\n",
      "17/17 - 2s - 128ms/step - accuracy: 0.9214 - loss: 0.2378\n",
      "Epoch 31/38\n",
      "17/17 - 2s - 127ms/step - accuracy: 0.9223 - loss: 0.2277\n",
      "Epoch 32/38\n",
      "17/17 - 3s - 148ms/step - accuracy: 0.9280 - loss: 0.2176\n",
      "Epoch 33/38\n",
      "17/17 - 2s - 124ms/step - accuracy: 0.9287 - loss: 0.2159\n",
      "Epoch 34/38\n",
      "17/17 - 2s - 127ms/step - accuracy: 0.9310 - loss: 0.2060\n",
      "Epoch 35/38\n",
      "17/17 - 3s - 157ms/step - accuracy: 0.9189 - loss: 0.2277\n",
      "Epoch 36/38\n",
      "17/17 - 2s - 131ms/step - accuracy: 0.9256 - loss: 0.2155\n",
      "Epoch 37/38\n",
      "17/17 - 3s - 149ms/step - accuracy: 0.9333 - loss: 0.2019\n",
      "Epoch 38/38\n",
      "17/17 - 3s - 164ms/step - accuracy: 0.9351 - loss: 0.1919\n",
      "5/5 - 1s - 134ms/step\n",
      "Epoch 1/38\n",
      "17/17 - 5s - 268ms/step - accuracy: 0.5853 - loss: 1.4265\n",
      "Epoch 2/38\n",
      "17/17 - 2s - 125ms/step - accuracy: 0.6897 - loss: 0.9030\n",
      "Epoch 3/38\n",
      "17/17 - 2s - 133ms/step - accuracy: 0.7289 - loss: 0.8091\n",
      "Epoch 4/38\n",
      "17/17 - 2s - 142ms/step - accuracy: 0.7458 - loss: 0.7483\n",
      "Epoch 5/38\n",
      "17/17 - 2s - 137ms/step - accuracy: 0.7651 - loss: 0.6983\n",
      "Epoch 6/38\n",
      "17/17 - 2s - 125ms/step - accuracy: 0.7802 - loss: 0.6569\n",
      "Epoch 7/38\n",
      "17/17 - 3s - 150ms/step - accuracy: 0.7866 - loss: 0.6173\n",
      "Epoch 8/38\n",
      "17/17 - 2s - 121ms/step - accuracy: 0.7972 - loss: 0.5805\n",
      "Epoch 9/38\n",
      "17/17 - 2s - 120ms/step - accuracy: 0.8088 - loss: 0.5433\n",
      "Epoch 10/38\n",
      "17/17 - 2s - 120ms/step - accuracy: 0.8195 - loss: 0.5140\n",
      "Epoch 11/38\n",
      "17/17 - 2s - 122ms/step - accuracy: 0.8274 - loss: 0.4879\n",
      "Epoch 12/38\n",
      "17/17 - 2s - 124ms/step - accuracy: 0.8359 - loss: 0.4612\n",
      "Epoch 13/38\n",
      "17/17 - 2s - 131ms/step - accuracy: 0.8452 - loss: 0.4414\n",
      "Epoch 14/38\n",
      "17/17 - 2s - 139ms/step - accuracy: 0.8517 - loss: 0.4184\n",
      "Epoch 15/38\n",
      "17/17 - 2s - 126ms/step - accuracy: 0.8598 - loss: 0.4020\n",
      "Epoch 16/38\n",
      "17/17 - 2s - 129ms/step - accuracy: 0.8654 - loss: 0.3822\n",
      "Epoch 17/38\n",
      "17/17 - 2s - 131ms/step - accuracy: 0.8704 - loss: 0.3687\n",
      "Epoch 18/38\n",
      "17/17 - 2s - 126ms/step - accuracy: 0.8792 - loss: 0.3512\n",
      "Epoch 19/38\n",
      "17/17 - 2s - 129ms/step - accuracy: 0.8820 - loss: 0.3395\n",
      "Epoch 20/38\n",
      "17/17 - 2s - 142ms/step - accuracy: 0.8838 - loss: 0.3333\n",
      "Epoch 21/38\n",
      "17/17 - 2s - 124ms/step - accuracy: 0.8924 - loss: 0.3165\n",
      "Epoch 22/38\n",
      "17/17 - 2s - 120ms/step - accuracy: 0.8877 - loss: 0.3254\n",
      "Epoch 23/38\n",
      "17/17 - 2s - 126ms/step - accuracy: 0.8964 - loss: 0.3005\n",
      "Epoch 24/38\n",
      "17/17 - 2s - 124ms/step - accuracy: 0.9010 - loss: 0.2915\n",
      "Epoch 25/38\n",
      "17/17 - 3s - 151ms/step - accuracy: 0.9001 - loss: 0.2898\n",
      "Epoch 26/38\n",
      "17/17 - 2s - 122ms/step - accuracy: 0.9050 - loss: 0.2769\n",
      "Epoch 27/38\n",
      "17/17 - 2s - 124ms/step - accuracy: 0.9009 - loss: 0.2872\n",
      "Epoch 28/38\n",
      "17/17 - 2s - 124ms/step - accuracy: 0.9066 - loss: 0.2684\n",
      "Epoch 29/38\n",
      "17/17 - 2s - 141ms/step - accuracy: 0.9099 - loss: 0.2601\n",
      "Epoch 30/38\n",
      "17/17 - 2s - 127ms/step - accuracy: 0.9151 - loss: 0.2502\n",
      "Epoch 31/38\n",
      "17/17 - 2s - 125ms/step - accuracy: 0.9092 - loss: 0.2665\n",
      "Epoch 32/38\n",
      "17/17 - 2s - 126ms/step - accuracy: 0.9089 - loss: 0.2641\n",
      "Epoch 33/38\n",
      "17/17 - 2s - 128ms/step - accuracy: 0.9186 - loss: 0.2401\n",
      "Epoch 34/38\n",
      "17/17 - 2s - 132ms/step - accuracy: 0.9174 - loss: 0.2406\n",
      "Epoch 35/38\n",
      "17/17 - 2s - 141ms/step - accuracy: 0.9190 - loss: 0.2357\n",
      "Epoch 36/38\n",
      "17/17 - 3s - 153ms/step - accuracy: 0.9208 - loss: 0.2310\n",
      "Epoch 37/38\n",
      "17/17 - 2s - 125ms/step - accuracy: 0.9213 - loss: 0.2332\n",
      "Epoch 38/38\n",
      "17/17 - 2s - 138ms/step - accuracy: 0.9207 - loss: 0.2359\n",
      "5/5 - 0s - 67ms/step\n",
      "Epoch 1/38\n",
      "17/17 - 5s - 287ms/step - accuracy: 0.5787 - loss: 1.4431\n",
      "Epoch 2/38\n",
      "17/17 - 2s - 130ms/step - accuracy: 0.6942 - loss: 0.9081\n",
      "Epoch 3/38\n",
      "17/17 - 2s - 126ms/step - accuracy: 0.7240 - loss: 0.8108\n",
      "Epoch 4/38\n",
      "17/17 - 2s - 124ms/step - accuracy: 0.7498 - loss: 0.7477\n",
      "Epoch 5/38\n",
      "17/17 - 2s - 125ms/step - accuracy: 0.7660 - loss: 0.6954\n",
      "Epoch 6/38\n",
      "17/17 - 2s - 127ms/step - accuracy: 0.7801 - loss: 0.6484\n",
      "Epoch 7/38\n",
      "17/17 - 2s - 122ms/step - accuracy: 0.7924 - loss: 0.6064\n",
      "Epoch 8/38\n",
      "17/17 - 2s - 126ms/step - accuracy: 0.8040 - loss: 0.5698\n",
      "Epoch 9/38\n",
      "17/17 - 2s - 125ms/step - accuracy: 0.8152 - loss: 0.5364\n",
      "Epoch 10/38\n",
      "17/17 - 2s - 134ms/step - accuracy: 0.8244 - loss: 0.5046\n",
      "Epoch 11/38\n",
      "17/17 - 2s - 141ms/step - accuracy: 0.8345 - loss: 0.4770\n",
      "Epoch 12/38\n",
      "17/17 - 2s - 123ms/step - accuracy: 0.8436 - loss: 0.4491\n",
      "Epoch 13/38\n",
      "17/17 - 2s - 131ms/step - accuracy: 0.8497 - loss: 0.4290\n",
      "Epoch 14/38\n",
      "17/17 - 2s - 131ms/step - accuracy: 0.8590 - loss: 0.4081\n",
      "Epoch 15/38\n",
      "17/17 - 2s - 124ms/step - accuracy: 0.8687 - loss: 0.3826\n",
      "Epoch 16/38\n",
      "17/17 - 2s - 126ms/step - accuracy: 0.8746 - loss: 0.3617\n",
      "Epoch 17/38\n",
      "17/17 - 2s - 129ms/step - accuracy: 0.8823 - loss: 0.3460\n",
      "Epoch 18/38\n",
      "17/17 - 2s - 128ms/step - accuracy: 0.8855 - loss: 0.3330\n",
      "Epoch 19/38\n",
      "17/17 - 2s - 134ms/step - accuracy: 0.8882 - loss: 0.3235\n",
      "Epoch 20/38\n",
      "17/17 - 2s - 140ms/step - accuracy: 0.8952 - loss: 0.3070\n",
      "Epoch 21/38\n",
      "17/17 - 2s - 128ms/step - accuracy: 0.9013 - loss: 0.2918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/38\n",
      "17/17 - 2s - 124ms/step - accuracy: 0.8982 - loss: 0.2999\n",
      "Epoch 23/38\n",
      "17/17 - 2s - 127ms/step - accuracy: 0.9036 - loss: 0.2788\n",
      "Epoch 24/38\n",
      "17/17 - 3s - 152ms/step - accuracy: 0.9033 - loss: 0.2748\n",
      "Epoch 25/38\n",
      "17/17 - 3s - 154ms/step - accuracy: 0.9137 - loss: 0.2581\n",
      "Epoch 26/38\n",
      "17/17 - 2s - 131ms/step - accuracy: 0.9133 - loss: 0.2547\n",
      "Epoch 27/38\n",
      "17/17 - 2s - 130ms/step - accuracy: 0.9187 - loss: 0.2434\n",
      "Epoch 28/38\n",
      "17/17 - 2s - 141ms/step - accuracy: 0.9178 - loss: 0.2448\n",
      "Epoch 29/38\n",
      "17/17 - 2s - 142ms/step - accuracy: 0.9217 - loss: 0.2326\n",
      "Epoch 30/38\n",
      "17/17 - 2s - 129ms/step - accuracy: 0.9230 - loss: 0.2292\n",
      "Epoch 31/38\n",
      "17/17 - 3s - 154ms/step - accuracy: 0.9259 - loss: 0.2187\n",
      "Epoch 32/38\n",
      "17/17 - 4s - 217ms/step - accuracy: 0.9261 - loss: 0.2163\n",
      "Epoch 33/38\n",
      "17/17 - 5s - 273ms/step - accuracy: 0.9293 - loss: 0.2130\n",
      "Epoch 34/38\n",
      "17/17 - 3s - 191ms/step - accuracy: 0.9293 - loss: 0.2082\n",
      "Epoch 35/38\n",
      "17/17 - 3s - 171ms/step - accuracy: 0.9325 - loss: 0.2000\n",
      "Epoch 36/38\n",
      "17/17 - 3s - 163ms/step - accuracy: 0.9372 - loss: 0.1895\n",
      "Epoch 37/38\n",
      "17/17 - 2s - 127ms/step - accuracy: 0.9335 - loss: 0.2010\n",
      "Epoch 38/38\n",
      "17/17 - 2s - 131ms/step - accuracy: 0.9386 - loss: 0.1863\n",
      "5/5 - 0s - 61ms/step\n",
      "| \u001b[35m3        \u001b[39m | \u001b[35m0.8801   \u001b[39m | \u001b[35m4.105    \u001b[39m | \u001b[35m828.1    \u001b[39m | \u001b[35m0.1997   \u001b[39m | \u001b[35m0.1543   \u001b[39m | \u001b[35m37.77    \u001b[39m | \u001b[35m1.093    \u001b[39m | \u001b[35m2.215    \u001b[39m | \u001b[35m1.341    \u001b[39m | \u001b[35m0.0744   \u001b[39m | \u001b[35m95.4     \u001b[39m | \u001b[35m0.9656   \u001b[39m | \u001b[35m5.659    \u001b[39m |\n",
      "Epoch 1/24\n",
      "50/50 - 3s - 58ms/step - accuracy: 0.4471 - loss: 2.3623\n",
      "Epoch 2/24\n",
      "50/50 - 1s - 30ms/step - accuracy: 0.6360 - loss: 1.8615\n",
      "Epoch 3/24\n",
      "50/50 - 2s - 30ms/step - accuracy: 0.6417 - loss: 1.5681\n",
      "Epoch 4/24\n",
      "50/50 - 1s - 30ms/step - accuracy: 0.6434 - loss: 1.4085\n",
      "Epoch 5/24\n",
      "50/50 - 2s - 30ms/step - accuracy: 0.6439 - loss: 1.3182\n",
      "Epoch 6/24\n",
      "50/50 - 2s - 34ms/step - accuracy: 0.6440 - loss: 1.2615\n",
      "Epoch 7/24\n",
      "50/50 - 178s - 4s/step - accuracy: 0.6440 - loss: 1.2247\n",
      "Epoch 8/24\n",
      "50/50 - 2s - 41ms/step - accuracy: 0.6440 - loss: 1.1979\n",
      "Epoch 9/24\n",
      "50/50 - 2s - 43ms/step - accuracy: 0.6440 - loss: 1.1783\n",
      "Epoch 10/24\n",
      "50/50 - 2s - 33ms/step - accuracy: 0.6440 - loss: 1.1629\n",
      "Epoch 11/24\n",
      "50/50 - 3s - 66ms/step - accuracy: 0.6440 - loss: 1.1496\n",
      "Epoch 12/24\n",
      "50/50 - 2s - 40ms/step - accuracy: 0.6440 - loss: 1.1401\n",
      "Epoch 13/24\n",
      "50/50 - 2s - 39ms/step - accuracy: 0.6440 - loss: 1.1310\n",
      "Epoch 14/24\n",
      "50/50 - 3s - 53ms/step - accuracy: 0.6440 - loss: 1.1234\n",
      "Epoch 15/24\n",
      "50/50 - 3s - 55ms/step - accuracy: 0.6440 - loss: 1.1163\n",
      "Epoch 16/24\n",
      "50/50 - 3s - 60ms/step - accuracy: 0.6441 - loss: 1.1104\n",
      "Epoch 17/24\n",
      "50/50 - 4s - 89ms/step - accuracy: 0.6440 - loss: 1.1051\n",
      "Epoch 18/24\n",
      "50/50 - 3s - 51ms/step - accuracy: 0.6442 - loss: 1.0997\n",
      "Epoch 19/24\n",
      "50/50 - 2s - 47ms/step - accuracy: 0.6441 - loss: 1.0956\n",
      "Epoch 20/24\n",
      "50/50 - 2s - 45ms/step - accuracy: 0.6444 - loss: 1.0911\n",
      "Epoch 21/24\n",
      "50/50 - 2s - 50ms/step - accuracy: 0.6443 - loss: 1.0873\n",
      "Epoch 22/24\n",
      "50/50 - 3s - 57ms/step - accuracy: 0.6448 - loss: 1.0839\n",
      "Epoch 23/24\n",
      "50/50 - 2s - 47ms/step - accuracy: 0.6447 - loss: 1.0810\n",
      "Epoch 24/24\n",
      "50/50 - 2s - 47ms/step - accuracy: 0.6452 - loss: 1.0781\n",
      "13/13 - 0s - 32ms/step\n",
      "Epoch 1/24\n",
      "50/50 - 398s - 8s/step - accuracy: 0.5355 - loss: 2.2746\n",
      "Epoch 2/24\n",
      "50/50 - 2s - 46ms/step - accuracy: 0.6279 - loss: 1.8100\n",
      "Epoch 3/24\n",
      "50/50 - 2s - 48ms/step - accuracy: 0.6361 - loss: 1.5479\n",
      "Epoch 4/24\n",
      "50/50 - 2s - 36ms/step - accuracy: 0.6412 - loss: 1.4021\n",
      "Epoch 5/24\n",
      "50/50 - 2s - 34ms/step - accuracy: 0.6428 - loss: 1.3155\n",
      "Epoch 6/24\n",
      "50/50 - 2s - 33ms/step - accuracy: 0.6434 - loss: 1.2595\n",
      "Epoch 7/24\n",
      "50/50 - 2s - 33ms/step - accuracy: 0.6438 - loss: 1.2204\n",
      "Epoch 8/24\n",
      "50/50 - 2s - 50ms/step - accuracy: 0.6439 - loss: 1.1910\n",
      "Epoch 9/24\n",
      "50/50 - 3s - 53ms/step - accuracy: 0.6440 - loss: 1.1697\n",
      "Epoch 10/24\n",
      "50/50 - 3s - 60ms/step - accuracy: 0.6439 - loss: 1.1520\n",
      "Epoch 11/24\n",
      "50/50 - 3s - 59ms/step - accuracy: 0.6440 - loss: 1.1383\n",
      "Epoch 12/24\n",
      "50/50 - 3s - 55ms/step - accuracy: 0.6440 - loss: 1.1266\n",
      "Epoch 13/24\n",
      "50/50 - 3s - 53ms/step - accuracy: 0.6440 - loss: 1.1170\n",
      "Epoch 14/24\n",
      "50/50 - 3s - 50ms/step - accuracy: 0.6440 - loss: 1.1090\n",
      "Epoch 15/24\n",
      "50/50 - 3s - 52ms/step - accuracy: 0.6441 - loss: 1.1017\n",
      "Epoch 16/24\n",
      "50/50 - 3s - 58ms/step - accuracy: 0.6440 - loss: 1.0954\n",
      "Epoch 17/24\n",
      "50/50 - 3s - 52ms/step - accuracy: 0.6442 - loss: 1.0908\n",
      "Epoch 18/24\n",
      "50/50 - 3s - 50ms/step - accuracy: 0.6441 - loss: 1.0860\n",
      "Epoch 19/24\n",
      "50/50 - 3s - 50ms/step - accuracy: 0.6446 - loss: 1.0818\n",
      "Epoch 20/24\n",
      "50/50 - 565s - 11s/step - accuracy: 0.6441 - loss: 1.0788\n",
      "Epoch 21/24\n",
      "50/50 - 3s - 66ms/step - accuracy: 0.6457 - loss: 1.0740\n",
      "Epoch 22/24\n",
      "50/50 - 5s - 95ms/step - accuracy: 0.6451 - loss: 1.0709\n",
      "Epoch 23/24\n",
      "50/50 - 3s - 53ms/step - accuracy: 0.6460 - loss: 1.0681\n",
      "Epoch 24/24\n",
      "50/50 - 2s - 40ms/step - accuracy: 0.6449 - loss: 1.0652\n",
      "13/13 - 1s - 42ms/step\n",
      "Epoch 1/24\n",
      "50/50 - 4s - 79ms/step - accuracy: 0.4528 - loss: 2.3524\n",
      "Epoch 2/24\n",
      "50/50 - 2s - 36ms/step - accuracy: 0.6411 - loss: 1.9306\n",
      "Epoch 3/24\n",
      "50/50 - 2s - 34ms/step - accuracy: 0.6439 - loss: 1.6347\n",
      "Epoch 4/24\n",
      "50/50 - 2s - 35ms/step - accuracy: 0.6439 - loss: 1.4490\n",
      "Epoch 5/24\n",
      "50/50 - 2s - 36ms/step - accuracy: 0.6439 - loss: 1.3424\n",
      "Epoch 6/24\n",
      "50/50 - 2s - 34ms/step - accuracy: 0.6439 - loss: 1.2781\n",
      "Epoch 7/24\n",
      "50/50 - 2s - 32ms/step - accuracy: 0.6439 - loss: 1.2359\n",
      "Epoch 8/24\n",
      "50/50 - 2s - 33ms/step - accuracy: 0.6439 - loss: 1.2070\n",
      "Epoch 9/24\n",
      "50/50 - 2s - 34ms/step - accuracy: 0.6439 - loss: 1.1856\n",
      "Epoch 10/24\n",
      "50/50 - 2s - 33ms/step - accuracy: 0.6439 - loss: 1.1689\n",
      "Epoch 11/24\n",
      "50/50 - 2s - 38ms/step - accuracy: 0.6439 - loss: 1.1548\n",
      "Epoch 12/24\n",
      "50/50 - 2s - 33ms/step - accuracy: 0.6439 - loss: 1.1434\n",
      "Epoch 13/24\n",
      "50/50 - 2s - 33ms/step - accuracy: 0.6439 - loss: 1.1333\n",
      "Epoch 14/24\n",
      "50/50 - 3s - 50ms/step - accuracy: 0.6439 - loss: 1.1244\n",
      "Epoch 15/24\n",
      "50/50 - 2s - 33ms/step - accuracy: 0.6439 - loss: 1.1167\n",
      "Epoch 16/24\n",
      "50/50 - 2s - 34ms/step - accuracy: 0.6439 - loss: 1.1098\n",
      "Epoch 17/24\n",
      "50/50 - 2s - 33ms/step - accuracy: 0.6439 - loss: 1.1043\n",
      "Epoch 18/24\n",
      "50/50 - 2s - 32ms/step - accuracy: 0.6439 - loss: 1.0978\n",
      "Epoch 19/24\n",
      "50/50 - 2s - 33ms/step - accuracy: 0.6439 - loss: 1.0930\n",
      "Epoch 20/24\n",
      "50/50 - 2s - 37ms/step - accuracy: 0.6438 - loss: 1.0887\n",
      "Epoch 21/24\n",
      "50/50 - 2s - 35ms/step - accuracy: 0.6439 - loss: 1.0841\n",
      "Epoch 22/24\n",
      "50/50 - 2s - 33ms/step - accuracy: 0.6439 - loss: 1.0798\n",
      "Epoch 23/24\n",
      "50/50 - 3s - 53ms/step - accuracy: 0.6442 - loss: 1.0763\n",
      "Epoch 24/24\n",
      "50/50 - 2s - 34ms/step - accuracy: 0.6439 - loss: 1.0725\n",
      "13/13 - 0s - 22ms/step\n",
      "Epoch 1/24\n",
      "50/50 - 3s - 66ms/step - accuracy: 0.4426 - loss: 2.4110\n",
      "Epoch 2/24\n",
      "50/50 - 2s - 33ms/step - accuracy: 0.6346 - loss: 1.9065\n",
      "Epoch 3/24\n",
      "50/50 - 2s - 43ms/step - accuracy: 0.6412 - loss: 1.6118\n",
      "Epoch 4/24\n",
      "50/50 - 2s - 38ms/step - accuracy: 0.6430 - loss: 1.4414\n",
      "Epoch 5/24\n",
      "50/50 - 2s - 47ms/step - accuracy: 0.6439 - loss: 1.3371\n",
      "Epoch 6/24\n",
      "50/50 - 2s - 32ms/step - accuracy: 0.6440 - loss: 1.2702\n",
      "Epoch 7/24\n",
      "50/50 - 2s - 33ms/step - accuracy: 0.6440 - loss: 1.2236\n",
      "Epoch 8/24\n",
      "50/50 - 2s - 38ms/step - accuracy: 0.6440 - loss: 1.1906\n",
      "Epoch 9/24\n",
      "50/50 - 2s - 41ms/step - accuracy: 0.6440 - loss: 1.1665\n",
      "Epoch 10/24\n",
      "50/50 - 2s - 42ms/step - accuracy: 0.6440 - loss: 1.1472\n",
      "Epoch 11/24\n",
      "50/50 - 2s - 36ms/step - accuracy: 0.6440 - loss: 1.1325\n",
      "Epoch 12/24\n",
      "50/50 - 2s - 38ms/step - accuracy: 0.6446 - loss: 1.1198\n",
      "Epoch 13/24\n",
      "50/50 - 2s - 39ms/step - accuracy: 0.6447 - loss: 1.1108\n",
      "Epoch 14/24\n",
      "50/50 - 2s - 37ms/step - accuracy: 0.6452 - loss: 1.1024\n",
      "Epoch 15/24\n",
      "50/50 - 2s - 38ms/step - accuracy: 0.6460 - loss: 1.0943\n",
      "Epoch 16/24\n",
      "50/50 - 3s - 52ms/step - accuracy: 0.6475 - loss: 1.0879\n",
      "Epoch 17/24\n",
      "50/50 - 2s - 40ms/step - accuracy: 0.6484 - loss: 1.0825\n",
      "Epoch 18/24\n",
      "50/50 - 2s - 36ms/step - accuracy: 0.6500 - loss: 1.0768\n",
      "Epoch 19/24\n",
      "50/50 - 2s - 42ms/step - accuracy: 0.6503 - loss: 1.0732\n",
      "Epoch 20/24\n",
      "50/50 - 2s - 44ms/step - accuracy: 0.6504 - loss: 1.0688\n",
      "Epoch 21/24\n",
      "50/50 - 2s - 36ms/step - accuracy: 0.6523 - loss: 1.0649\n",
      "Epoch 22/24\n",
      "50/50 - 2s - 34ms/step - accuracy: 0.6534 - loss: 1.0610\n",
      "Epoch 23/24\n",
      "50/50 - 2s - 34ms/step - accuracy: 0.6545 - loss: 1.0583\n",
      "Epoch 24/24\n",
      "50/50 - 2s - 34ms/step - accuracy: 0.6564 - loss: 1.0545\n",
      "13/13 - 0s - 24ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/24\n",
      "50/50 - 3s - 61ms/step - accuracy: 0.2357 - loss: 2.5250\n",
      "Epoch 2/24\n",
      "50/50 - 2s - 34ms/step - accuracy: 0.6306 - loss: 2.0082\n",
      "Epoch 3/24\n",
      "50/50 - 2s - 35ms/step - accuracy: 0.6430 - loss: 1.6553\n",
      "Epoch 4/24\n",
      "50/50 - 2s - 34ms/step - accuracy: 0.6438 - loss: 1.4469\n",
      "Epoch 5/24\n",
      "50/50 - 2s - 33ms/step - accuracy: 0.6439 - loss: 1.3355\n",
      "Epoch 6/24\n",
      "50/50 - 2s - 34ms/step - accuracy: 0.6439 - loss: 1.2727\n",
      "Epoch 7/24\n",
      "50/50 - 2s - 34ms/step - accuracy: 0.6439 - loss: 1.2334\n",
      "Epoch 8/24\n",
      "50/50 - 2s - 38ms/step - accuracy: 0.6439 - loss: 1.2072\n",
      "Epoch 9/24\n",
      "50/50 - 2s - 35ms/step - accuracy: 0.6439 - loss: 1.1862\n",
      "Epoch 10/24\n",
      "50/50 - 2s - 30ms/step - accuracy: 0.6439 - loss: 1.1700\n",
      "Epoch 11/24\n",
      "50/50 - 1s - 29ms/step - accuracy: 0.6439 - loss: 1.1561\n",
      "Epoch 12/24\n",
      "50/50 - 2s - 30ms/step - accuracy: 0.6439 - loss: 1.1449\n",
      "Epoch 13/24\n",
      "50/50 - 1s - 30ms/step - accuracy: 0.6439 - loss: 1.1348\n",
      "Epoch 14/24\n",
      "50/50 - 2s - 34ms/step - accuracy: 0.6439 - loss: 1.1252\n",
      "Epoch 15/24\n",
      "50/50 - 2s - 33ms/step - accuracy: 0.6439 - loss: 1.1175\n",
      "Epoch 16/24\n",
      "50/50 - 2s - 32ms/step - accuracy: 0.6439 - loss: 1.1099\n",
      "Epoch 17/24\n",
      "50/50 - 2s - 31ms/step - accuracy: 0.6439 - loss: 1.1038\n",
      "Epoch 18/24\n",
      "50/50 - 2s - 49ms/step - accuracy: 0.6439 - loss: 1.0982\n",
      "Epoch 19/24\n",
      "50/50 - 3s - 52ms/step - accuracy: 0.6438 - loss: 1.0923\n",
      "Epoch 20/24\n",
      "50/50 - 3s - 53ms/step - accuracy: 0.6439 - loss: 1.0875\n",
      "Epoch 21/24\n",
      "50/50 - 1s - 30ms/step - accuracy: 0.6441 - loss: 1.0835\n",
      "Epoch 22/24\n",
      "50/50 - 3s - 51ms/step - accuracy: 0.6450 - loss: 1.0785\n",
      "Epoch 23/24\n",
      "50/50 - 1s - 29ms/step - accuracy: 0.6452 - loss: 1.0749\n",
      "Epoch 24/24\n",
      "50/50 - 2s - 31ms/step - accuracy: 0.6446 - loss: 1.0718\n",
      "13/13 - 0s - 23ms/step\n",
      "| \u001b[39m4        \u001b[39m | \u001b[39m0.6483   \u001b[39m | \u001b[39m2.742    \u001b[39m | \u001b[39m278.1    \u001b[39m | \u001b[39m0.6842   \u001b[39m | \u001b[39m0.132    \u001b[39m | \u001b[39m23.66    \u001b[39m | \u001b[39m1.99     \u001b[39m | \u001b[39m1.069    \u001b[39m | \u001b[39m2.819    \u001b[39m | \u001b[39m0.2662   \u001b[39m | \u001b[39m69.63    \u001b[39m | \u001b[39m0.3117   \u001b[39m | \u001b[39m3.64     \u001b[39m |\n",
      "Epoch 1/48\n",
      "40/40 - 2s - 46ms/step - accuracy: 0.5907 - loss: 1.3055\n",
      "Epoch 2/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.6428 - loss: 1.0057\n",
      "Epoch 3/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.6756 - loss: 0.9095\n",
      "Epoch 4/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.6969 - loss: 0.8532\n",
      "Epoch 5/48\n",
      "40/40 - 1s - 16ms/step - accuracy: 0.7130 - loss: 0.8086\n",
      "Epoch 6/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7226 - loss: 0.7779\n",
      "Epoch 7/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7330 - loss: 0.7518\n",
      "Epoch 8/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7401 - loss: 0.7277\n",
      "Epoch 9/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7475 - loss: 0.7131\n",
      "Epoch 10/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7473 - loss: 0.6934\n",
      "Epoch 11/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7552 - loss: 0.6827\n",
      "Epoch 12/48\n",
      "40/40 - 1s - 16ms/step - accuracy: 0.7621 - loss: 0.6617\n",
      "Epoch 13/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7694 - loss: 0.6430\n",
      "Epoch 14/48\n",
      "40/40 - 0s - 12ms/step - accuracy: 0.7703 - loss: 0.6354\n",
      "Epoch 15/48\n",
      "40/40 - 0s - 12ms/step - accuracy: 0.7739 - loss: 0.6329\n",
      "Epoch 16/48\n",
      "40/40 - 1s - 14ms/step - accuracy: 0.7803 - loss: 0.6083\n",
      "Epoch 17/48\n",
      "40/40 - 1s - 16ms/step - accuracy: 0.7807 - loss: 0.6037\n",
      "Epoch 18/48\n",
      "40/40 - 1s - 16ms/step - accuracy: 0.7828 - loss: 0.6013\n",
      "Epoch 19/48\n",
      "40/40 - 0s - 12ms/step - accuracy: 0.7867 - loss: 0.5918\n",
      "Epoch 20/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7911 - loss: 0.5764\n",
      "Epoch 21/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7879 - loss: 0.5809\n",
      "Epoch 22/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7921 - loss: 0.5666\n",
      "Epoch 23/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7950 - loss: 0.5616\n",
      "Epoch 24/48\n",
      "40/40 - 1s - 16ms/step - accuracy: 0.7961 - loss: 0.5588\n",
      "Epoch 25/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7994 - loss: 0.5497\n",
      "Epoch 26/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7984 - loss: 0.5467\n",
      "Epoch 27/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8063 - loss: 0.5347\n",
      "Epoch 28/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8025 - loss: 0.5381\n",
      "Epoch 29/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8083 - loss: 0.5217\n",
      "Epoch 30/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8091 - loss: 0.5218\n",
      "Epoch 31/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8138 - loss: 0.5134\n",
      "Epoch 32/48\n",
      "40/40 - 1s - 16ms/step - accuracy: 0.8112 - loss: 0.5106\n",
      "Epoch 33/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8154 - loss: 0.5076\n",
      "Epoch 34/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8200 - loss: 0.4973\n",
      "Epoch 35/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8202 - loss: 0.4932\n",
      "Epoch 36/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8213 - loss: 0.4944\n",
      "Epoch 37/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8258 - loss: 0.4832\n",
      "Epoch 38/48\n",
      "40/40 - 1s - 16ms/step - accuracy: 0.8250 - loss: 0.4772\n",
      "Epoch 39/48\n",
      "40/40 - 1s - 15ms/step - accuracy: 0.8271 - loss: 0.4677\n",
      "Epoch 40/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8282 - loss: 0.4728\n",
      "Epoch 41/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8300 - loss: 0.4637\n",
      "Epoch 42/48\n",
      "40/40 - 1s - 16ms/step - accuracy: 0.8323 - loss: 0.4582\n",
      "Epoch 43/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8304 - loss: 0.4649\n",
      "Epoch 44/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8346 - loss: 0.4474\n",
      "Epoch 45/48\n",
      "40/40 - 1s - 16ms/step - accuracy: 0.8358 - loss: 0.4532\n",
      "Epoch 46/48\n",
      "40/40 - 1s - 16ms/step - accuracy: 0.8399 - loss: 0.4443\n",
      "Epoch 47/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8372 - loss: 0.4414\n",
      "Epoch 48/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8418 - loss: 0.4417\n",
      "10/10 - 0s - 20ms/step\n",
      "Epoch 1/48\n",
      "40/40 - 2s - 55ms/step - accuracy: 0.6238 - loss: 1.2198\n",
      "Epoch 2/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.6845 - loss: 0.9483\n",
      "Epoch 3/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7080 - loss: 0.8596\n",
      "Epoch 4/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7299 - loss: 0.8001\n",
      "Epoch 5/48\n",
      "40/40 - 1s - 14ms/step - accuracy: 0.7364 - loss: 0.7616\n",
      "Epoch 6/48\n",
      "40/40 - 1s - 15ms/step - accuracy: 0.7446 - loss: 0.7277\n",
      "Epoch 7/48\n",
      "40/40 - 1s - 16ms/step - accuracy: 0.7565 - loss: 0.7098\n",
      "Epoch 8/48\n",
      "40/40 - 0s - 12ms/step - accuracy: 0.7563 - loss: 0.6954\n",
      "Epoch 9/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7627 - loss: 0.6747\n",
      "Epoch 10/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7677 - loss: 0.6603\n",
      "Epoch 11/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7733 - loss: 0.6440\n",
      "Epoch 12/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7735 - loss: 0.6402\n",
      "Epoch 13/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7814 - loss: 0.6225\n",
      "Epoch 14/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7822 - loss: 0.6158\n",
      "Epoch 15/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7873 - loss: 0.5989\n",
      "Epoch 16/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7905 - loss: 0.5988\n",
      "Epoch 17/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7924 - loss: 0.5836\n",
      "Epoch 18/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7955 - loss: 0.5773\n",
      "Epoch 19/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7981 - loss: 0.5718\n",
      "Epoch 20/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8012 - loss: 0.5599\n",
      "Epoch 21/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8049 - loss: 0.5478\n",
      "Epoch 22/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8091 - loss: 0.5387\n",
      "Epoch 23/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8088 - loss: 0.5275\n",
      "Epoch 24/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8080 - loss: 0.5332\n",
      "Epoch 25/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8176 - loss: 0.5187\n",
      "Epoch 26/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8171 - loss: 0.5150\n",
      "Epoch 27/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8197 - loss: 0.5072\n",
      "Epoch 28/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8205 - loss: 0.4930\n",
      "Epoch 29/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8237 - loss: 0.4946\n",
      "Epoch 30/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8258 - loss: 0.4855\n",
      "Epoch 31/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8285 - loss: 0.4819\n",
      "Epoch 32/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8309 - loss: 0.4743\n",
      "Epoch 33/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8324 - loss: 0.4732\n",
      "Epoch 34/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8323 - loss: 0.4606\n",
      "Epoch 35/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8317 - loss: 0.4646\n",
      "Epoch 36/48\n",
      "40/40 - 1s - 16ms/step - accuracy: 0.8354 - loss: 0.4548\n",
      "Epoch 37/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8403 - loss: 0.4504\n",
      "Epoch 38/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8383 - loss: 0.4489\n",
      "Epoch 39/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8432 - loss: 0.4332\n",
      "Epoch 40/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8428 - loss: 0.4339\n",
      "Epoch 41/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8409 - loss: 0.4387\n",
      "Epoch 42/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8497 - loss: 0.4182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/48\n",
      "40/40 - 1s - 16ms/step - accuracy: 0.8504 - loss: 0.4178\n",
      "Epoch 44/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8439 - loss: 0.4242\n",
      "Epoch 45/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8508 - loss: 0.4161\n",
      "Epoch 46/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8550 - loss: 0.4055\n",
      "Epoch 47/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8528 - loss: 0.4061\n",
      "Epoch 48/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8561 - loss: 0.4026\n",
      "10/10 - 0s - 20ms/step\n",
      "Epoch 1/48\n",
      "40/40 - 2s - 50ms/step - accuracy: 0.5844 - loss: 1.4276\n",
      "Epoch 2/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.6701 - loss: 0.9779\n",
      "Epoch 3/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.6915 - loss: 0.8990\n",
      "Epoch 4/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7071 - loss: 0.8316\n",
      "Epoch 5/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7182 - loss: 0.7928\n",
      "Epoch 6/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7345 - loss: 0.7524\n",
      "Epoch 7/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7405 - loss: 0.7310\n",
      "Epoch 8/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7511 - loss: 0.7014\n",
      "Epoch 9/48\n",
      "40/40 - 1s - 16ms/step - accuracy: 0.7615 - loss: 0.6822\n",
      "Epoch 10/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7653 - loss: 0.6587\n",
      "Epoch 11/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7680 - loss: 0.6479\n",
      "Epoch 12/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7693 - loss: 0.6338\n",
      "Epoch 13/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7786 - loss: 0.6207\n",
      "Epoch 14/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7816 - loss: 0.6147\n",
      "Epoch 15/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7877 - loss: 0.5973\n",
      "Epoch 16/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7890 - loss: 0.5836\n",
      "Epoch 17/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7912 - loss: 0.5786\n",
      "Epoch 18/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7947 - loss: 0.5731\n",
      "Epoch 19/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8001 - loss: 0.5557\n",
      "Epoch 20/48\n",
      "40/40 - 1s - 13ms/step - accuracy: 0.8033 - loss: 0.5561\n",
      "Epoch 21/48\n",
      "40/40 - 1s - 16ms/step - accuracy: 0.8035 - loss: 0.5412\n",
      "Epoch 22/48\n",
      "40/40 - 1s - 17ms/step - accuracy: 0.8103 - loss: 0.5323\n",
      "Epoch 23/48\n",
      "40/40 - 0s - 12ms/step - accuracy: 0.8082 - loss: 0.5273\n",
      "Epoch 24/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8125 - loss: 0.5223\n",
      "Epoch 25/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8135 - loss: 0.5163\n",
      "Epoch 26/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8171 - loss: 0.5041\n",
      "Epoch 27/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8195 - loss: 0.4929\n",
      "Epoch 28/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8245 - loss: 0.4903\n",
      "Epoch 29/48\n",
      "40/40 - 1s - 16ms/step - accuracy: 0.8227 - loss: 0.4870\n",
      "Epoch 30/48\n",
      "40/40 - 1s - 16ms/step - accuracy: 0.8280 - loss: 0.4785\n",
      "Epoch 31/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8275 - loss: 0.4743\n",
      "Epoch 32/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8288 - loss: 0.4686\n",
      "Epoch 33/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8359 - loss: 0.4596\n",
      "Epoch 34/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8377 - loss: 0.4501\n",
      "Epoch 35/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8392 - loss: 0.4457\n",
      "Epoch 36/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8404 - loss: 0.4409\n",
      "Epoch 37/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8421 - loss: 0.4386\n",
      "Epoch 38/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8442 - loss: 0.4259\n",
      "Epoch 39/48\n",
      "40/40 - 1s - 16ms/step - accuracy: 0.8455 - loss: 0.4236\n",
      "Epoch 40/48\n",
      "40/40 - 1s - 16ms/step - accuracy: 0.8469 - loss: 0.4254\n",
      "Epoch 41/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8511 - loss: 0.4149\n",
      "Epoch 42/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8473 - loss: 0.4175\n",
      "Epoch 43/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8527 - loss: 0.4106\n",
      "Epoch 44/48\n",
      "40/40 - 1s - 16ms/step - accuracy: 0.8515 - loss: 0.4036\n",
      "Epoch 45/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8550 - loss: 0.4006\n",
      "Epoch 46/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8588 - loss: 0.3970\n",
      "Epoch 47/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8559 - loss: 0.3990\n",
      "Epoch 48/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8602 - loss: 0.3902\n",
      "10/10 - 0s - 20ms/step\n",
      "Epoch 1/48\n",
      "40/40 - 2s - 44ms/step - accuracy: 0.5737 - loss: 1.4123\n",
      "Epoch 2/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.6546 - loss: 0.9936\n",
      "Epoch 3/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.6890 - loss: 0.8909\n",
      "Epoch 4/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7141 - loss: 0.8280\n",
      "Epoch 5/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7275 - loss: 0.7861\n",
      "Epoch 6/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7365 - loss: 0.7515\n",
      "Epoch 7/48\n",
      "40/40 - 1s - 14ms/step - accuracy: 0.7511 - loss: 0.7144\n",
      "Epoch 8/48\n",
      "40/40 - 1s - 15ms/step - accuracy: 0.7561 - loss: 0.6962\n",
      "Epoch 9/48\n",
      "40/40 - 1s - 14ms/step - accuracy: 0.7601 - loss: 0.6768\n",
      "Epoch 10/48\n",
      "40/40 - 1s - 14ms/step - accuracy: 0.7631 - loss: 0.6549\n",
      "Epoch 11/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7703 - loss: 0.6450\n",
      "Epoch 12/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7771 - loss: 0.6346\n",
      "Epoch 13/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7797 - loss: 0.6167\n",
      "Epoch 14/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7809 - loss: 0.6132\n",
      "Epoch 15/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7847 - loss: 0.6002\n",
      "Epoch 16/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7864 - loss: 0.5965\n",
      "Epoch 17/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7883 - loss: 0.5864\n",
      "Epoch 18/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7932 - loss: 0.5781\n",
      "Epoch 19/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7882 - loss: 0.5803\n",
      "Epoch 20/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7911 - loss: 0.5676\n",
      "Epoch 21/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8002 - loss: 0.5543\n",
      "Epoch 22/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7991 - loss: 0.5530\n",
      "Epoch 23/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7978 - loss: 0.5484\n",
      "Epoch 24/48\n",
      "40/40 - 1s - 16ms/step - accuracy: 0.8032 - loss: 0.5434\n",
      "Epoch 25/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8031 - loss: 0.5364\n",
      "Epoch 26/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8073 - loss: 0.5297\n",
      "Epoch 27/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8035 - loss: 0.5240\n",
      "Epoch 28/48\n",
      "40/40 - 1s - 13ms/step - accuracy: 0.8075 - loss: 0.5219\n",
      "Epoch 29/48\n",
      "40/40 - 1s - 16ms/step - accuracy: 0.8114 - loss: 0.5135\n",
      "Epoch 30/48\n",
      "40/40 - 1s - 27ms/step - accuracy: 0.8158 - loss: 0.5036\n",
      "Epoch 31/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8138 - loss: 0.5105\n",
      "Epoch 32/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8148 - loss: 0.5034\n",
      "Epoch 33/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8171 - loss: 0.4978\n",
      "Epoch 34/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8216 - loss: 0.4908\n",
      "Epoch 35/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8253 - loss: 0.4790\n",
      "Epoch 36/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8220 - loss: 0.4839\n",
      "Epoch 37/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8232 - loss: 0.4774\n",
      "Epoch 38/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8236 - loss: 0.4752\n",
      "Epoch 39/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8242 - loss: 0.4805\n",
      "Epoch 40/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8248 - loss: 0.4678\n",
      "Epoch 41/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8251 - loss: 0.4648\n",
      "Epoch 42/48\n",
      "40/40 - 1s - 16ms/step - accuracy: 0.8303 - loss: 0.4592\n",
      "Epoch 43/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8299 - loss: 0.4592\n",
      "Epoch 44/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8309 - loss: 0.4562\n",
      "Epoch 45/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8352 - loss: 0.4473\n",
      "Epoch 46/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8330 - loss: 0.4496\n",
      "Epoch 47/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8380 - loss: 0.4429\n",
      "Epoch 48/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8383 - loss: 0.4407\n",
      "10/10 - 0s - 20ms/step\n",
      "Epoch 1/48\n",
      "40/40 - 2s - 44ms/step - accuracy: 0.5789 - loss: 1.4210\n",
      "Epoch 2/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.6524 - loss: 0.9980\n",
      "Epoch 3/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.6776 - loss: 0.8975\n",
      "Epoch 4/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.6956 - loss: 0.8397\n",
      "Epoch 5/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7206 - loss: 0.7802\n",
      "Epoch 6/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7243 - loss: 0.7530\n",
      "Epoch 7/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7359 - loss: 0.7187\n",
      "Epoch 8/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7490 - loss: 0.6946\n",
      "Epoch 9/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7568 - loss: 0.6703\n",
      "Epoch 10/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7707 - loss: 0.6441\n",
      "Epoch 11/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7706 - loss: 0.6359\n",
      "Epoch 12/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7784 - loss: 0.6173\n",
      "Epoch 13/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7799 - loss: 0.6141\n",
      "Epoch 14/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7835 - loss: 0.5986\n",
      "Epoch 15/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7858 - loss: 0.5865\n",
      "Epoch 16/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.7931 - loss: 0.5765\n",
      "Epoch 17/48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 - 0s - 11ms/step - accuracy: 0.7973 - loss: 0.5691\n",
      "Epoch 18/48\n",
      "40/40 - 1s - 13ms/step - accuracy: 0.7937 - loss: 0.5622\n",
      "Epoch 19/48\n",
      "40/40 - 1s - 14ms/step - accuracy: 0.8015 - loss: 0.5447\n",
      "Epoch 20/48\n",
      "40/40 - 1s - 17ms/step - accuracy: 0.8023 - loss: 0.5469\n",
      "Epoch 21/48\n",
      "40/40 - 1s - 27ms/step - accuracy: 0.8062 - loss: 0.5351\n",
      "Epoch 22/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8080 - loss: 0.5274\n",
      "Epoch 23/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8089 - loss: 0.5202\n",
      "Epoch 24/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8115 - loss: 0.5160\n",
      "Epoch 25/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8179 - loss: 0.5043\n",
      "Epoch 26/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8166 - loss: 0.5059\n",
      "Epoch 27/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8188 - loss: 0.4948\n",
      "Epoch 28/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8192 - loss: 0.4919\n",
      "Epoch 29/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8243 - loss: 0.4890\n",
      "Epoch 30/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8233 - loss: 0.4817\n",
      "Epoch 31/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8261 - loss: 0.4781\n",
      "Epoch 32/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8261 - loss: 0.4680\n",
      "Epoch 33/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8260 - loss: 0.4674\n",
      "Epoch 34/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8301 - loss: 0.4627\n",
      "Epoch 35/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8347 - loss: 0.4517\n",
      "Epoch 36/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8307 - loss: 0.4563\n",
      "Epoch 37/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8367 - loss: 0.4462\n",
      "Epoch 38/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8378 - loss: 0.4432\n",
      "Epoch 39/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8439 - loss: 0.4320\n",
      "Epoch 40/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8380 - loss: 0.4368\n",
      "Epoch 41/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8436 - loss: 0.4238\n",
      "Epoch 42/48\n",
      "40/40 - 1s - 16ms/step - accuracy: 0.8441 - loss: 0.4233\n",
      "Epoch 43/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8458 - loss: 0.4211\n",
      "Epoch 44/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8473 - loss: 0.4170\n",
      "Epoch 45/48\n",
      "40/40 - 1s - 16ms/step - accuracy: 0.8465 - loss: 0.4123\n",
      "Epoch 46/48\n",
      "40/40 - 0s - 11ms/step - accuracy: 0.8502 - loss: 0.4074\n",
      "Epoch 47/48\n",
      "40/40 - 1s - 16ms/step - accuracy: 0.8501 - loss: 0.4054\n",
      "Epoch 48/48\n",
      "40/40 - 1s - 15ms/step - accuracy: 0.8541 - loss: 0.4006\n",
      "10/10 - 0s - 20ms/step\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39m0.8458   \u001b[39m | \u001b[39m4.92     \u001b[39m | \u001b[39m347.9    \u001b[39m | \u001b[39m0.9696   \u001b[39m | \u001b[39m0.2325   \u001b[39m | \u001b[39m48.18    \u001b[39m | \u001b[39m2.79     \u001b[39m | \u001b[39m2.196    \u001b[39m | \u001b[39m2.844    \u001b[39m | \u001b[39m0.09761  \u001b[39m | \u001b[39m27.64    \u001b[39m | \u001b[39m0.04523  \u001b[39m | \u001b[39m2.277    \u001b[39m |\n",
      "Epoch 1/28\n",
      "34/34 - 5s - 152ms/step - accuracy: 0.6022 - loss: 1.3183\n",
      "Epoch 2/28\n",
      "34/34 - 3s - 85ms/step - accuracy: 0.7126 - loss: 0.8332\n",
      "Epoch 3/28\n",
      "34/34 - 3s - 84ms/step - accuracy: 0.7454 - loss: 0.7405\n",
      "Epoch 4/28\n",
      "34/34 - 3s - 84ms/step - accuracy: 0.7678 - loss: 0.6848\n",
      "Epoch 5/28\n",
      "34/34 - 3s - 92ms/step - accuracy: 0.7838 - loss: 0.6301\n",
      "Epoch 6/28\n",
      "34/34 - 5s - 143ms/step - accuracy: 0.7980 - loss: 0.5836\n",
      "Epoch 7/28\n",
      "34/34 - 5s - 149ms/step - accuracy: 0.8082 - loss: 0.5606\n",
      "Epoch 8/28\n",
      "34/34 - 3s - 83ms/step - accuracy: 0.8103 - loss: 0.5417\n",
      "Epoch 9/28\n",
      "34/34 - 3s - 84ms/step - accuracy: 0.8210 - loss: 0.5105\n",
      "Epoch 10/28\n",
      "34/34 - 5s - 150ms/step - accuracy: 0.8316 - loss: 0.4824\n",
      "Epoch 11/28\n",
      "34/34 - 3s - 83ms/step - accuracy: 0.8342 - loss: 0.4670\n",
      "Epoch 12/28\n",
      "34/34 - 3s - 83ms/step - accuracy: 0.8395 - loss: 0.4509\n",
      "Epoch 13/28\n",
      "34/34 - 3s - 84ms/step - accuracy: 0.8436 - loss: 0.4415\n",
      "Epoch 14/28\n",
      "34/34 - 3s - 84ms/step - accuracy: 0.8274 - loss: 0.4868\n",
      "Epoch 15/28\n",
      "34/34 - 3s - 84ms/step - accuracy: 0.8454 - loss: 0.4346\n",
      "Epoch 16/28\n",
      "34/34 - 3s - 89ms/step - accuracy: 0.8516 - loss: 0.4111\n",
      "Epoch 17/28\n",
      "34/34 - 3s - 87ms/step - accuracy: 0.8590 - loss: 0.3929\n",
      "Epoch 18/28\n",
      "34/34 - 3s - 82ms/step - accuracy: 0.8511 - loss: 0.4152\n",
      "Epoch 19/28\n",
      "34/34 - 3s - 85ms/step - accuracy: 0.8597 - loss: 0.3913\n",
      "Epoch 20/28\n",
      "34/34 - 3s - 92ms/step - accuracy: 0.8648 - loss: 0.3772\n",
      "Epoch 21/28\n",
      "34/34 - 3s - 83ms/step - accuracy: 0.8474 - loss: 0.4244\n",
      "Epoch 22/28\n",
      "34/34 - 3s - 83ms/step - accuracy: 0.8707 - loss: 0.3549\n",
      "Epoch 23/28\n",
      "34/34 - 5s - 152ms/step - accuracy: 0.8655 - loss: 0.3807\n",
      "Epoch 24/28\n",
      "34/34 - 5s - 157ms/step - accuracy: 0.8770 - loss: 0.3387\n",
      "Epoch 25/28\n",
      "34/34 - 5s - 145ms/step - accuracy: 0.8870 - loss: 0.3198\n",
      "Epoch 26/28\n",
      "34/34 - 3s - 84ms/step - accuracy: 0.8792 - loss: 0.3323\n",
      "Epoch 27/28\n",
      "34/34 - 3s - 84ms/step - accuracy: 0.8876 - loss: 0.3098\n",
      "Epoch 28/28\n",
      "34/34 - 3s - 92ms/step - accuracy: 0.8823 - loss: 0.3341\n",
      "9/9 - 0s - 39ms/step\n",
      "Epoch 1/28\n",
      "34/34 - 5s - 144ms/step - accuracy: 0.6052 - loss: 1.2940\n",
      "Epoch 2/28\n",
      "34/34 - 5s - 153ms/step - accuracy: 0.7135 - loss: 0.8445\n",
      "Epoch 3/28\n",
      "34/34 - 3s - 83ms/step - accuracy: 0.7442 - loss: 0.7479\n",
      "Epoch 4/28\n",
      "34/34 - 3s - 83ms/step - accuracy: 0.7640 - loss: 0.6928\n",
      "Epoch 5/28\n",
      "34/34 - 3s - 83ms/step - accuracy: 0.7808 - loss: 0.6436\n",
      "Epoch 6/28\n",
      "34/34 - 3s - 82ms/step - accuracy: 0.7911 - loss: 0.6080\n",
      "Epoch 7/28\n",
      "34/34 - 3s - 83ms/step - accuracy: 0.8029 - loss: 0.5681\n",
      "Epoch 8/28\n",
      "34/34 - 3s - 89ms/step - accuracy: 0.8154 - loss: 0.5268\n",
      "Epoch 9/28\n",
      "34/34 - 3s - 100ms/step - accuracy: 0.8186 - loss: 0.5153\n",
      "Epoch 10/28\n",
      "34/34 - 5s - 138ms/step - accuracy: 0.8284 - loss: 0.4955\n",
      "Epoch 11/28\n",
      "34/34 - 3s - 86ms/step - accuracy: 0.8400 - loss: 0.4530\n",
      "Epoch 12/28\n",
      "34/34 - 3s - 86ms/step - accuracy: 0.8411 - loss: 0.4575\n",
      "Epoch 13/28\n",
      "34/34 - 3s - 85ms/step - accuracy: 0.8476 - loss: 0.4272\n",
      "Epoch 14/28\n",
      "34/34 - 3s - 86ms/step - accuracy: 0.8545 - loss: 0.4030\n",
      "Epoch 15/28\n",
      "34/34 - 3s - 84ms/step - accuracy: 0.8513 - loss: 0.4287\n",
      "Epoch 16/28\n",
      "34/34 - 3s - 84ms/step - accuracy: 0.8686 - loss: 0.3667\n",
      "Epoch 17/28\n",
      "34/34 - 3s - 84ms/step - accuracy: 0.8717 - loss: 0.3646\n",
      "Epoch 18/28\n",
      "34/34 - 3s - 93ms/step - accuracy: 0.8541 - loss: 0.4042\n",
      "Epoch 19/28\n",
      "34/34 - 3s - 83ms/step - accuracy: 0.8481 - loss: 0.4306\n",
      "Epoch 20/28\n",
      "34/34 - 3s - 84ms/step - accuracy: 0.8789 - loss: 0.3464\n",
      "Epoch 21/28\n",
      "34/34 - 3s - 92ms/step - accuracy: 0.8892 - loss: 0.3203\n",
      "Epoch 22/28\n",
      "34/34 - 3s - 86ms/step - accuracy: 0.8832 - loss: 0.3301\n",
      "Epoch 23/28\n",
      "34/34 - 3s - 83ms/step - accuracy: 0.8880 - loss: 0.3136\n",
      "Epoch 24/28\n",
      "34/34 - 5s - 152ms/step - accuracy: 0.8890 - loss: 0.3117\n",
      "Epoch 25/28\n",
      "34/34 - 3s - 83ms/step - accuracy: 0.8943 - loss: 0.2919\n",
      "Epoch 26/28\n",
      "34/34 - 3s - 83ms/step - accuracy: 0.8945 - loss: 0.3022\n",
      "Epoch 27/28\n",
      "34/34 - 3s - 87ms/step - accuracy: 0.8916 - loss: 0.3075\n",
      "Epoch 28/28\n",
      "34/34 - 3s - 89ms/step - accuracy: 0.8972 - loss: 0.2999\n",
      "9/9 - 0s - 39ms/step\n",
      "Epoch 1/28\n",
      "34/34 - 5s - 144ms/step - accuracy: 0.6340 - loss: 1.2436\n",
      "Epoch 2/28\n",
      "34/34 - 3s - 84ms/step - accuracy: 0.7152 - loss: 0.8253\n",
      "Epoch 3/28\n",
      "34/34 - 3s - 84ms/step - accuracy: 0.7505 - loss: 0.7236\n",
      "Epoch 4/28\n",
      "34/34 - 3s - 83ms/step - accuracy: 0.7670 - loss: 0.6693\n",
      "Epoch 5/28\n",
      "34/34 - 6s - 163ms/step - accuracy: 0.7889 - loss: 0.6067\n",
      "Epoch 6/28\n",
      "34/34 - 3s - 83ms/step - accuracy: 0.8004 - loss: 0.5696\n",
      "Epoch 7/28\n",
      "34/34 - 3s - 84ms/step - accuracy: 0.8069 - loss: 0.5556\n",
      "Epoch 8/28\n",
      "34/34 - 3s - 83ms/step - accuracy: 0.8274 - loss: 0.5028\n",
      "Epoch 9/28\n",
      "34/34 - 3s - 83ms/step - accuracy: 0.8351 - loss: 0.4834\n",
      "Epoch 10/28\n",
      "34/34 - 3s - 92ms/step - accuracy: 0.8208 - loss: 0.5114\n",
      "Epoch 11/28\n",
      "34/34 - 3s - 85ms/step - accuracy: 0.8421 - loss: 0.4536\n",
      "Epoch 12/28\n",
      "34/34 - 5s - 150ms/step - accuracy: 0.8482 - loss: 0.4298\n",
      "Epoch 13/28\n",
      "34/34 - 3s - 83ms/step - accuracy: 0.8531 - loss: 0.4192\n",
      "Epoch 14/28\n",
      "34/34 - 3s - 83ms/step - accuracy: 0.8556 - loss: 0.3991\n",
      "Epoch 15/28\n",
      "34/34 - 3s - 83ms/step - accuracy: 0.8619 - loss: 0.3906\n",
      "Epoch 16/28\n",
      "34/34 - 5s - 160ms/step - accuracy: 0.8573 - loss: 0.3923\n",
      "Epoch 17/28\n",
      "34/34 - 3s - 84ms/step - accuracy: 0.8790 - loss: 0.3519\n",
      "Epoch 18/28\n",
      "34/34 - 3s - 83ms/step - accuracy: 0.8706 - loss: 0.3666\n",
      "Epoch 19/28\n",
      "34/34 - 3s - 83ms/step - accuracy: 0.8755 - loss: 0.3506\n",
      "Epoch 20/28\n",
      "34/34 - 3s - 83ms/step - accuracy: 0.8679 - loss: 0.3717\n",
      "Epoch 21/28\n",
      "34/34 - 3s - 84ms/step - accuracy: 0.8847 - loss: 0.3288\n",
      "Epoch 22/28\n",
      "34/34 - 3s - 84ms/step - accuracy: 0.8869 - loss: 0.3265\n",
      "Epoch 23/28\n",
      "34/34 - 3s - 97ms/step - accuracy: 0.8922 - loss: 0.3097\n",
      "Epoch 24/28\n",
      "34/34 - 3s - 84ms/step - accuracy: 0.8528 - loss: 0.4305\n",
      "Epoch 25/28\n",
      "34/34 - 3s - 84ms/step - accuracy: 0.8899 - loss: 0.3157\n",
      "Epoch 26/28\n",
      "34/34 - 3s - 83ms/step - accuracy: 0.8996 - loss: 0.2983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/28\n",
      "34/34 - 3s - 83ms/step - accuracy: 0.8763 - loss: 0.3575\n",
      "Epoch 28/28\n",
      "34/34 - 3s - 83ms/step - accuracy: 0.9008 - loss: 0.2816\n",
      "9/9 - 0s - 39ms/step\n",
      "Epoch 1/28\n",
      "34/34 - 5s - 144ms/step - accuracy: 0.6130 - loss: 1.3195\n",
      "Epoch 2/28\n",
      "34/34 - 3s - 84ms/step - accuracy: 0.7175 - loss: 0.8365\n",
      "Epoch 3/28\n",
      "34/34 - 4s - 104ms/step - accuracy: 0.7510 - loss: 0.7398\n",
      "Epoch 4/28\n",
      "34/34 - 3s - 87ms/step - accuracy: 0.7714 - loss: 0.6748\n",
      "Epoch 5/28\n",
      "34/34 - 3s - 84ms/step - accuracy: 0.7779 - loss: 0.6407\n",
      "Epoch 6/28\n",
      "34/34 - 3s - 84ms/step - accuracy: 0.7899 - loss: 0.5956\n",
      "Epoch 7/28\n",
      "34/34 - 5s - 150ms/step - accuracy: 0.8031 - loss: 0.5616\n",
      "Epoch 8/28\n",
      "34/34 - 5s - 151ms/step - accuracy: 0.8068 - loss: 0.5498\n",
      "Epoch 9/28\n",
      "34/34 - 3s - 84ms/step - accuracy: 0.8168 - loss: 0.5198\n",
      "Epoch 10/28\n",
      "34/34 - 3s - 83ms/step - accuracy: 0.8198 - loss: 0.5110\n",
      "Epoch 11/28\n",
      "34/34 - 3s - 84ms/step - accuracy: 0.8324 - loss: 0.4711\n",
      "Epoch 12/28\n",
      "34/34 - 3s - 83ms/step - accuracy: 0.8362 - loss: 0.4649\n",
      "Epoch 13/28\n",
      "34/34 - 5s - 151ms/step - accuracy: 0.8443 - loss: 0.4326\n",
      "Epoch 14/28\n",
      "34/34 - 5s - 152ms/step - accuracy: 0.8502 - loss: 0.4222\n",
      "Epoch 15/28\n",
      "34/34 - 3s - 83ms/step - accuracy: 0.8551 - loss: 0.4094\n",
      "Epoch 16/28\n",
      "34/34 - 3s - 84ms/step - accuracy: 0.8580 - loss: 0.3899\n",
      "Epoch 17/28\n",
      "34/34 - 3s - 83ms/step - accuracy: 0.8505 - loss: 0.4163\n",
      "Epoch 18/28\n",
      "34/34 - 3s - 83ms/step - accuracy: 0.8669 - loss: 0.3694\n",
      "Epoch 19/28\n",
      "34/34 - 3s - 83ms/step - accuracy: 0.8614 - loss: 0.3889\n",
      "Epoch 20/28\n",
      "34/34 - 3s - 85ms/step - accuracy: 0.8715 - loss: 0.3592\n",
      "Epoch 21/28\n",
      "34/34 - 3s - 84ms/step - accuracy: 0.8620 - loss: 0.3755\n",
      "Epoch 22/28\n",
      "34/34 - 3s - 83ms/step - accuracy: 0.8626 - loss: 0.3784\n",
      "Epoch 23/28\n",
      "34/34 - 3s - 85ms/step - accuracy: 0.8792 - loss: 0.3375\n",
      "Epoch 24/28\n",
      "34/34 - 3s - 90ms/step - accuracy: 0.8812 - loss: 0.3329\n",
      "Epoch 25/28\n",
      "34/34 - 3s - 84ms/step - accuracy: 0.8775 - loss: 0.3399\n",
      "Epoch 26/28\n",
      "34/34 - 3s - 83ms/step - accuracy: 0.8844 - loss: 0.3274\n",
      "Epoch 27/28\n",
      "34/34 - 3s - 83ms/step - accuracy: 0.8754 - loss: 0.3541\n",
      "Epoch 28/28\n",
      "34/34 - 3s - 84ms/step - accuracy: 0.8826 - loss: 0.3273\n",
      "9/9 - 0s - 39ms/step\n",
      "Epoch 1/28\n",
      "34/34 - 5s - 157ms/step - accuracy: 0.6125 - loss: 1.3241\n",
      "Epoch 2/28\n",
      "34/34 - 3s - 84ms/step - accuracy: 0.7063 - loss: 0.8704\n",
      "Epoch 3/28\n",
      "34/34 - 3s - 90ms/step - accuracy: 0.7383 - loss: 0.7613\n",
      "Epoch 4/28\n",
      "34/34 - 5s - 145ms/step - accuracy: 0.7619 - loss: 0.6901\n",
      "Epoch 5/28\n",
      "34/34 - 5s - 151ms/step - accuracy: 0.7771 - loss: 0.6430\n",
      "Epoch 6/28\n",
      "34/34 - 3s - 83ms/step - accuracy: 0.7939 - loss: 0.5960\n",
      "Epoch 7/28\n",
      "34/34 - 3s - 91ms/step - accuracy: 0.7972 - loss: 0.5804\n",
      "Epoch 8/28\n",
      "34/34 - 4s - 112ms/step - accuracy: 0.8073 - loss: 0.5519\n",
      "Epoch 9/28\n",
      "34/34 - 4s - 109ms/step - accuracy: 0.8129 - loss: 0.5310\n",
      "Epoch 10/28\n",
      "34/34 - 4s - 108ms/step - accuracy: 0.8187 - loss: 0.5117\n",
      "Epoch 11/28\n",
      "34/34 - 4s - 126ms/step - accuracy: 0.8268 - loss: 0.4892\n",
      "Epoch 12/28\n",
      "34/34 - 4s - 111ms/step - accuracy: 0.8233 - loss: 0.5009\n",
      "Epoch 13/28\n",
      "34/34 - 3s - 84ms/step - accuracy: 0.8393 - loss: 0.4533\n",
      "Epoch 14/28\n",
      "34/34 - 3s - 92ms/step - accuracy: 0.8393 - loss: 0.4520\n",
      "Epoch 15/28\n",
      "34/34 - 3s - 83ms/step - accuracy: 0.8356 - loss: 0.4662\n",
      "Epoch 16/28\n",
      "34/34 - 3s - 87ms/step - accuracy: 0.8464 - loss: 0.4276\n",
      "Epoch 17/28\n",
      "34/34 - 3s - 86ms/step - accuracy: 0.8521 - loss: 0.4101\n",
      "Epoch 18/28\n",
      "34/34 - 1801s - 53s/step - accuracy: 0.8578 - loss: 0.3979\n",
      "Epoch 19/28\n",
      "34/34 - 5s - 141ms/step - accuracy: 0.8593 - loss: 0.3945\n",
      "Epoch 20/28\n",
      "34/34 - 3s - 97ms/step - accuracy: 0.8654 - loss: 0.3791\n",
      "Epoch 21/28\n",
      "34/34 - 4s - 109ms/step - accuracy: 0.8694 - loss: 0.3676\n",
      "Epoch 22/28\n",
      "34/34 - 7s - 218ms/step - accuracy: 0.8656 - loss: 0.3717\n",
      "Epoch 23/28\n",
      "34/34 - 10s - 294ms/step - accuracy: 0.8715 - loss: 0.3643\n",
      "Epoch 24/28\n",
      "34/34 - 6s - 162ms/step - accuracy: 0.8663 - loss: 0.3715\n",
      "Epoch 25/28\n",
      "34/34 - 9s - 263ms/step - accuracy: 0.8614 - loss: 0.3808\n",
      "Epoch 26/28\n",
      "34/34 - 5s - 136ms/step - accuracy: 0.8693 - loss: 0.3566\n",
      "Epoch 27/28\n",
      "34/34 - 5s - 156ms/step - accuracy: 0.8814 - loss: 0.3330\n",
      "Epoch 28/28\n",
      "34/34 - 5s - 143ms/step - accuracy: 0.8829 - loss: 0.3306\n",
      "9/9 - 1s - 71ms/step\n",
      "| \u001b[39m6        \u001b[39m | \u001b[39m0.8086   \u001b[39m | \u001b[39m3.498    \u001b[39m | \u001b[39m417.1    \u001b[39m | \u001b[39m0.8287   \u001b[39m | \u001b[39m0.107    \u001b[39m | \u001b[39m28.43    \u001b[39m | \u001b[39m2.085    \u001b[39m | \u001b[39m1.282    \u001b[39m | \u001b[39m2.604    \u001b[39m | \u001b[39m0.08381  \u001b[39m | \u001b[39m98.82    \u001b[39m | \u001b[39m0.7722   \u001b[39m | \u001b[39m1.391    \u001b[39m |\n",
      "Epoch 1/43\n",
      "17/17 - 3s - 178ms/step - accuracy: 0.5751 - loss: 1.9124\n",
      "Epoch 2/43\n",
      "17/17 - 2s - 116ms/step - accuracy: 0.6402 - loss: 1.1565\n",
      "Epoch 3/43\n",
      "17/17 - 2s - 129ms/step - accuracy: 0.6490 - loss: 1.0903\n",
      "Epoch 4/43\n",
      "17/17 - 2s - 99ms/step - accuracy: 0.6470 - loss: 1.0655\n",
      "Epoch 5/43\n",
      "17/17 - 2s - 100ms/step - accuracy: 0.6555 - loss: 1.0399\n",
      "Epoch 6/43\n",
      "17/17 - 2s - 101ms/step - accuracy: 0.6614 - loss: 1.0138\n",
      "Epoch 7/43\n",
      "17/17 - 2s - 100ms/step - accuracy: 0.6682 - loss: 0.9941\n",
      "Epoch 8/43\n",
      "17/17 - 2s - 96ms/step - accuracy: 0.6685 - loss: 0.9807\n",
      "Epoch 9/43\n",
      "17/17 - 2s - 100ms/step - accuracy: 0.6738 - loss: 0.9657\n",
      "Epoch 10/43\n",
      "17/17 - 2s - 106ms/step - accuracy: 0.6792 - loss: 0.9563\n",
      "Epoch 11/43\n",
      "17/17 - 2s - 125ms/step - accuracy: 0.6820 - loss: 0.9411\n",
      "Epoch 12/43\n",
      "17/17 - 2s - 105ms/step - accuracy: 0.6817 - loss: 0.9308\n",
      "Epoch 13/43\n",
      "17/17 - 2s - 99ms/step - accuracy: 0.6868 - loss: 0.9235\n",
      "Epoch 14/43\n",
      "17/17 - 2s - 98ms/step - accuracy: 0.6866 - loss: 0.9166\n",
      "Epoch 15/43\n",
      "17/17 - 2s - 95ms/step - accuracy: 0.6907 - loss: 0.9111\n",
      "Epoch 16/43\n",
      "17/17 - 2s - 101ms/step - accuracy: 0.6939 - loss: 0.9019\n",
      "Epoch 17/43\n",
      "17/17 - 2s - 100ms/step - accuracy: 0.6964 - loss: 0.8977\n",
      "Epoch 18/43\n",
      "17/17 - 2s - 100ms/step - accuracy: 0.6977 - loss: 0.8881\n",
      "Epoch 19/43\n",
      "17/17 - 2s - 96ms/step - accuracy: 0.6977 - loss: 0.8891\n",
      "Epoch 20/43\n",
      "17/17 - 2s - 111ms/step - accuracy: 0.6990 - loss: 0.8808\n",
      "Epoch 21/43\n",
      "17/17 - 2s - 105ms/step - accuracy: 0.7007 - loss: 0.8738\n",
      "Epoch 22/43\n",
      "17/17 - 2s - 95ms/step - accuracy: 0.7008 - loss: 0.8679\n",
      "Epoch 23/43\n",
      "17/17 - 2s - 97ms/step - accuracy: 0.7047 - loss: 0.8623\n",
      "Epoch 24/43\n",
      "17/17 - 2s - 103ms/step - accuracy: 0.7020 - loss: 0.8608\n",
      "Epoch 25/43\n",
      "17/17 - 2s - 100ms/step - accuracy: 0.7080 - loss: 0.8537\n",
      "Epoch 26/43\n",
      "17/17 - 2s - 100ms/step - accuracy: 0.7073 - loss: 0.8495\n",
      "Epoch 27/43\n",
      "17/17 - 2s - 99ms/step - accuracy: 0.7072 - loss: 0.8489\n",
      "Epoch 28/43\n",
      "17/17 - 2s - 99ms/step - accuracy: 0.7091 - loss: 0.8479\n",
      "Epoch 29/43\n",
      "17/17 - 2s - 112ms/step - accuracy: 0.7133 - loss: 0.8407\n",
      "Epoch 30/43\n",
      "17/17 - 2s - 122ms/step - accuracy: 0.7133 - loss: 0.8425\n",
      "Epoch 31/43\n",
      "17/17 - 2s - 102ms/step - accuracy: 0.7136 - loss: 0.8355\n",
      "Epoch 32/43\n",
      "17/17 - 2s - 101ms/step - accuracy: 0.7128 - loss: 0.8300\n",
      "Epoch 33/43\n",
      "17/17 - 2s - 101ms/step - accuracy: 0.7133 - loss: 0.8332\n",
      "Epoch 34/43\n",
      "17/17 - 2s - 99ms/step - accuracy: 0.7133 - loss: 0.8284\n",
      "Epoch 35/43\n",
      "17/17 - 2s - 99ms/step - accuracy: 0.7163 - loss: 0.8252\n",
      "Epoch 36/43\n",
      "17/17 - 2s - 93ms/step - accuracy: 0.7160 - loss: 0.8239\n",
      "Epoch 37/43\n",
      "17/17 - 2s - 96ms/step - accuracy: 0.7174 - loss: 0.8159\n",
      "Epoch 38/43\n",
      "17/17 - 2s - 110ms/step - accuracy: 0.7194 - loss: 0.8134\n",
      "Epoch 39/43\n",
      "17/17 - 2s - 119ms/step - accuracy: 0.7186 - loss: 0.8189\n",
      "Epoch 40/43\n",
      "17/17 - 2s - 104ms/step - accuracy: 0.7185 - loss: 0.8135\n",
      "Epoch 41/43\n",
      "17/17 - 2s - 97ms/step - accuracy: 0.7202 - loss: 0.8123\n",
      "Epoch 42/43\n",
      "17/17 - 2s - 100ms/step - accuracy: 0.7183 - loss: 0.8116\n",
      "Epoch 43/43\n",
      "17/17 - 2s - 97ms/step - accuracy: 0.7243 - loss: 0.8050\n",
      "5/5 - 0s - 78ms/step\n",
      "Epoch 1/43\n",
      "17/17 - 3s - 175ms/step - accuracy: 0.5625 - loss: 1.6006\n",
      "Epoch 2/43\n",
      "17/17 - 2s - 93ms/step - accuracy: 0.6265 - loss: 1.1502\n",
      "Epoch 3/43\n",
      "17/17 - 2s - 97ms/step - accuracy: 0.6359 - loss: 1.0853\n",
      "Epoch 4/43\n",
      "17/17 - 2s - 120ms/step - accuracy: 0.6476 - loss: 1.0490\n",
      "Epoch 5/43\n",
      "17/17 - 2s - 109ms/step - accuracy: 0.6524 - loss: 1.0182\n",
      "Epoch 6/43\n",
      "17/17 - 2s - 98ms/step - accuracy: 0.6578 - loss: 0.9992\n",
      "Epoch 7/43\n",
      "17/17 - 2s - 99ms/step - accuracy: 0.6622 - loss: 0.9788\n",
      "Epoch 8/43\n",
      "17/17 - 2s - 100ms/step - accuracy: 0.6688 - loss: 0.9585\n",
      "Epoch 9/43\n",
      "17/17 - 2s - 98ms/step - accuracy: 0.6724 - loss: 0.9504\n",
      "Epoch 10/43\n",
      "17/17 - 2s - 101ms/step - accuracy: 0.6743 - loss: 0.9333\n",
      "Epoch 11/43\n",
      "17/17 - 2s - 103ms/step - accuracy: 0.6840 - loss: 0.9203\n",
      "Epoch 12/43\n",
      "17/17 - 2s - 108ms/step - accuracy: 0.6817 - loss: 0.9180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/43\n",
      "17/17 - 2s - 112ms/step - accuracy: 0.6821 - loss: 0.9115\n",
      "Epoch 14/43\n",
      "17/17 - 2s - 100ms/step - accuracy: 0.6883 - loss: 0.9065\n",
      "Epoch 15/43\n",
      "17/17 - 2s - 96ms/step - accuracy: 0.6902 - loss: 0.8889\n",
      "Epoch 16/43\n",
      "17/17 - 2s - 100ms/step - accuracy: 0.6947 - loss: 0.8865\n",
      "Epoch 17/43\n",
      "17/17 - 2s - 102ms/step - accuracy: 0.6943 - loss: 0.8786\n",
      "Epoch 18/43\n",
      "17/17 - 2s - 100ms/step - accuracy: 0.6972 - loss: 0.8736\n",
      "Epoch 19/43\n",
      "17/17 - 2s - 99ms/step - accuracy: 0.7049 - loss: 0.8634\n",
      "Epoch 20/43\n",
      "17/17 - 2s - 98ms/step - accuracy: 0.7020 - loss: 0.8638\n",
      "Epoch 21/43\n",
      "17/17 - 2s - 104ms/step - accuracy: 0.7011 - loss: 0.8626\n",
      "Epoch 22/43\n",
      "17/17 - 2s - 119ms/step - accuracy: 0.7029 - loss: 0.8546\n",
      "Epoch 23/43\n",
      "17/17 - 2s - 112ms/step - accuracy: 0.7091 - loss: 0.8528\n",
      "Epoch 24/43\n",
      "17/17 - 2s - 98ms/step - accuracy: 0.7101 - loss: 0.8495\n",
      "Epoch 25/43\n",
      "17/17 - 2s - 103ms/step - accuracy: 0.7072 - loss: 0.8448\n",
      "Epoch 26/43\n",
      "17/17 - 2s - 96ms/step - accuracy: 0.7081 - loss: 0.8394\n",
      "Epoch 27/43\n",
      "17/17 - 3s - 149ms/step - accuracy: 0.7125 - loss: 0.8334\n",
      "Epoch 28/43\n",
      "17/17 - 2s - 94ms/step - accuracy: 0.7112 - loss: 0.8378\n",
      "Epoch 29/43\n",
      "17/17 - 2s - 145ms/step - accuracy: 0.7196 - loss: 0.8276\n",
      "Epoch 30/43\n",
      "17/17 - 2s - 114ms/step - accuracy: 0.7154 - loss: 0.8289\n",
      "Epoch 31/43\n",
      "17/17 - 2s - 106ms/step - accuracy: 0.7176 - loss: 0.8250\n",
      "Epoch 32/43\n",
      "17/17 - 2s - 94ms/step - accuracy: 0.7145 - loss: 0.8230\n",
      "Epoch 33/43\n",
      "17/17 - 2s - 91ms/step - accuracy: 0.7197 - loss: 0.8181\n",
      "Epoch 34/43\n",
      "17/17 - 2s - 99ms/step - accuracy: 0.7175 - loss: 0.8182\n",
      "Epoch 35/43\n",
      "17/17 - 2s - 99ms/step - accuracy: 0.7192 - loss: 0.8171\n",
      "Epoch 36/43\n",
      "17/17 - 2s - 102ms/step - accuracy: 0.7200 - loss: 0.8114\n",
      "Epoch 37/43\n",
      "17/17 - 2s - 101ms/step - accuracy: 0.7207 - loss: 0.8144\n",
      "Epoch 38/43\n",
      "17/17 - 3s - 147ms/step - accuracy: 0.7225 - loss: 0.8121\n",
      "Epoch 39/43\n",
      "17/17 - 2s - 121ms/step - accuracy: 0.7234 - loss: 0.8042\n",
      "Epoch 40/43\n",
      "17/17 - 2s - 115ms/step - accuracy: 0.7219 - loss: 0.8068\n",
      "Epoch 41/43\n",
      "17/17 - 2s - 98ms/step - accuracy: 0.7254 - loss: 0.8029\n",
      "Epoch 42/43\n",
      "17/17 - 2s - 101ms/step - accuracy: 0.7236 - loss: 0.7999\n",
      "Epoch 43/43\n",
      "17/17 - 2s - 96ms/step - accuracy: 0.7237 - loss: 0.8026\n",
      "5/5 - 0s - 77ms/step\n",
      "Epoch 1/43\n",
      "17/17 - 3s - 170ms/step - accuracy: 0.5733 - loss: 1.6438\n",
      "Epoch 2/43\n",
      "17/17 - 2s - 93ms/step - accuracy: 0.6381 - loss: 1.1582\n",
      "Epoch 3/43\n",
      "17/17 - 2s - 96ms/step - accuracy: 0.6458 - loss: 1.0937\n",
      "Epoch 4/43\n",
      "17/17 - 2s - 113ms/step - accuracy: 0.6530 - loss: 1.0617\n",
      "Epoch 5/43\n",
      "17/17 - 2s - 115ms/step - accuracy: 0.6578 - loss: 1.0325\n",
      "Epoch 6/43\n",
      "17/17 - 2s - 96ms/step - accuracy: 0.6603 - loss: 1.0167\n",
      "Epoch 7/43\n",
      "17/17 - 2s - 99ms/step - accuracy: 0.6641 - loss: 0.9968\n",
      "Epoch 8/43\n",
      "17/17 - 2s - 98ms/step - accuracy: 0.6728 - loss: 0.9784\n",
      "Epoch 9/43\n",
      "17/17 - 2s - 103ms/step - accuracy: 0.6666 - loss: 0.9725\n",
      "Epoch 10/43\n",
      "17/17 - 2s - 102ms/step - accuracy: 0.6755 - loss: 0.9598\n",
      "Epoch 11/43\n",
      "17/17 - 2s - 103ms/step - accuracy: 0.6790 - loss: 0.9494\n",
      "Epoch 12/43\n",
      "17/17 - 2s - 107ms/step - accuracy: 0.6780 - loss: 0.9344\n",
      "Epoch 13/43\n",
      "17/17 - 2s - 127ms/step - accuracy: 0.6799 - loss: 0.9282\n",
      "Epoch 14/43\n",
      "17/17 - 3s - 154ms/step - accuracy: 0.6845 - loss: 0.9222\n",
      "Epoch 15/43\n",
      "17/17 - 2s - 143ms/step - accuracy: 0.6890 - loss: 0.9120\n",
      "Epoch 16/43\n",
      "17/17 - 2s - 114ms/step - accuracy: 0.6869 - loss: 0.9100\n",
      "Epoch 17/43\n",
      "17/17 - 2s - 99ms/step - accuracy: 0.6909 - loss: 0.8974\n",
      "Epoch 18/43\n",
      "17/17 - 2s - 111ms/step - accuracy: 0.6919 - loss: 0.8968\n",
      "Epoch 19/43\n",
      "17/17 - 2s - 103ms/step - accuracy: 0.6964 - loss: 0.8900\n",
      "Epoch 20/43\n",
      "17/17 - 2s - 105ms/step - accuracy: 0.6996 - loss: 0.8803\n",
      "Epoch 21/43\n",
      "17/17 - 2s - 124ms/step - accuracy: 0.7004 - loss: 0.8816\n",
      "Epoch 22/43\n",
      "17/17 - 2s - 116ms/step - accuracy: 0.7023 - loss: 0.8757\n",
      "Epoch 23/43\n",
      "17/17 - 2s - 103ms/step - accuracy: 0.7026 - loss: 0.8691\n",
      "Epoch 24/43\n",
      "17/17 - 2s - 102ms/step - accuracy: 0.7029 - loss: 0.8636\n",
      "Epoch 25/43\n",
      "17/17 - 2s - 97ms/step - accuracy: 0.7049 - loss: 0.8620\n",
      "Epoch 26/43\n",
      "17/17 - 2s - 102ms/step - accuracy: 0.7058 - loss: 0.8550\n",
      "Epoch 27/43\n",
      "17/17 - 2s - 100ms/step - accuracy: 0.7086 - loss: 0.8528\n",
      "Epoch 28/43\n",
      "17/17 - 904s - 53s/step - accuracy: 0.7134 - loss: 0.8463\n",
      "Epoch 29/43\n",
      "17/17 - 3s - 190ms/step - accuracy: 0.7073 - loss: 0.8508\n",
      "Epoch 30/43\n",
      "17/17 - 1s - 86ms/step - accuracy: 0.7107 - loss: 0.8451\n",
      "Epoch 31/43\n",
      "17/17 - 1s - 79ms/step - accuracy: 0.7120 - loss: 0.8432\n",
      "Epoch 32/43\n",
      "17/17 - 2s - 132ms/step - accuracy: 0.7115 - loss: 0.8423\n",
      "Epoch 33/43\n",
      "17/17 - 1s - 62ms/step - accuracy: 0.7120 - loss: 0.8370\n",
      "Epoch 34/43\n",
      "17/17 - 1s - 60ms/step - accuracy: 0.7166 - loss: 0.8351\n",
      "Epoch 35/43\n",
      "17/17 - 1s - 65ms/step - accuracy: 0.7146 - loss: 0.8310\n",
      "Epoch 36/43\n",
      "17/17 - 1s - 61ms/step - accuracy: 0.7137 - loss: 0.8326\n",
      "Epoch 37/43\n",
      "17/17 - 1s - 79ms/step - accuracy: 0.7174 - loss: 0.8223\n",
      "Epoch 38/43\n",
      "17/17 - 1s - 76ms/step - accuracy: 0.7200 - loss: 0.8238\n",
      "Epoch 39/43\n",
      "17/17 - 2s - 89ms/step - accuracy: 0.7179 - loss: 0.8207\n",
      "Epoch 40/43\n",
      "17/17 - 2s - 118ms/step - accuracy: 0.7190 - loss: 0.8179\n",
      "Epoch 41/43\n",
      "17/17 - 2s - 113ms/step - accuracy: 0.7216 - loss: 0.8173\n",
      "Epoch 42/43\n",
      "17/17 - 2s - 115ms/step - accuracy: 0.7221 - loss: 0.8199\n",
      "Epoch 43/43\n",
      "17/17 - 2s - 100ms/step - accuracy: 0.7246 - loss: 0.8114\n",
      "5/5 - 1s - 122ms/step\n",
      "Epoch 1/43\n",
      "17/17 - 3s - 172ms/step - accuracy: 0.5864 - loss: 1.5082\n",
      "Epoch 2/43\n",
      "17/17 - 2s - 90ms/step - accuracy: 0.6366 - loss: 1.1436\n",
      "Epoch 3/43\n",
      "17/17 - 2s - 94ms/step - accuracy: 0.6522 - loss: 1.0858\n",
      "Epoch 4/43\n",
      "17/17 - 1s - 83ms/step - accuracy: 0.6492 - loss: 1.0612\n",
      "Epoch 5/43\n",
      "17/17 - 2s - 97ms/step - accuracy: 0.6579 - loss: 1.0371\n",
      "Epoch 6/43\n",
      "17/17 - 2s - 128ms/step - accuracy: 0.6605 - loss: 1.0274\n",
      "Epoch 7/43\n",
      "17/17 - 1s - 71ms/step - accuracy: 0.6633 - loss: 1.0131\n",
      "Epoch 8/43\n",
      "17/17 - 1s - 72ms/step - accuracy: 0.6644 - loss: 1.0049\n",
      "Epoch 9/43\n",
      "17/17 - 1s - 75ms/step - accuracy: 0.6727 - loss: 0.9862\n",
      "Epoch 10/43\n",
      "17/17 - 1s - 71ms/step - accuracy: 0.6752 - loss: 0.9761\n",
      "Epoch 11/43\n",
      "17/17 - 1s - 78ms/step - accuracy: 0.6779 - loss: 0.9600\n",
      "Epoch 12/43\n",
      "17/17 - 1s - 71ms/step - accuracy: 0.6786 - loss: 0.9516\n",
      "Epoch 13/43\n",
      "17/17 - 1s - 72ms/step - accuracy: 0.6803 - loss: 0.9424\n",
      "Epoch 14/43\n",
      "17/17 - 1s - 73ms/step - accuracy: 0.6829 - loss: 0.9314\n",
      "Epoch 15/43\n",
      "17/17 - 1s - 77ms/step - accuracy: 0.6906 - loss: 0.9241\n",
      "Epoch 16/43\n",
      "17/17 - 1058s - 62s/step - accuracy: 0.6882 - loss: 0.9179\n",
      "Epoch 17/43\n",
      "17/17 - 2s - 120ms/step - accuracy: 0.6898 - loss: 0.9128\n",
      "Epoch 18/43\n",
      "17/17 - 2s - 102ms/step - accuracy: 0.6975 - loss: 0.8994\n",
      "Epoch 19/43\n",
      "17/17 - 2s - 110ms/step - accuracy: 0.6972 - loss: 0.8892\n",
      "Epoch 20/43\n",
      "17/17 - 1s - 71ms/step - accuracy: 0.7009 - loss: 0.8816\n",
      "Epoch 21/43\n",
      "17/17 - 1s - 72ms/step - accuracy: 0.7007 - loss: 0.8825\n",
      "Epoch 22/43\n",
      "17/17 - 1s - 54ms/step - accuracy: 0.7065 - loss: 0.8682\n",
      "Epoch 23/43\n",
      "17/17 - 1s - 53ms/step - accuracy: 0.7049 - loss: 0.8669\n",
      "Epoch 24/43\n",
      "17/17 - 1s - 53ms/step - accuracy: 0.7096 - loss: 0.8564\n",
      "Epoch 25/43\n",
      "17/17 - 1s - 62ms/step - accuracy: 0.7141 - loss: 0.8529\n",
      "Epoch 26/43\n",
      "17/17 - 1s - 66ms/step - accuracy: 0.7105 - loss: 0.8500\n",
      "Epoch 27/43\n",
      "17/17 - 2s - 88ms/step - accuracy: 0.7155 - loss: 0.8430\n",
      "Epoch 28/43\n",
      "17/17 - 1s - 84ms/step - accuracy: 0.7174 - loss: 0.8372\n",
      "Epoch 29/43\n",
      "17/17 - 1s - 73ms/step - accuracy: 0.7132 - loss: 0.8376\n",
      "Epoch 30/43\n",
      "17/17 - 1s - 76ms/step - accuracy: 0.7168 - loss: 0.8336\n",
      "Epoch 31/43\n",
      "17/17 - 1s - 83ms/step - accuracy: 0.7177 - loss: 0.8300\n",
      "Epoch 32/43\n",
      "17/17 - 1s - 76ms/step - accuracy: 0.7209 - loss: 0.8230\n",
      "Epoch 33/43\n",
      "17/17 - 1s - 77ms/step - accuracy: 0.7191 - loss: 0.8245\n",
      "Epoch 34/43\n",
      "17/17 - 1s - 77ms/step - accuracy: 0.7210 - loss: 0.8213\n",
      "Epoch 35/43\n",
      "17/17 - 1s - 77ms/step - accuracy: 0.7206 - loss: 0.8146\n",
      "Epoch 36/43\n",
      "17/17 - 1s - 74ms/step - accuracy: 0.7240 - loss: 0.8143\n",
      "Epoch 37/43\n",
      "17/17 - 1s - 75ms/step - accuracy: 0.7245 - loss: 0.8105\n",
      "Epoch 38/43\n",
      "17/17 - 1s - 74ms/step - accuracy: 0.7230 - loss: 0.8100\n",
      "Epoch 39/43\n",
      "17/17 - 2s - 89ms/step - accuracy: 0.7294 - loss: 0.8054\n",
      "Epoch 40/43\n",
      "17/17 - 2s - 130ms/step - accuracy: 0.7277 - loss: 0.8054\n",
      "Epoch 41/43\n",
      "17/17 - 1s - 70ms/step - accuracy: 0.7266 - loss: 0.8069\n",
      "Epoch 42/43\n",
      "17/17 - 1s - 72ms/step - accuracy: 0.7322 - loss: 0.7962\n",
      "Epoch 43/43\n",
      "17/17 - 1s - 74ms/step - accuracy: 0.7286 - loss: 0.7980\n",
      "5/5 - 0s - 57ms/step\n",
      "Epoch 1/43\n",
      "17/17 - 2s - 124ms/step - accuracy: 0.5617 - loss: 1.7110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/43\n",
      "17/17 - 1s - 74ms/step - accuracy: 0.6528 - loss: 1.1238\n",
      "Epoch 3/43\n",
      "17/17 - 1s - 69ms/step - accuracy: 0.6545 - loss: 1.0751\n",
      "Epoch 4/43\n",
      "17/17 - 1s - 71ms/step - accuracy: 0.6593 - loss: 1.0462\n",
      "Epoch 5/43\n",
      "17/17 - 1s - 69ms/step - accuracy: 0.6631 - loss: 1.0254\n",
      "Epoch 6/43\n",
      "17/17 - 1s - 72ms/step - accuracy: 0.6670 - loss: 1.0036\n",
      "Epoch 7/43\n",
      "17/17 - 907s - 53s/step - accuracy: 0.6693 - loss: 0.9865\n",
      "Epoch 8/43\n",
      "17/17 - 2s - 144ms/step - accuracy: 0.6702 - loss: 0.9773\n",
      "Epoch 9/43\n",
      "17/17 - 1s - 87ms/step - accuracy: 0.6741 - loss: 0.9529\n",
      "Epoch 10/43\n",
      "17/17 - 1s - 79ms/step - accuracy: 0.6743 - loss: 0.9499\n",
      "Epoch 11/43\n",
      "17/17 - 1s - 61ms/step - accuracy: 0.6807 - loss: 0.9344\n",
      "Epoch 12/43\n",
      "17/17 - 1s - 55ms/step - accuracy: 0.6838 - loss: 0.9252\n",
      "Epoch 13/43\n",
      "17/17 - 1s - 53ms/step - accuracy: 0.6798 - loss: 0.9177\n",
      "Epoch 14/43\n",
      "17/17 - 1s - 54ms/step - accuracy: 0.6874 - loss: 0.9048\n",
      "Epoch 15/43\n",
      "17/17 - 1s - 52ms/step - accuracy: 0.6935 - loss: 0.8949\n",
      "Epoch 16/43\n",
      "17/17 - 1s - 53ms/step - accuracy: 0.6937 - loss: 0.8864\n",
      "Epoch 17/43\n",
      "17/17 - 1s - 53ms/step - accuracy: 0.6871 - loss: 0.8972\n",
      "Epoch 18/43\n",
      "17/17 - 1s - 56ms/step - accuracy: 0.7018 - loss: 0.8748\n",
      "Epoch 19/43\n",
      "17/17 - 1s - 73ms/step - accuracy: 0.6981 - loss: 0.8814\n",
      "Epoch 20/43\n",
      "17/17 - 2s - 90ms/step - accuracy: 0.7028 - loss: 0.8686\n",
      "Epoch 21/43\n",
      "17/17 - 1s - 80ms/step - accuracy: 0.7014 - loss: 0.8666\n",
      "Epoch 22/43\n",
      "17/17 - 1s - 76ms/step - accuracy: 0.7038 - loss: 0.8599\n",
      "Epoch 23/43\n",
      "17/17 - 1s - 78ms/step - accuracy: 0.7026 - loss: 0.8556\n",
      "Epoch 24/43\n",
      "17/17 - 2s - 143ms/step - accuracy: 0.7061 - loss: 0.8539\n",
      "Epoch 25/43\n",
      "17/17 - 1s - 69ms/step - accuracy: 0.7062 - loss: 0.8507\n",
      "Epoch 26/43\n",
      "17/17 - 1s - 77ms/step - accuracy: 0.7044 - loss: 0.8440\n",
      "Epoch 27/43\n",
      "17/17 - 1s - 69ms/step - accuracy: 0.7083 - loss: 0.8459\n",
      "Epoch 28/43\n",
      "17/17 - 1s - 70ms/step - accuracy: 0.7126 - loss: 0.8432\n",
      "Epoch 29/43\n",
      "17/17 - 1s - 69ms/step - accuracy: 0.7085 - loss: 0.8418\n",
      "Epoch 30/43\n",
      "17/17 - 1s - 75ms/step - accuracy: 0.7121 - loss: 0.8318\n",
      "Epoch 31/43\n",
      "17/17 - 1s - 83ms/step - accuracy: 0.7106 - loss: 0.8359\n",
      "Epoch 32/43\n",
      "17/17 - 1s - 88ms/step - accuracy: 0.7135 - loss: 0.8318\n",
      "Epoch 33/43\n",
      "17/17 - 1s - 74ms/step - accuracy: 0.7149 - loss: 0.8262\n",
      "Epoch 34/43\n",
      "17/17 - 1s - 77ms/step - accuracy: 0.7121 - loss: 0.8276\n",
      "Epoch 35/43\n",
      "17/17 - 1s - 82ms/step - accuracy: 0.7142 - loss: 0.8182\n",
      "Epoch 36/43\n",
      "17/17 - 1s - 74ms/step - accuracy: 0.7161 - loss: 0.8169\n",
      "Epoch 37/43\n",
      "17/17 - 1s - 75ms/step - accuracy: 0.7176 - loss: 0.8141\n",
      "Epoch 38/43\n",
      "17/17 - 1s - 74ms/step - accuracy: 0.7184 - loss: 0.8107\n",
      "Epoch 39/43\n",
      "17/17 - 1s - 75ms/step - accuracy: 0.7211 - loss: 0.8138\n",
      "Epoch 40/43\n",
      "17/17 - 1s - 75ms/step - accuracy: 0.7174 - loss: 0.8086\n",
      "Epoch 41/43\n",
      "17/17 - 1s - 74ms/step - accuracy: 0.7192 - loss: 0.8074\n",
      "Epoch 42/43\n",
      "17/17 - 1s - 73ms/step - accuracy: 0.7171 - loss: 0.8128\n",
      "Epoch 43/43\n",
      "17/17 - 2s - 94ms/step - accuracy: 0.7225 - loss: 0.8043\n",
      "5/5 - 0s - 81ms/step\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39m0.7333   \u001b[39m | \u001b[39m0.0497   \u001b[39m | \u001b[39m852.4    \u001b[39m | \u001b[39m0.7069   \u001b[39m | \u001b[39m0.2187   \u001b[39m | \u001b[39m43.14    \u001b[39m | \u001b[39m1.148    \u001b[39m | \u001b[39m1.717    \u001b[39m | \u001b[39m1.232    \u001b[39m | \u001b[39m0.8645   \u001b[39m | \u001b[39m66.1     \u001b[39m | \u001b[39m0.3309   \u001b[39m | \u001b[39m0.4449   \u001b[39m |\n",
      "Epoch 1/47\n",
      "30/30 - 5s - 182ms/step - accuracy: 0.0631 - loss: 2.8598\n",
      "Epoch 2/47\n",
      "30/30 - 2s - 51ms/step - accuracy: 0.0625 - loss: 2.8548\n",
      "Epoch 3/47\n",
      "30/30 - 1s - 48ms/step - accuracy: 0.0631 - loss: 2.8469\n",
      "Epoch 4/47\n",
      "30/30 - 1s - 47ms/step - accuracy: 0.0667 - loss: 2.8393\n",
      "Epoch 5/47\n",
      "30/30 - 2s - 82ms/step - accuracy: 0.0661 - loss: 2.8327\n",
      "Epoch 6/47\n",
      "30/30 - 2s - 50ms/step - accuracy: 0.0680 - loss: 2.8251\n",
      "Epoch 7/47\n",
      "30/30 - 2s - 56ms/step - accuracy: 0.0714 - loss: 2.8179\n",
      "Epoch 8/47\n",
      "30/30 - 2s - 50ms/step - accuracy: 0.0730 - loss: 2.8107\n",
      "Epoch 9/47\n",
      "30/30 - 2s - 52ms/step - accuracy: 0.0768 - loss: 2.8016\n",
      "Epoch 10/47\n",
      "30/30 - 2s - 52ms/step - accuracy: 0.0786 - loss: 2.7935\n",
      "Epoch 11/47\n",
      "30/30 - 3s - 83ms/step - accuracy: 0.0776 - loss: 2.7850\n",
      "Epoch 12/47\n",
      "30/30 - 2s - 50ms/step - accuracy: 0.0791 - loss: 2.7774\n",
      "Epoch 13/47\n",
      "30/30 - 1s - 50ms/step - accuracy: 0.0845 - loss: 2.7705\n",
      "Epoch 14/47\n",
      "30/30 - 1s - 50ms/step - accuracy: 0.0850 - loss: 2.7613\n",
      "Epoch 15/47\n",
      "30/30 - 2s - 50ms/step - accuracy: 0.0882 - loss: 2.7538\n",
      "Epoch 16/47\n",
      "30/30 - 2s - 61ms/step - accuracy: 0.0903 - loss: 2.7437\n",
      "Epoch 17/47\n",
      "30/30 - 2s - 57ms/step - accuracy: 0.0927 - loss: 2.7373\n",
      "Epoch 18/47\n",
      "30/30 - 2s - 53ms/step - accuracy: 0.0945 - loss: 2.7289\n",
      "Epoch 19/47\n",
      "30/30 - 2s - 52ms/step - accuracy: 0.0996 - loss: 2.7193\n",
      "Epoch 20/47\n",
      "30/30 - 2s - 52ms/step - accuracy: 0.1079 - loss: 2.7076\n",
      "Epoch 21/47\n",
      "30/30 - 2s - 52ms/step - accuracy: 0.1097 - loss: 2.7002\n",
      "Epoch 22/47\n",
      "30/30 - 2s - 51ms/step - accuracy: 0.1129 - loss: 2.6913\n",
      "Epoch 23/47\n",
      "30/30 - 2s - 52ms/step - accuracy: 0.1193 - loss: 2.6828\n",
      "Epoch 24/47\n",
      "30/30 - 2s - 52ms/step - accuracy: 0.1264 - loss: 2.6701\n",
      "Epoch 25/47\n",
      "30/30 - 2s - 52ms/step - accuracy: 0.1262 - loss: 2.6638\n",
      "Epoch 26/47\n",
      "30/30 - 2s - 67ms/step - accuracy: 0.1352 - loss: 2.6533\n",
      "Epoch 27/47\n",
      "30/30 - 2s - 58ms/step - accuracy: 0.1392 - loss: 2.6451\n",
      "Epoch 28/47\n",
      "30/30 - 2s - 54ms/step - accuracy: 0.1479 - loss: 2.6319\n",
      "Epoch 29/47\n",
      "30/30 - 2s - 54ms/step - accuracy: 0.1561 - loss: 2.6239\n",
      "Epoch 30/47\n",
      "30/30 - 2s - 54ms/step - accuracy: 0.1599 - loss: 2.6154\n",
      "Epoch 31/47\n",
      "30/30 - 2s - 54ms/step - accuracy: 0.1721 - loss: 2.6038\n",
      "Epoch 32/47\n",
      "30/30 - 2s - 53ms/step - accuracy: 0.1770 - loss: 2.5927\n",
      "Epoch 33/47\n",
      "30/30 - 2s - 52ms/step - accuracy: 0.1854 - loss: 2.5841\n",
      "Epoch 34/47\n",
      "30/30 - 2s - 52ms/step - accuracy: 0.1927 - loss: 2.5749\n",
      "Epoch 35/47\n",
      "30/30 - 2s - 80ms/step - accuracy: 0.1999 - loss: 2.5650\n",
      "Epoch 36/47\n",
      "30/30 - 2s - 61ms/step - accuracy: 0.2097 - loss: 2.5547\n",
      "Epoch 37/47\n",
      "30/30 - 2s - 55ms/step - accuracy: 0.2215 - loss: 2.5428\n",
      "Epoch 38/47\n",
      "30/30 - 2s - 78ms/step - accuracy: 0.2311 - loss: 2.5317\n",
      "Epoch 39/47\n",
      "30/30 - 1s - 48ms/step - accuracy: 0.2400 - loss: 2.5225\n",
      "Epoch 40/47\n",
      "30/30 - 2s - 82ms/step - accuracy: 0.2535 - loss: 2.5125\n",
      "Epoch 41/47\n",
      "30/30 - 2s - 82ms/step - accuracy: 0.2652 - loss: 2.5023\n",
      "Epoch 42/47\n",
      "30/30 - 1s - 44ms/step - accuracy: 0.2774 - loss: 2.4912\n",
      "Epoch 43/47\n",
      "30/30 - 3s - 83ms/step - accuracy: 0.2853 - loss: 2.4780\n",
      "Epoch 44/47\n",
      "30/30 - 2s - 54ms/step - accuracy: 0.2966 - loss: 2.4696\n",
      "Epoch 45/47\n",
      "30/30 - 2s - 50ms/step - accuracy: 0.3140 - loss: 2.4588\n",
      "Epoch 46/47\n",
      "30/30 - 1s - 49ms/step - accuracy: 0.3201 - loss: 2.4479\n",
      "Epoch 47/47\n",
      "30/30 - 2s - 50ms/step - accuracy: 0.3397 - loss: 2.4346\n",
      "8/8 - 0s - 42ms/step\n",
      "Epoch 1/47\n",
      "30/30 - 4s - 126ms/step - accuracy: 0.0275 - loss: 2.6733\n",
      "Epoch 2/47\n",
      "30/30 - 1s - 48ms/step - accuracy: 0.0317 - loss: 2.6668\n",
      "Epoch 3/47\n",
      "30/30 - 1s - 49ms/step - accuracy: 0.0352 - loss: 2.6597\n",
      "Epoch 4/47\n",
      "30/30 - 2s - 52ms/step - accuracy: 0.0383 - loss: 2.6550\n",
      "Epoch 5/47\n",
      "30/30 - 2s - 67ms/step - accuracy: 0.0458 - loss: 2.6463\n",
      "Epoch 6/47\n",
      "30/30 - 2s - 54ms/step - accuracy: 0.0476 - loss: 2.6392\n",
      "Epoch 7/47\n",
      "30/30 - 2s - 52ms/step - accuracy: 0.0564 - loss: 2.6316\n",
      "Epoch 8/47\n",
      "30/30 - 2s - 53ms/step - accuracy: 0.0559 - loss: 2.6256\n",
      "Epoch 9/47\n",
      "30/30 - 2s - 54ms/step - accuracy: 0.0617 - loss: 2.6154\n",
      "Epoch 10/47\n",
      "30/30 - 2s - 80ms/step - accuracy: 0.0667 - loss: 2.6110\n",
      "Epoch 11/47\n",
      "30/30 - 1s - 49ms/step - accuracy: 0.0723 - loss: 2.6011\n",
      "Epoch 12/47\n",
      "30/30 - 1s - 50ms/step - accuracy: 0.0789 - loss: 2.5960\n",
      "Epoch 13/47\n",
      "30/30 - 2s - 51ms/step - accuracy: 0.0881 - loss: 2.5859\n",
      "Epoch 14/47\n",
      "30/30 - 3s - 91ms/step - accuracy: 0.0905 - loss: 2.5797\n",
      "Epoch 15/47\n",
      "30/30 - 1s - 50ms/step - accuracy: 0.1039 - loss: 2.5700\n",
      "Epoch 16/47\n",
      "30/30 - 2s - 82ms/step - accuracy: 0.1089 - loss: 2.5631\n",
      "Epoch 17/47\n",
      "30/30 - 1s - 47ms/step - accuracy: 0.1208 - loss: 2.5534\n",
      "Epoch 18/47\n",
      "30/30 - 2s - 81ms/step - accuracy: 0.1275 - loss: 2.5457\n",
      "Epoch 19/47\n",
      "30/30 - 1s - 45ms/step - accuracy: 0.1368 - loss: 2.5354\n",
      "Epoch 20/47\n",
      "30/30 - 1s - 47ms/step - accuracy: 0.1469 - loss: 2.5275\n",
      "Epoch 21/47\n",
      "30/30 - 1s - 49ms/step - accuracy: 0.1560 - loss: 2.5201\n",
      "Epoch 22/47\n",
      "30/30 - 2s - 50ms/step - accuracy: 0.1734 - loss: 2.5102\n",
      "Epoch 23/47\n",
      "30/30 - 3s - 93ms/step - accuracy: 0.1775 - loss: 2.5024\n",
      "Epoch 24/47\n",
      "30/30 - 988s - 33s/step - accuracy: 0.1914 - loss: 2.4926\n",
      "Epoch 25/47\n",
      "30/30 - 2s - 78ms/step - accuracy: 0.2023 - loss: 2.4832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/47\n",
      "30/30 - 2s - 65ms/step - accuracy: 0.2177 - loss: 2.4739\n",
      "Epoch 27/47\n",
      "30/30 - 1s - 38ms/step - accuracy: 0.2280 - loss: 2.4645\n",
      "Epoch 28/47\n",
      "30/30 - 1s - 38ms/step - accuracy: 0.2386 - loss: 2.4557\n",
      "Epoch 29/47\n",
      "30/30 - 1s - 38ms/step - accuracy: 0.2550 - loss: 2.4455\n",
      "Epoch 30/47\n",
      "30/30 - 1s - 38ms/step - accuracy: 0.2639 - loss: 2.4390\n",
      "Epoch 31/47\n",
      "30/30 - 1s - 38ms/step - accuracy: 0.2769 - loss: 2.4284\n",
      "Epoch 32/47\n",
      "30/30 - 2s - 56ms/step - accuracy: 0.2903 - loss: 2.4164\n",
      "Epoch 33/47\n",
      "30/30 - 2s - 52ms/step - accuracy: 0.2992 - loss: 2.4105\n",
      "Epoch 34/47\n",
      "30/30 - 2s - 52ms/step - accuracy: 0.3126 - loss: 2.3986\n",
      "Epoch 35/47\n",
      "30/30 - 2s - 52ms/step - accuracy: 0.3281 - loss: 2.3876\n",
      "Epoch 36/47\n",
      "30/30 - 2s - 57ms/step - accuracy: 0.3375 - loss: 2.3801\n",
      "Epoch 37/47\n",
      "30/30 - 2s - 64ms/step - accuracy: 0.3488 - loss: 2.3695\n",
      "Epoch 38/47\n",
      "30/30 - 2s - 63ms/step - accuracy: 0.3609 - loss: 2.3590\n",
      "Epoch 39/47\n",
      "30/30 - 2s - 67ms/step - accuracy: 0.3671 - loss: 2.3503\n",
      "Epoch 40/47\n",
      "30/30 - 2s - 66ms/step - accuracy: 0.3868 - loss: 2.3394\n",
      "Epoch 41/47\n",
      "30/30 - 3s - 84ms/step - accuracy: 0.3962 - loss: 2.3291\n",
      "Epoch 42/47\n",
      "30/30 - 2s - 74ms/step - accuracy: 0.4077 - loss: 2.3202\n",
      "Epoch 43/47\n",
      "30/30 - 2s - 67ms/step - accuracy: 0.4203 - loss: 2.3095\n",
      "Epoch 44/47\n",
      "30/30 - 2s - 66ms/step - accuracy: 0.4321 - loss: 2.2971\n",
      "Epoch 45/47\n",
      "30/30 - 2s - 65ms/step - accuracy: 0.4416 - loss: 2.2857\n",
      "Epoch 46/47\n",
      "30/30 - 2s - 66ms/step - accuracy: 0.4502 - loss: 2.2780\n",
      "Epoch 47/47\n",
      "30/30 - 2s - 67ms/step - accuracy: 0.4565 - loss: 2.2678\n",
      "8/8 - 0s - 53ms/step\n",
      "Epoch 1/47\n",
      "30/30 - 6s - 189ms/step - accuracy: 0.0458 - loss: 2.6970\n",
      "Epoch 2/47\n",
      "30/30 - 2s - 70ms/step - accuracy: 0.0481 - loss: 2.6928\n",
      "Epoch 3/47\n",
      "30/30 - 2s - 65ms/step - accuracy: 0.0508 - loss: 2.6867\n",
      "Epoch 4/47\n",
      "30/30 - 2s - 66ms/step - accuracy: 0.0542 - loss: 2.6799\n",
      "Epoch 5/47\n",
      "30/30 - 2s - 65ms/step - accuracy: 0.0588 - loss: 2.6732\n",
      "Epoch 6/47\n",
      "30/30 - 2s - 69ms/step - accuracy: 0.0628 - loss: 2.6657\n",
      "Epoch 7/47\n",
      "30/30 - 2s - 69ms/step - accuracy: 0.0717 - loss: 2.6610\n",
      "Epoch 8/47\n",
      "30/30 - 2s - 83ms/step - accuracy: 0.0721 - loss: 2.6536\n",
      "Epoch 9/47\n",
      "30/30 - 2s - 73ms/step - accuracy: 0.0813 - loss: 2.6460\n",
      "Epoch 10/47\n",
      "30/30 - 2s - 67ms/step - accuracy: 0.0836 - loss: 2.6384\n",
      "Epoch 11/47\n",
      "30/30 - 2s - 69ms/step - accuracy: 0.0892 - loss: 2.6343\n",
      "Epoch 12/47\n",
      "30/30 - 2s - 67ms/step - accuracy: 0.0978 - loss: 2.6259\n",
      "Epoch 13/47\n",
      "30/30 - 2s - 71ms/step - accuracy: 0.1052 - loss: 2.6168\n",
      "Epoch 14/47\n",
      "30/30 - 2s - 71ms/step - accuracy: 0.1115 - loss: 2.6093\n",
      "Epoch 15/47\n",
      "30/30 - 3s - 84ms/step - accuracy: 0.1253 - loss: 2.6030\n",
      "Epoch 16/47\n",
      "30/30 - 2s - 71ms/step - accuracy: 0.1270 - loss: 2.5965\n",
      "Epoch 17/47\n",
      "30/30 - 2s - 73ms/step - accuracy: 0.1357 - loss: 2.5878\n",
      "Epoch 18/47\n",
      "30/30 - 2s - 71ms/step - accuracy: 0.1484 - loss: 2.5788\n",
      "Epoch 19/47\n",
      "30/30 - 2s - 70ms/step - accuracy: 0.1566 - loss: 2.5707\n",
      "Epoch 20/47\n",
      "30/30 - 2s - 68ms/step - accuracy: 0.1675 - loss: 2.5625\n",
      "Epoch 21/47\n",
      "30/30 - 2s - 68ms/step - accuracy: 0.1768 - loss: 2.5545\n",
      "Epoch 22/47\n",
      "30/30 - 2s - 73ms/step - accuracy: 0.1847 - loss: 2.5482\n",
      "Epoch 23/47\n",
      "30/30 - 2s - 77ms/step - accuracy: 0.1955 - loss: 2.5391\n",
      "Epoch 24/47\n",
      "30/30 - 2s - 70ms/step - accuracy: 0.2094 - loss: 2.5316\n",
      "Epoch 25/47\n",
      "30/30 - 2s - 66ms/step - accuracy: 0.2192 - loss: 2.5236\n",
      "Epoch 26/47\n",
      "30/30 - 2s - 66ms/step - accuracy: 0.2302 - loss: 2.5143\n",
      "Epoch 27/47\n",
      "30/30 - 2s - 67ms/step - accuracy: 0.2448 - loss: 2.5051\n",
      "Epoch 28/47\n",
      "30/30 - 2s - 67ms/step - accuracy: 0.2519 - loss: 2.4960\n",
      "Epoch 29/47\n",
      "30/30 - 2s - 68ms/step - accuracy: 0.2656 - loss: 2.4879\n",
      "Epoch 30/47\n",
      "30/30 - 2s - 78ms/step - accuracy: 0.2785 - loss: 2.4802\n",
      "Epoch 31/47\n",
      "30/30 - 2s - 75ms/step - accuracy: 0.2871 - loss: 2.4726\n",
      "Epoch 32/47\n",
      "30/30 - 2s - 67ms/step - accuracy: 0.3015 - loss: 2.4619\n",
      "Epoch 33/47\n",
      "30/30 - 2s - 68ms/step - accuracy: 0.3166 - loss: 2.4529\n",
      "Epoch 34/47\n",
      "30/30 - 2s - 68ms/step - accuracy: 0.3346 - loss: 2.4441\n",
      "Epoch 35/47\n",
      "30/30 - 2s - 67ms/step - accuracy: 0.3443 - loss: 2.4354\n",
      "Epoch 36/47\n",
      "30/30 - 2s - 68ms/step - accuracy: 0.3510 - loss: 2.4270\n",
      "Epoch 37/47\n",
      "30/30 - 2s - 70ms/step - accuracy: 0.3654 - loss: 2.4161\n",
      "Epoch 38/47\n",
      "30/30 - 2s - 83ms/step - accuracy: 0.3784 - loss: 2.4085\n",
      "Epoch 39/47\n",
      "30/30 - 2s - 75ms/step - accuracy: 0.3898 - loss: 2.3987\n",
      "Epoch 40/47\n",
      "30/30 - 2s - 68ms/step - accuracy: 0.3978 - loss: 2.3888\n",
      "Epoch 41/47\n",
      "30/30 - 2s - 68ms/step - accuracy: 0.4126 - loss: 2.3785\n",
      "Epoch 42/47\n",
      "30/30 - 2s - 69ms/step - accuracy: 0.4237 - loss: 2.3699\n",
      "Epoch 43/47\n",
      "30/30 - 2s - 68ms/step - accuracy: 0.4409 - loss: 2.3609\n",
      "Epoch 44/47\n",
      "30/30 - 2s - 67ms/step - accuracy: 0.4447 - loss: 2.3519\n",
      "Epoch 45/47\n",
      "30/30 - 3s - 83ms/step - accuracy: 0.4548 - loss: 2.3409\n",
      "Epoch 46/47\n",
      "30/30 - 2s - 73ms/step - accuracy: 0.4700 - loss: 2.3307\n",
      "Epoch 47/47\n",
      "30/30 - 2s - 68ms/step - accuracy: 0.4792 - loss: 2.3236\n",
      "8/8 - 0s - 51ms/step\n",
      "Epoch 1/47\n",
      "30/30 - 5s - 169ms/step - accuracy: 0.0218 - loss: 2.8608\n",
      "Epoch 2/47\n",
      "30/30 - 2s - 61ms/step - accuracy: 0.0240 - loss: 2.8542\n",
      "Epoch 3/47\n",
      "30/30 - 2s - 63ms/step - accuracy: 0.0238 - loss: 2.8477\n",
      "Epoch 4/47\n",
      "30/30 - 2s - 81ms/step - accuracy: 0.0277 - loss: 2.8386\n",
      "Epoch 5/47\n",
      "30/30 - 2s - 76ms/step - accuracy: 0.0283 - loss: 2.8319\n",
      "Epoch 6/47\n",
      "30/30 - 2s - 65ms/step - accuracy: 0.0312 - loss: 2.8234\n",
      "Epoch 7/47\n",
      "30/30 - 2s - 67ms/step - accuracy: 0.0341 - loss: 2.8157\n",
      "Epoch 8/47\n",
      "30/30 - 2s - 67ms/step - accuracy: 0.0357 - loss: 2.8093\n",
      "Epoch 9/47\n",
      "30/30 - 2s - 69ms/step - accuracy: 0.0421 - loss: 2.8000\n",
      "Epoch 10/47\n",
      "30/30 - 2s - 75ms/step - accuracy: 0.0432 - loss: 2.7913\n",
      "Epoch 11/47\n",
      "30/30 - 3s - 89ms/step - accuracy: 0.0461 - loss: 2.7838\n",
      "Epoch 12/47\n",
      "30/30 - 5s - 156ms/step - accuracy: 0.0533 - loss: 2.7762\n",
      "Epoch 13/47\n",
      "30/30 - 2s - 80ms/step - accuracy: 0.0551 - loss: 2.7663\n",
      "Epoch 14/47\n",
      "30/30 - 2s - 74ms/step - accuracy: 0.0609 - loss: 2.7570\n",
      "Epoch 15/47\n",
      "30/30 - 2s - 83ms/step - accuracy: 0.0651 - loss: 2.7485\n",
      "Epoch 16/47\n",
      "30/30 - 2s - 75ms/step - accuracy: 0.0731 - loss: 2.7409\n",
      "Epoch 17/47\n",
      "30/30 - 3s - 91ms/step - accuracy: 0.0760 - loss: 2.7316\n",
      "Epoch 18/47\n",
      "30/30 - 2s - 75ms/step - accuracy: 0.0824 - loss: 2.7218\n",
      "Epoch 19/47\n",
      "30/30 - 2s - 74ms/step - accuracy: 0.0911 - loss: 2.7124\n",
      "Epoch 20/47\n",
      "30/30 - 2s - 75ms/step - accuracy: 0.0992 - loss: 2.7027\n",
      "Epoch 21/47\n",
      "30/30 - 2s - 77ms/step - accuracy: 0.1055 - loss: 2.6928\n",
      "Epoch 22/47\n",
      "30/30 - 2s - 81ms/step - accuracy: 0.1191 - loss: 2.6823\n",
      "Epoch 23/47\n",
      "30/30 - 2s - 81ms/step - accuracy: 0.1264 - loss: 2.6738\n",
      "Epoch 24/47\n",
      "30/30 - 3s - 102ms/step - accuracy: 0.1329 - loss: 2.6632\n",
      "Epoch 25/47\n",
      "30/30 - 3s - 89ms/step - accuracy: 0.1406 - loss: 2.6553\n",
      "Epoch 26/47\n",
      "30/30 - 5s - 150ms/step - accuracy: 0.1558 - loss: 2.6430\n",
      "Epoch 27/47\n",
      "30/30 - 2s - 69ms/step - accuracy: 0.1672 - loss: 2.6319\n",
      "Epoch 28/47\n",
      "30/30 - 2s - 73ms/step - accuracy: 0.1756 - loss: 2.6225\n",
      "Epoch 29/47\n",
      "30/30 - 3s - 86ms/step - accuracy: 0.1908 - loss: 2.6112\n",
      "Epoch 30/47\n",
      "30/30 - 3s - 89ms/step - accuracy: 0.2028 - loss: 2.6007\n",
      "Epoch 31/47\n",
      "30/30 - 3s - 88ms/step - accuracy: 0.2174 - loss: 2.5892\n",
      "Epoch 32/47\n",
      "30/30 - 3s - 84ms/step - accuracy: 0.2324 - loss: 2.5800\n",
      "Epoch 33/47\n",
      "30/30 - 3s - 85ms/step - accuracy: 0.2431 - loss: 2.5688\n",
      "Epoch 34/47\n",
      "30/30 - 2s - 82ms/step - accuracy: 0.2606 - loss: 2.5567\n",
      "Epoch 35/47\n",
      "30/30 - 2s - 79ms/step - accuracy: 0.2720 - loss: 2.5475\n",
      "Epoch 36/47\n",
      "30/30 - 3s - 98ms/step - accuracy: 0.2867 - loss: 2.5348\n",
      "Epoch 37/47\n",
      "30/30 - 3s - 90ms/step - accuracy: 0.3003 - loss: 2.5257\n",
      "Epoch 38/47\n",
      "30/30 - 2s - 83ms/step - accuracy: 0.3121 - loss: 2.5154\n",
      "Epoch 39/47\n",
      "30/30 - 3s - 84ms/step - accuracy: 0.3310 - loss: 2.5037\n",
      "Epoch 40/47\n",
      "30/30 - 2s - 79ms/step - accuracy: 0.3423 - loss: 2.4919\n",
      "Epoch 41/47\n",
      "30/30 - 2s - 83ms/step - accuracy: 0.3570 - loss: 2.4800\n",
      "Epoch 42/47\n",
      "30/30 - 3s - 99ms/step - accuracy: 0.3710 - loss: 2.4684\n",
      "Epoch 43/47\n",
      "30/30 - 2s - 82ms/step - accuracy: 0.3872 - loss: 2.4576\n",
      "Epoch 44/47\n",
      "30/30 - 2s - 81ms/step - accuracy: 0.3984 - loss: 2.4469\n",
      "Epoch 45/47\n",
      "30/30 - 3s - 90ms/step - accuracy: 0.4166 - loss: 2.4323\n",
      "Epoch 46/47\n",
      "30/30 - 2s - 82ms/step - accuracy: 0.4322 - loss: 2.4220\n",
      "Epoch 47/47\n",
      "30/30 - 2s - 80ms/step - accuracy: 0.4428 - loss: 2.4099\n",
      "8/8 - 1s - 87ms/step\n",
      "Epoch 1/47\n",
      "30/30 - 7s - 232ms/step - accuracy: 0.2139 - loss: 2.5859\n",
      "Epoch 2/47\n",
      "30/30 - 3s - 91ms/step - accuracy: 0.2193 - loss: 2.5801\n",
      "Epoch 3/47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 - 2s - 79ms/step - accuracy: 0.2359 - loss: 2.5729\n",
      "Epoch 4/47\n",
      "30/30 - 2s - 71ms/step - accuracy: 0.2421 - loss: 2.5649\n",
      "Epoch 5/47\n",
      "30/30 - 1076s - 36s/step - accuracy: 0.2548 - loss: 2.5572\n",
      "Epoch 6/47\n",
      "30/30 - 2s - 72ms/step - accuracy: 0.2677 - loss: 2.5494\n",
      "Epoch 7/47\n",
      "30/30 - 2s - 59ms/step - accuracy: 0.2859 - loss: 2.5405\n",
      "Epoch 8/47\n",
      "30/30 - 2s - 71ms/step - accuracy: 0.2914 - loss: 2.5343\n",
      "Epoch 9/47\n",
      "30/30 - 1s - 44ms/step - accuracy: 0.3030 - loss: 2.5260\n",
      "Epoch 10/47\n",
      "30/30 - 1s - 45ms/step - accuracy: 0.3214 - loss: 2.5189\n",
      "Epoch 11/47\n",
      "30/30 - 1s - 44ms/step - accuracy: 0.3359 - loss: 2.5094\n",
      "Epoch 12/47\n",
      "30/30 - 4s - 131ms/step - accuracy: 0.3480 - loss: 2.5011\n",
      "Epoch 13/47\n",
      "30/30 - 3s - 90ms/step - accuracy: 0.3608 - loss: 2.4935\n",
      "Epoch 14/47\n",
      "30/30 - 2s - 67ms/step - accuracy: 0.3766 - loss: 2.4823\n",
      "Epoch 15/47\n",
      "30/30 - 2s - 62ms/step - accuracy: 0.3888 - loss: 2.4751\n",
      "Epoch 16/47\n",
      "30/30 - 2s - 77ms/step - accuracy: 0.4023 - loss: 2.4658\n",
      "Epoch 17/47\n",
      "30/30 - 2s - 53ms/step - accuracy: 0.4206 - loss: 2.4574\n",
      "Epoch 18/47\n",
      "30/30 - 2s - 52ms/step - accuracy: 0.4250 - loss: 2.4483\n",
      "Epoch 19/47\n",
      "30/30 - 2s - 52ms/step - accuracy: 0.4446 - loss: 2.4382\n",
      "Epoch 20/47\n",
      "30/30 - 2s - 56ms/step - accuracy: 0.4622 - loss: 2.4272\n",
      "Epoch 21/47\n",
      "30/30 - 3s - 87ms/step - accuracy: 0.4707 - loss: 2.4190\n",
      "Epoch 22/47\n",
      "30/30 - 2s - 54ms/step - accuracy: 0.4844 - loss: 2.4102\n",
      "Epoch 23/47\n",
      "30/30 - 2s - 80ms/step - accuracy: 0.4952 - loss: 2.4002\n",
      "Epoch 24/47\n",
      "30/30 - 1s - 49ms/step - accuracy: 0.5027 - loss: 2.3903\n",
      "Epoch 25/47\n",
      "30/30 - 1s - 49ms/step - accuracy: 0.5189 - loss: 2.3811\n",
      "Epoch 26/47\n",
      "30/30 - 2s - 83ms/step - accuracy: 0.5294 - loss: 2.3705\n",
      "Epoch 27/47\n",
      "30/30 - 2s - 82ms/step - accuracy: 0.5409 - loss: 2.3607\n",
      "Epoch 28/47\n",
      "30/30 - 1s - 50ms/step - accuracy: 0.5502 - loss: 2.3509\n",
      "Epoch 29/47\n",
      "30/30 - 2359s - 79s/step - accuracy: 0.5564 - loss: 2.3405\n",
      "Epoch 30/47\n",
      "30/30 - 4s - 123ms/step - accuracy: 0.5669 - loss: 2.3301\n",
      "Epoch 31/47\n",
      "30/30 - 1s - 46ms/step - accuracy: 0.5736 - loss: 2.3211\n",
      "Epoch 32/47\n",
      "30/30 - 2s - 78ms/step - accuracy: 0.5834 - loss: 2.3105\n",
      "Epoch 33/47\n",
      "30/30 - 1s - 38ms/step - accuracy: 0.5910 - loss: 2.2986\n",
      "Epoch 34/47\n",
      "30/30 - 1s - 39ms/step - accuracy: 0.5941 - loss: 2.2910\n",
      "Epoch 35/47\n",
      "30/30 - 1s - 48ms/step - accuracy: 0.5996 - loss: 2.2807\n",
      "Epoch 36/47\n",
      "30/30 - 2s - 59ms/step - accuracy: 0.6044 - loss: 2.2692\n",
      "Epoch 37/47\n",
      "30/30 - 2s - 80ms/step - accuracy: 0.6075 - loss: 2.2600\n",
      "Epoch 38/47\n",
      "30/30 - 2s - 60ms/step - accuracy: 0.6150 - loss: 2.2476\n",
      "Epoch 39/47\n",
      "30/30 - 2s - 56ms/step - accuracy: 0.6166 - loss: 2.2365\n",
      "Epoch 40/47\n",
      "30/30 - 2s - 56ms/step - accuracy: 0.6221 - loss: 2.2274\n",
      "Epoch 41/47\n",
      "30/30 - 2s - 56ms/step - accuracy: 0.6241 - loss: 2.2164\n",
      "Epoch 42/47\n",
      "30/30 - 2s - 56ms/step - accuracy: 0.6269 - loss: 2.2049\n",
      "Epoch 43/47\n",
      "30/30 - 2s - 55ms/step - accuracy: 0.6288 - loss: 2.1944\n",
      "Epoch 44/47\n",
      "30/30 - 2s - 79ms/step - accuracy: 0.6308 - loss: 2.1837\n",
      "Epoch 45/47\n",
      "30/30 - 2s - 63ms/step - accuracy: 0.6316 - loss: 2.1714\n",
      "Epoch 46/47\n",
      "30/30 - 2s - 52ms/step - accuracy: 0.6325 - loss: 2.1616\n",
      "Epoch 47/47\n",
      "30/30 - 3s - 87ms/step - accuracy: 0.6341 - loss: 2.1508\n",
      "8/8 - 0s - 40ms/step\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39mnan      \u001b[39m | \u001b[39m2.799    \u001b[39m | \u001b[39m460.1    \u001b[39m | \u001b[39m0.7296   \u001b[39m | \u001b[39m0.1913   \u001b[39m | \u001b[39m46.62    \u001b[39m | \u001b[39m1.944    \u001b[39m | \u001b[39m1.239    \u001b[39m | \u001b[39m2.426    \u001b[39m | \u001b[39m0.7632   \u001b[39m | \u001b[39m60.51    \u001b[39m | \u001b[39m0.771    \u001b[39m | \u001b[39m3.457    \u001b[39m |\n",
      "Epoch 1/21\n",
      "26/26 - 2s - 94ms/step - accuracy: 0.5174 - loss: 1.6545\n",
      "Epoch 2/21\n",
      "26/26 - 1s - 19ms/step - accuracy: 0.6740 - loss: 1.0035\n",
      "Epoch 3/21\n",
      "26/26 - 1s - 22ms/step - accuracy: 0.6825 - loss: 0.9545\n",
      "Epoch 4/21\n",
      "26/26 - 0s - 16ms/step - accuracy: 0.6877 - loss: 0.9277\n",
      "Epoch 5/21\n",
      "26/26 - 0s - 17ms/step - accuracy: 0.6910 - loss: 0.9055\n",
      "Epoch 6/21\n",
      "26/26 - 0s - 17ms/step - accuracy: 0.6990 - loss: 0.8857\n",
      "Epoch 7/21\n",
      "26/26 - 0s - 17ms/step - accuracy: 0.7047 - loss: 0.8674\n",
      "Epoch 8/21\n",
      "26/26 - 0s - 17ms/step - accuracy: 0.7112 - loss: 0.8515\n",
      "Epoch 9/21\n",
      "26/26 - 0s - 17ms/step - accuracy: 0.7151 - loss: 0.8360\n",
      "Epoch 10/21\n",
      "26/26 - 0s - 18ms/step - accuracy: 0.7215 - loss: 0.8223\n",
      "Epoch 11/21\n",
      "26/26 - 1s - 25ms/step - accuracy: 0.7255 - loss: 0.8095\n",
      "Epoch 12/21\n",
      "26/26 - 1s - 25ms/step - accuracy: 0.7300 - loss: 0.7965\n",
      "Epoch 13/21\n",
      "26/26 - 0s - 18ms/step - accuracy: 0.7332 - loss: 0.7848\n",
      "Epoch 14/21\n",
      "26/26 - 0s - 18ms/step - accuracy: 0.7380 - loss: 0.7721\n",
      "Epoch 15/21\n",
      "26/26 - 0s - 18ms/step - accuracy: 0.7416 - loss: 0.7611\n",
      "Epoch 16/21\n",
      "26/26 - 1s - 25ms/step - accuracy: 0.7441 - loss: 0.7502\n",
      "Epoch 17/21\n",
      "26/26 - 1s - 24ms/step - accuracy: 0.7502 - loss: 0.7399\n",
      "Epoch 18/21\n",
      "26/26 - 1s - 26ms/step - accuracy: 0.7516 - loss: 0.7326\n",
      "Epoch 19/21\n",
      "26/26 - 936s - 36s/step - accuracy: 0.7574 - loss: 0.7205\n",
      "Epoch 20/21\n",
      "26/26 - 1s - 38ms/step - accuracy: 0.7592 - loss: 0.7127\n",
      "Epoch 21/21\n",
      "26/26 - 0s - 17ms/step - accuracy: 0.7620 - loss: 0.7041\n",
      "7/7 - 0s - 32ms/step\n",
      "Epoch 1/21\n",
      "26/26 - 3s - 115ms/step - accuracy: 0.5830 - loss: 1.2880\n",
      "Epoch 2/21\n",
      "26/26 - 1s - 24ms/step - accuracy: 0.6420 - loss: 0.9811\n",
      "Epoch 3/21\n",
      "26/26 - 0s - 17ms/step - accuracy: 0.6673 - loss: 0.9369\n",
      "Epoch 4/21\n",
      "26/26 - 0s - 17ms/step - accuracy: 0.6832 - loss: 0.9083\n",
      "Epoch 5/21\n",
      "26/26 - 1s - 24ms/step - accuracy: 0.6935 - loss: 0.8869\n",
      "Epoch 6/21\n",
      "26/26 - 0s - 17ms/step - accuracy: 0.7008 - loss: 0.8693\n",
      "Epoch 7/21\n",
      "26/26 - 1s - 24ms/step - accuracy: 0.7076 - loss: 0.8537\n",
      "Epoch 8/21\n",
      "26/26 - 0s - 17ms/step - accuracy: 0.7133 - loss: 0.8393\n",
      "Epoch 9/21\n",
      "26/26 - 0s - 15ms/step - accuracy: 0.7167 - loss: 0.8260\n",
      "Epoch 10/21\n",
      "26/26 - 0s - 15ms/step - accuracy: 0.7234 - loss: 0.8124\n",
      "Epoch 11/21\n",
      "26/26 - 0s - 16ms/step - accuracy: 0.7270 - loss: 0.8018\n",
      "Epoch 12/21\n",
      "26/26 - 1s - 24ms/step - accuracy: 0.7284 - loss: 0.7894\n",
      "Epoch 13/21\n",
      "26/26 - 0s - 16ms/step - accuracy: 0.7326 - loss: 0.7778\n",
      "Epoch 14/21\n",
      "26/26 - 0s - 16ms/step - accuracy: 0.7341 - loss: 0.7673\n",
      "Epoch 15/21\n",
      "26/26 - 0s - 17ms/step - accuracy: 0.7400 - loss: 0.7560\n",
      "Epoch 16/21\n",
      "26/26 - 0s - 18ms/step - accuracy: 0.7441 - loss: 0.7447\n",
      "Epoch 17/21\n",
      "26/26 - 1s - 20ms/step - accuracy: 0.7452 - loss: 0.7356\n",
      "Epoch 18/21\n",
      "26/26 - 1s - 23ms/step - accuracy: 0.7497 - loss: 0.7249\n",
      "Epoch 19/21\n",
      "26/26 - 1s - 25ms/step - accuracy: 0.7533 - loss: 0.7133\n",
      "Epoch 20/21\n",
      "26/26 - 1s - 45ms/step - accuracy: 0.7561 - loss: 0.7047\n",
      "Epoch 21/21\n",
      "26/26 - 1s - 23ms/step - accuracy: 0.7580 - loss: 0.6939\n",
      "7/7 - 0s - 44ms/step\n",
      "Epoch 1/21\n",
      "26/26 - 4s - 135ms/step - accuracy: 0.6195 - loss: 1.2947\n",
      "Epoch 2/21\n",
      "26/26 - 1s - 22ms/step - accuracy: 0.6789 - loss: 0.9765\n",
      "Epoch 3/21\n",
      "26/26 - 1s - 23ms/step - accuracy: 0.6899 - loss: 0.9187\n",
      "Epoch 4/21\n",
      "26/26 - 1s - 24ms/step - accuracy: 0.6996 - loss: 0.8818\n",
      "Epoch 5/21\n",
      "26/26 - 1s - 22ms/step - accuracy: 0.7084 - loss: 0.8532\n",
      "Epoch 6/21\n",
      "26/26 - 1s - 24ms/step - accuracy: 0.7177 - loss: 0.8292\n",
      "Epoch 7/21\n",
      "26/26 - 1s - 24ms/step - accuracy: 0.7233 - loss: 0.8084\n",
      "Epoch 8/21\n",
      "26/26 - 1s - 23ms/step - accuracy: 0.7321 - loss: 0.7914\n",
      "Epoch 9/21\n",
      "26/26 - 1s - 25ms/step - accuracy: 0.7376 - loss: 0.7743\n",
      "Epoch 10/21\n",
      "26/26 - 1s - 25ms/step - accuracy: 0.7434 - loss: 0.7588\n",
      "Epoch 11/21\n",
      "26/26 - 1s - 48ms/step - accuracy: 0.7459 - loss: 0.7458\n",
      "Epoch 12/21\n",
      "26/26 - 1s - 26ms/step - accuracy: 0.7504 - loss: 0.7325\n",
      "Epoch 13/21\n",
      "26/26 - 1s - 24ms/step - accuracy: 0.7515 - loss: 0.7244\n",
      "Epoch 14/21\n",
      "26/26 - 1s - 26ms/step - accuracy: 0.7571 - loss: 0.7109\n",
      "Epoch 15/21\n",
      "26/26 - 1s - 28ms/step - accuracy: 0.7592 - loss: 0.7004\n",
      "Epoch 16/21\n",
      "26/26 - 1s - 30ms/step - accuracy: 0.7614 - loss: 0.6940\n",
      "Epoch 17/21\n",
      "26/26 - 1s - 30ms/step - accuracy: 0.7654 - loss: 0.6831\n",
      "Epoch 18/21\n",
      "26/26 - 1s - 27ms/step - accuracy: 0.7670 - loss: 0.6754\n",
      "Epoch 19/21\n",
      "26/26 - 1s - 25ms/step - accuracy: 0.7707 - loss: 0.6676\n",
      "Epoch 20/21\n",
      "26/26 - 1s - 24ms/step - accuracy: 0.7722 - loss: 0.6604\n",
      "Epoch 21/21\n",
      "26/26 - 1s - 24ms/step - accuracy: 0.7722 - loss: 0.6552\n",
      "7/7 - 0s - 47ms/step\n",
      "Epoch 1/21\n",
      "26/26 - 4s - 136ms/step - accuracy: 0.5189 - loss: 1.7772\n",
      "Epoch 2/21\n",
      "26/26 - 1s - 23ms/step - accuracy: 0.6172 - loss: 1.0843\n",
      "Epoch 3/21\n",
      "26/26 - 1s - 23ms/step - accuracy: 0.6506 - loss: 0.9963\n",
      "Epoch 4/21\n",
      "26/26 - 1s - 22ms/step - accuracy: 0.6656 - loss: 0.9581\n",
      "Epoch 5/21\n",
      "26/26 - 1s - 23ms/step - accuracy: 0.6779 - loss: 0.9326\n",
      "Epoch 6/21\n",
      "26/26 - 1s - 23ms/step - accuracy: 0.6879 - loss: 0.9113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/21\n",
      "26/26 - 1s - 25ms/step - accuracy: 0.7020 - loss: 0.8917\n",
      "Epoch 8/21\n",
      "26/26 - 1s - 26ms/step - accuracy: 0.7076 - loss: 0.8748\n",
      "Epoch 9/21\n",
      "26/26 - 1s - 24ms/step - accuracy: 0.7134 - loss: 0.8612\n",
      "Epoch 10/21\n",
      "26/26 - 1s - 22ms/step - accuracy: 0.7167 - loss: 0.8465\n",
      "Epoch 11/21\n",
      "26/26 - 1s - 23ms/step - accuracy: 0.7217 - loss: 0.8332\n",
      "Epoch 12/21\n",
      "26/26 - 1s - 28ms/step - accuracy: 0.7288 - loss: 0.8194\n",
      "Epoch 13/21\n",
      "26/26 - 1s - 29ms/step - accuracy: 0.7318 - loss: 0.8071\n",
      "Epoch 14/21\n",
      "26/26 - 1s - 27ms/step - accuracy: 0.7358 - loss: 0.7966\n",
      "Epoch 15/21\n",
      "26/26 - 1s - 29ms/step - accuracy: 0.7399 - loss: 0.7835\n",
      "Epoch 16/21\n",
      "26/26 - 1s - 29ms/step - accuracy: 0.7415 - loss: 0.7736\n",
      "Epoch 17/21\n",
      "26/26 - 1s - 26ms/step - accuracy: 0.7466 - loss: 0.7625\n",
      "Epoch 18/21\n",
      "26/26 - 1s - 23ms/step - accuracy: 0.7502 - loss: 0.7532\n",
      "Epoch 19/21\n",
      "26/26 - 1s - 24ms/step - accuracy: 0.7539 - loss: 0.7432\n",
      "Epoch 20/21\n",
      "26/26 - 1s - 24ms/step - accuracy: 0.7573 - loss: 0.7339\n",
      "Epoch 21/21\n",
      "26/26 - 1s - 25ms/step - accuracy: 0.7571 - loss: 0.7279\n",
      "7/7 - 0s - 46ms/step\n",
      "Epoch 1/21\n",
      "26/26 - 4s - 145ms/step - accuracy: 0.5117 - loss: 1.9298\n",
      "Epoch 2/21\n",
      "26/26 - 1s - 24ms/step - accuracy: 0.6580 - loss: 1.0707\n",
      "Epoch 3/21\n",
      "26/26 - 1s - 26ms/step - accuracy: 0.6765 - loss: 0.9870\n",
      "Epoch 4/21\n",
      "26/26 - 1s - 26ms/step - accuracy: 0.6890 - loss: 0.9422\n",
      "Epoch 5/21\n",
      "26/26 - 1s - 25ms/step - accuracy: 0.6958 - loss: 0.9104\n",
      "Epoch 6/21\n",
      "26/26 - 1s - 25ms/step - accuracy: 0.7009 - loss: 0.8850\n",
      "Epoch 7/21\n",
      "26/26 - 1s - 26ms/step - accuracy: 0.7097 - loss: 0.8635\n",
      "Epoch 8/21\n",
      "26/26 - 1s - 25ms/step - accuracy: 0.7137 - loss: 0.8453\n",
      "Epoch 9/21\n",
      "26/26 - 1s - 27ms/step - accuracy: 0.7203 - loss: 0.8272\n",
      "Epoch 10/21\n",
      "26/26 - 1s - 28ms/step - accuracy: 0.7264 - loss: 0.8107\n",
      "Epoch 11/21\n",
      "26/26 - 1s - 29ms/step - accuracy: 0.7316 - loss: 0.7966\n",
      "Epoch 12/21\n",
      "26/26 - 1s - 47ms/step - accuracy: 0.7347 - loss: 0.7841\n",
      "Epoch 13/21\n",
      "26/26 - 1s - 27ms/step - accuracy: 0.7393 - loss: 0.7720\n",
      "Epoch 14/21\n",
      "26/26 - 1s - 24ms/step - accuracy: 0.7420 - loss: 0.7618\n",
      "Epoch 15/21\n",
      "26/26 - 1s - 23ms/step - accuracy: 0.7461 - loss: 0.7514\n",
      "Epoch 16/21\n",
      "26/26 - 1s - 26ms/step - accuracy: 0.7485 - loss: 0.7412\n",
      "Epoch 17/21\n",
      "26/26 - 1s - 25ms/step - accuracy: 0.7510 - loss: 0.7321\n",
      "Epoch 18/21\n",
      "26/26 - 1s - 25ms/step - accuracy: 0.7546 - loss: 0.7233\n",
      "Epoch 19/21\n",
      "26/26 - 1s - 27ms/step - accuracy: 0.7575 - loss: 0.7147\n",
      "Epoch 20/21\n",
      "26/26 - 1s - 45ms/step - accuracy: 0.7588 - loss: 0.7078\n",
      "Epoch 21/21\n",
      "26/26 - 1s - 24ms/step - accuracy: 0.7582 - loss: 0.7021\n",
      "7/7 - 0s - 43ms/step\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m0.763    \u001b[39m | \u001b[39m4.705    \u001b[39m | \u001b[39m542.0    \u001b[39m | \u001b[39m0.02542  \u001b[39m | \u001b[39m0.03237  \u001b[39m | \u001b[39m20.94    \u001b[39m | \u001b[39m2.273    \u001b[39m | \u001b[39m1.629    \u001b[39m | \u001b[39m2.017    \u001b[39m | \u001b[39m0.9085   \u001b[39m | \u001b[39m32.44    \u001b[39m | \u001b[39m0.4104   \u001b[39m | \u001b[39m5.289    \u001b[39m |\n",
      "Epoch 1/48\n",
      "53/53 - 4s - 69ms/step - accuracy: 0.3904 - loss: 1.9267\n",
      "Epoch 2/48\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.6440 - loss: 1.4051\n",
      "Epoch 3/48\n",
      "53/53 - 1s - 20ms/step - accuracy: 0.6440 - loss: 1.2802\n",
      "Epoch 4/48\n",
      "53/53 - 1s - 24ms/step - accuracy: 0.6440 - loss: 1.2308\n",
      "Epoch 5/48\n",
      "53/53 - 1s - 25ms/step - accuracy: 0.6440 - loss: 1.2046\n",
      "Epoch 6/48\n",
      "53/53 - 1s - 23ms/step - accuracy: 0.6440 - loss: 1.1882\n",
      "Epoch 7/48\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.6440 - loss: 1.1764\n",
      "Epoch 8/48\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.6440 - loss: 1.1674\n",
      "Epoch 9/48\n",
      "53/53 - 1s - 20ms/step - accuracy: 0.6440 - loss: 1.1599\n",
      "Epoch 10/48\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.6440 - loss: 1.1534\n",
      "Epoch 11/48\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.6440 - loss: 1.1475\n",
      "Epoch 12/48\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.6440 - loss: 1.1418\n",
      "Epoch 13/48\n",
      "53/53 - 1s - 23ms/step - accuracy: 0.6440 - loss: 1.1367\n",
      "Epoch 14/48\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.6440 - loss: 1.1318\n",
      "Epoch 15/48\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.6440 - loss: 1.1269\n",
      "Epoch 16/48\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.6440 - loss: 1.1222\n",
      "Epoch 17/48\n",
      "53/53 - 1s - 24ms/step - accuracy: 0.6440 - loss: 1.1175\n",
      "Epoch 18/48\n",
      "53/53 - 1s - 26ms/step - accuracy: 0.6439 - loss: 1.1130\n",
      "Epoch 19/48\n",
      "53/53 - 1s - 25ms/step - accuracy: 0.6440 - loss: 1.1085\n",
      "Epoch 20/48\n",
      "53/53 - 1s - 18ms/step - accuracy: 0.6443 - loss: 1.1044\n",
      "Epoch 21/48\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.6443 - loss: 1.0999\n",
      "Epoch 22/48\n",
      "53/53 - 1s - 18ms/step - accuracy: 0.6453 - loss: 1.0953\n",
      "Epoch 23/48\n",
      "53/53 - 1s - 20ms/step - accuracy: 0.6449 - loss: 1.0913\n",
      "Epoch 24/48\n",
      "53/53 - 1s - 20ms/step - accuracy: 0.6450 - loss: 1.0875\n",
      "Epoch 25/48\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.6451 - loss: 1.0836\n",
      "Epoch 26/48\n",
      "53/53 - 1s - 20ms/step - accuracy: 0.6451 - loss: 1.0798\n",
      "Epoch 27/48\n",
      "53/53 - 1s - 20ms/step - accuracy: 0.6472 - loss: 1.0761\n",
      "Epoch 28/48\n",
      "53/53 - 1s - 18ms/step - accuracy: 0.6460 - loss: 1.0727\n",
      "Epoch 29/48\n",
      "53/53 - 1s - 17ms/step - accuracy: 0.6479 - loss: 1.0697\n",
      "Epoch 30/48\n",
      "53/53 - 1s - 20ms/step - accuracy: 0.6475 - loss: 1.0663\n",
      "Epoch 31/48\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.6462 - loss: 1.0632\n",
      "Epoch 32/48\n",
      "53/53 - 1s - 23ms/step - accuracy: 0.6470 - loss: 1.0607\n",
      "Epoch 33/48\n",
      "53/53 - 1s - 23ms/step - accuracy: 0.6475 - loss: 1.0580\n",
      "Epoch 34/48\n",
      "53/53 - 1s - 23ms/step - accuracy: 0.6492 - loss: 1.0550\n",
      "Epoch 35/48\n",
      "53/53 - 1s - 19ms/step - accuracy: 0.6478 - loss: 1.0533\n",
      "Epoch 36/48\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.6490 - loss: 1.0503\n",
      "Epoch 37/48\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.6496 - loss: 1.0482\n",
      "Epoch 38/48\n",
      "53/53 - 1s - 20ms/step - accuracy: 0.6488 - loss: 1.0459\n",
      "Epoch 39/48\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.6497 - loss: 1.0439\n",
      "Epoch 40/48\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.6485 - loss: 1.0420\n",
      "Epoch 41/48\n",
      "53/53 - 1s - 20ms/step - accuracy: 0.6507 - loss: 1.0399\n",
      "Epoch 42/48\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.6480 - loss: 1.0387\n",
      "Epoch 43/48\n",
      "53/53 - 1s - 19ms/step - accuracy: 0.6515 - loss: 1.0362\n",
      "Epoch 44/48\n",
      "53/53 - 1s - 19ms/step - accuracy: 0.6505 - loss: 1.0339\n",
      "Epoch 45/48\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.6504 - loss: 1.0322\n",
      "Epoch 46/48\n",
      "53/53 - 1s - 24ms/step - accuracy: 0.6508 - loss: 1.0307\n",
      "Epoch 47/48\n",
      "53/53 - 1s - 26ms/step - accuracy: 0.6527 - loss: 1.0291\n",
      "Epoch 48/48\n",
      "53/53 - 2s - 41ms/step - accuracy: 0.6508 - loss: 1.0271\n",
      "14/14 - 0s - 29ms/step\n",
      "Epoch 1/48\n",
      "53/53 - 3s - 55ms/step - accuracy: 0.6299 - loss: 1.6219\n",
      "Epoch 2/48\n",
      "53/53 - 3898s - 74s/step - accuracy: 0.6440 - loss: 1.3121\n",
      "Epoch 3/48\n",
      "53/53 - 1s - 25ms/step - accuracy: 0.6440 - loss: 1.2463\n",
      "Epoch 4/48\n",
      "53/53 - 1s - 27ms/step - accuracy: 0.6440 - loss: 1.2171\n",
      "Epoch 5/48\n",
      "53/53 - 1s - 20ms/step - accuracy: 0.6440 - loss: 1.2006\n",
      "Epoch 6/48\n",
      "53/53 - 1s - 19ms/step - accuracy: 0.6440 - loss: 1.1900\n",
      "Epoch 7/48\n",
      "53/53 - 1s - 19ms/step - accuracy: 0.6440 - loss: 1.1823\n",
      "Epoch 8/48\n",
      "53/53 - 1s - 19ms/step - accuracy: 0.6440 - loss: 1.1763\n",
      "Epoch 9/48\n",
      "53/53 - 1s - 16ms/step - accuracy: 0.6440 - loss: 1.1714\n",
      "Epoch 10/48\n",
      "53/53 - 1s - 13ms/step - accuracy: 0.6440 - loss: 1.1671\n",
      "Epoch 11/48\n",
      "53/53 - 1s - 12ms/step - accuracy: 0.6440 - loss: 1.1631\n",
      "Epoch 12/48\n",
      "53/53 - 1s - 13ms/step - accuracy: 0.6440 - loss: 1.1594\n",
      "Epoch 13/48\n",
      "53/53 - 1s - 14ms/step - accuracy: 0.6440 - loss: 1.1558\n",
      "Epoch 14/48\n",
      "53/53 - 1s - 12ms/step - accuracy: 0.6440 - loss: 1.1523\n",
      "Epoch 15/48\n",
      "53/53 - 1s - 13ms/step - accuracy: 0.6440 - loss: 1.1487\n",
      "Epoch 16/48\n",
      "53/53 - 1s - 28ms/step - accuracy: 0.6440 - loss: 1.1451\n",
      "Epoch 17/48\n",
      "53/53 - 1s - 18ms/step - accuracy: 0.6440 - loss: 1.1413\n",
      "Epoch 18/48\n",
      "53/53 - 1s - 25ms/step - accuracy: 0.6440 - loss: 1.1373\n",
      "Epoch 19/48\n",
      "53/53 - 1s - 18ms/step - accuracy: 0.6440 - loss: 1.1333\n",
      "Epoch 20/48\n",
      "53/53 - 1s - 18ms/step - accuracy: 0.6440 - loss: 1.1288\n",
      "Epoch 21/48\n",
      "53/53 - 1s - 20ms/step - accuracy: 0.6440 - loss: 1.1243\n",
      "Epoch 22/48\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.6440 - loss: 1.1195\n",
      "Epoch 23/48\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.6440 - loss: 1.1145\n",
      "Epoch 24/48\n",
      "53/53 - 1s - 23ms/step - accuracy: 0.6440 - loss: 1.1097\n",
      "Epoch 25/48\n",
      "53/53 - 1s - 25ms/step - accuracy: 0.6440 - loss: 1.1045\n",
      "Epoch 26/48\n",
      "53/53 - 1s - 25ms/step - accuracy: 0.6440 - loss: 1.0994\n",
      "Epoch 27/48\n",
      "53/53 - 1s - 20ms/step - accuracy: 0.6440 - loss: 1.0947\n",
      "Epoch 28/48\n",
      "53/53 - 1s - 20ms/step - accuracy: 0.6440 - loss: 1.0897\n",
      "Epoch 29/48\n",
      "53/53 - 1s - 20ms/step - accuracy: 0.6440 - loss: 1.0853\n",
      "Epoch 30/48\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.6440 - loss: 1.0810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/48\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.6440 - loss: 1.0773\n",
      "Epoch 32/48\n",
      "53/53 - 1s - 20ms/step - accuracy: 0.6440 - loss: 1.0732\n",
      "Epoch 33/48\n",
      "53/53 - 1s - 20ms/step - accuracy: 0.6440 - loss: 1.0701\n",
      "Epoch 34/48\n",
      "53/53 - 1s - 19ms/step - accuracy: 0.6440 - loss: 1.0668\n",
      "Epoch 35/48\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.6440 - loss: 1.0638\n",
      "Epoch 36/48\n",
      "53/53 - 1s - 20ms/step - accuracy: 0.6440 - loss: 1.0609\n",
      "Epoch 37/48\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.6440 - loss: 1.0587\n",
      "Epoch 38/48\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.6440 - loss: 1.0566\n",
      "Epoch 39/48\n",
      "53/53 - 1s - 24ms/step - accuracy: 0.6440 - loss: 1.0543\n",
      "Epoch 40/48\n",
      "53/53 - 1s - 26ms/step - accuracy: 0.6440 - loss: 1.0525\n",
      "Epoch 41/48\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.6440 - loss: 1.0504\n",
      "Epoch 42/48\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.6440 - loss: 1.0486\n",
      "Epoch 43/48\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.6440 - loss: 1.0474\n",
      "Epoch 44/48\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.6440 - loss: 1.0454\n",
      "Epoch 45/48\n",
      "53/53 - 1s - 18ms/step - accuracy: 0.6440 - loss: 1.0439\n",
      "Epoch 46/48\n",
      "53/53 - 1s - 20ms/step - accuracy: 0.6440 - loss: 1.0423\n",
      "Epoch 47/48\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.6440 - loss: 1.0410\n",
      "Epoch 48/48\n",
      "53/53 - 1s - 19ms/step - accuracy: 0.6440 - loss: 1.0394\n",
      "14/14 - 0s - 33ms/step\n",
      "Epoch 1/48\n",
      "53/53 - 4s - 69ms/step - accuracy: 0.1607 - loss: 2.6061\n",
      "Epoch 2/48\n",
      "53/53 - 1s - 24ms/step - accuracy: 0.5980 - loss: 1.5599\n",
      "Epoch 3/48\n",
      "53/53 - 2s - 44ms/step - accuracy: 0.6439 - loss: 1.3056\n",
      "Epoch 4/48\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.6439 - loss: 1.2359\n",
      "Epoch 5/48\n",
      "53/53 - 1s - 18ms/step - accuracy: 0.6439 - loss: 1.2040\n",
      "Epoch 6/48\n",
      "53/53 - 1s - 19ms/step - accuracy: 0.6439 - loss: 1.1837\n",
      "Epoch 7/48\n",
      "53/53 - 1s - 17ms/step - accuracy: 0.6439 - loss: 1.1688\n",
      "Epoch 8/48\n",
      "53/53 - 1s - 19ms/step - accuracy: 0.6439 - loss: 1.1566\n",
      "Epoch 9/48\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.6439 - loss: 1.1465\n",
      "Epoch 10/48\n",
      "53/53 - 1s - 23ms/step - accuracy: 0.6439 - loss: 1.1376\n",
      "Epoch 11/48\n",
      "53/53 - 1s - 25ms/step - accuracy: 0.6439 - loss: 1.1294\n",
      "Epoch 12/48\n",
      "53/53 - 1s - 24ms/step - accuracy: 0.6439 - loss: 1.1223\n",
      "Epoch 13/48\n",
      "53/53 - 1s - 27ms/step - accuracy: 0.6439 - loss: 1.1156\n",
      "Epoch 14/48\n",
      "53/53 - 2s - 28ms/step - accuracy: 0.6439 - loss: 1.1090\n",
      "Epoch 15/48\n",
      "53/53 - 2s - 43ms/step - accuracy: 0.6439 - loss: 1.1034\n",
      "Epoch 16/48\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.6439 - loss: 1.0979\n",
      "Epoch 17/48\n",
      "53/53 - 1s - 20ms/step - accuracy: 0.6439 - loss: 1.0923\n",
      "Epoch 18/48\n",
      "53/53 - 1s - 20ms/step - accuracy: 0.6439 - loss: 1.0874\n",
      "Epoch 19/48\n",
      "53/53 - 1s - 20ms/step - accuracy: 0.6439 - loss: 1.0825\n",
      "Epoch 20/48\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.6439 - loss: 1.0784\n",
      "Epoch 21/48\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.6439 - loss: 1.0737\n",
      "Epoch 22/48\n",
      "53/53 - 1s - 19ms/step - accuracy: 0.6438 - loss: 1.0698\n",
      "Epoch 23/48\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.6438 - loss: 1.0660\n",
      "Epoch 24/48\n",
      "53/53 - 1s - 23ms/step - accuracy: 0.6427 - loss: 1.0627\n",
      "Epoch 25/48\n",
      "53/53 - 1s - 23ms/step - accuracy: 0.6427 - loss: 1.0600\n",
      "Epoch 26/48\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.6426 - loss: 1.0566\n",
      "Epoch 27/48\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.6423 - loss: 1.0542\n",
      "Epoch 28/48\n",
      "53/53 - 1s - 25ms/step - accuracy: 0.6426 - loss: 1.0516\n",
      "Epoch 29/48\n",
      "53/53 - 1s - 24ms/step - accuracy: 0.6425 - loss: 1.0491\n",
      "Epoch 30/48\n",
      "53/53 - 1s - 23ms/step - accuracy: 0.6434 - loss: 1.0473\n",
      "Epoch 31/48\n",
      "53/53 - 1s - 25ms/step - accuracy: 0.6436 - loss: 1.0448\n",
      "Epoch 32/48\n",
      "53/53 - 1s - 26ms/step - accuracy: 0.6442 - loss: 1.0432\n",
      "Epoch 33/48\n",
      "53/53 - 1s - 25ms/step - accuracy: 0.6449 - loss: 1.0410\n",
      "Epoch 34/48\n",
      "53/53 - 1s - 26ms/step - accuracy: 0.6442 - loss: 1.0396\n",
      "Epoch 35/48\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.6444 - loss: 1.0372\n",
      "Epoch 36/48\n",
      "53/53 - 1s - 19ms/step - accuracy: 0.6452 - loss: 1.0358\n",
      "Epoch 37/48\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.6461 - loss: 1.0343\n",
      "Epoch 38/48\n",
      "53/53 - 1s - 19ms/step - accuracy: 0.6444 - loss: 1.0322\n",
      "Epoch 39/48\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.6468 - loss: 1.0306\n",
      "Epoch 40/48\n",
      "53/53 - 1s - 23ms/step - accuracy: 0.6480 - loss: 1.0285\n",
      "Epoch 41/48\n",
      "53/53 - 1s - 25ms/step - accuracy: 0.6474 - loss: 1.0272\n",
      "Epoch 42/48\n",
      "53/53 - 1s - 26ms/step - accuracy: 0.6486 - loss: 1.0254\n",
      "Epoch 43/48\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.6492 - loss: 1.0239\n",
      "Epoch 44/48\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.6499 - loss: 1.0221\n",
      "Epoch 45/48\n",
      "53/53 - 1s - 19ms/step - accuracy: 0.6521 - loss: 1.0206\n",
      "Epoch 46/48\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.6518 - loss: 1.0189\n",
      "Epoch 47/48\n",
      "53/53 - 1s - 20ms/step - accuracy: 0.6530 - loss: 1.0173\n",
      "Epoch 48/48\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.6537 - loss: 1.0149\n",
      "14/14 - 1s - 36ms/step\n",
      "Epoch 1/48\n",
      "53/53 - 4s - 66ms/step - accuracy: 0.5167 - loss: 1.6571\n",
      "Epoch 2/48\n",
      "53/53 - 1s - 19ms/step - accuracy: 0.6440 - loss: 1.2221\n",
      "Epoch 3/48\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.6440 - loss: 1.1666\n",
      "Epoch 4/48\n",
      "53/53 - 1s - 24ms/step - accuracy: 0.6440 - loss: 1.1464\n",
      "Epoch 5/48\n",
      "53/53 - 2s - 46ms/step - accuracy: 0.6440 - loss: 1.1339\n",
      "Epoch 6/48\n",
      "53/53 - 1s - 26ms/step - accuracy: 0.6440 - loss: 1.1250\n",
      "Epoch 7/48\n",
      "53/53 - 1s - 26ms/step - accuracy: 0.6440 - loss: 1.1172\n",
      "Epoch 8/48\n",
      "53/53 - 1s - 25ms/step - accuracy: 0.6440 - loss: 1.1103\n",
      "Epoch 9/48\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.6440 - loss: 1.1043\n",
      "Epoch 10/48\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.6440 - loss: 1.0988\n",
      "Epoch 11/48\n",
      "53/53 - 1s - 23ms/step - accuracy: 0.6440 - loss: 1.0938\n",
      "Epoch 12/48\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.6440 - loss: 1.0894\n",
      "Epoch 13/48\n",
      "53/53 - 1s - 20ms/step - accuracy: 0.6440 - loss: 1.0852\n",
      "Epoch 14/48\n",
      "53/53 - 1s - 20ms/step - accuracy: 0.6440 - loss: 1.0811\n",
      "Epoch 15/48\n",
      "53/53 - 2s - 29ms/step - accuracy: 0.6440 - loss: 1.0776\n",
      "Epoch 16/48\n",
      "53/53 - 1s - 26ms/step - accuracy: 0.6440 - loss: 1.0741\n",
      "Epoch 17/48\n",
      "53/53 - 1s - 25ms/step - accuracy: 0.6440 - loss: 1.0712\n",
      "Epoch 18/48\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.6440 - loss: 1.0680\n",
      "Epoch 19/48\n",
      "53/53 - 1s - 19ms/step - accuracy: 0.6440 - loss: 1.0654\n",
      "Epoch 20/48\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.6440 - loss: 1.0634\n",
      "Epoch 21/48\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.6440 - loss: 1.0611\n",
      "Epoch 22/48\n",
      "53/53 - 1s - 23ms/step - accuracy: 0.6440 - loss: 1.0586\n",
      "Epoch 23/48\n",
      "53/53 - 1s - 19ms/step - accuracy: 0.6440 - loss: 1.0567\n",
      "Epoch 24/48\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.6440 - loss: 1.0548\n",
      "Epoch 25/48\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.6440 - loss: 1.0531\n",
      "Epoch 26/48\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.6440 - loss: 1.0514\n",
      "Epoch 27/48\n",
      "53/53 - 1s - 19ms/step - accuracy: 0.6440 - loss: 1.0496\n",
      "Epoch 28/48\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.6440 - loss: 1.0482\n",
      "Epoch 29/48\n",
      "53/53 - 1s - 26ms/step - accuracy: 0.6440 - loss: 1.0465\n",
      "Epoch 30/48\n",
      "53/53 - 1s - 26ms/step - accuracy: 0.6440 - loss: 1.0454\n",
      "Epoch 31/48\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.6440 - loss: 1.0439\n",
      "Epoch 32/48\n",
      "53/53 - 1s - 20ms/step - accuracy: 0.6440 - loss: 1.0425\n",
      "Epoch 33/48\n",
      "53/53 - 1s - 23ms/step - accuracy: 0.6440 - loss: 1.0408\n",
      "Epoch 34/48\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.6440 - loss: 1.0397\n",
      "Epoch 35/48\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.6440 - loss: 1.0380\n",
      "Epoch 36/48\n",
      "53/53 - 1s - 20ms/step - accuracy: 0.6440 - loss: 1.0364\n",
      "Epoch 37/48\n",
      "53/53 - 1s - 20ms/step - accuracy: 0.6441 - loss: 1.0358\n",
      "Epoch 38/48\n",
      "53/53 - 1s - 19ms/step - accuracy: 0.6440 - loss: 1.0345\n",
      "Epoch 39/48\n",
      "53/53 - 1s - 20ms/step - accuracy: 0.6440 - loss: 1.0336\n",
      "Epoch 40/48\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.6441 - loss: 1.0320\n",
      "Epoch 41/48\n",
      "53/53 - 1s - 18ms/step - accuracy: 0.6439 - loss: 1.0307\n",
      "Epoch 42/48\n",
      "53/53 - 789s - 15s/step - accuracy: 0.6441 - loss: 1.0300\n",
      "Epoch 43/48\n",
      "53/53 - 4s - 68ms/step - accuracy: 0.6441 - loss: 1.0283\n",
      "Epoch 44/48\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.6441 - loss: 1.0273\n",
      "Epoch 45/48\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.6444 - loss: 1.0256\n",
      "Epoch 46/48\n",
      "53/53 - 1s - 18ms/step - accuracy: 0.6442 - loss: 1.0248\n",
      "Epoch 47/48\n",
      "53/53 - 1s - 15ms/step - accuracy: 0.6444 - loss: 1.0230\n",
      "Epoch 48/48\n",
      "53/53 - 1s - 11ms/step - accuracy: 0.6443 - loss: 1.0221\n",
      "14/14 - 0s - 18ms/step\n",
      "Epoch 1/48\n",
      "53/53 - 2s - 44ms/step - accuracy: 0.6231 - loss: 1.5771\n",
      "Epoch 2/48\n",
      "53/53 - 1s - 12ms/step - accuracy: 0.6439 - loss: 1.2631\n",
      "Epoch 3/48\n",
      "53/53 - 1s - 11ms/step - accuracy: 0.6439 - loss: 1.2021\n",
      "Epoch 4/48\n",
      "53/53 - 1s - 11ms/step - accuracy: 0.6439 - loss: 1.1766\n",
      "Epoch 5/48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 1s - 12ms/step - accuracy: 0.6439 - loss: 1.1615\n",
      "Epoch 6/48\n",
      "53/53 - 1s - 13ms/step - accuracy: 0.6439 - loss: 1.1506\n",
      "Epoch 7/48\n",
      "53/53 - 1s - 25ms/step - accuracy: 0.6439 - loss: 1.1419\n",
      "Epoch 8/48\n",
      "53/53 - 1s - 14ms/step - accuracy: 0.6439 - loss: 1.1343\n",
      "Epoch 9/48\n",
      "53/53 - 1s - 18ms/step - accuracy: 0.6439 - loss: 1.1278\n",
      "Epoch 10/48\n",
      "53/53 - 1s - 20ms/step - accuracy: 0.6439 - loss: 1.1218\n",
      "Epoch 11/48\n",
      "53/53 - 1s - 18ms/step - accuracy: 0.6439 - loss: 1.1166\n",
      "Epoch 12/48\n",
      "53/53 - 1s - 15ms/step - accuracy: 0.6439 - loss: 1.1116\n",
      "Epoch 13/48\n",
      "53/53 - 1s - 15ms/step - accuracy: 0.6439 - loss: 1.1067\n",
      "Epoch 14/48\n",
      "53/53 - 1s - 15ms/step - accuracy: 0.6439 - loss: 1.1024\n",
      "Epoch 15/48\n",
      "53/53 - 1s - 16ms/step - accuracy: 0.6439 - loss: 1.0985\n",
      "Epoch 16/48\n",
      "53/53 - 1s - 15ms/step - accuracy: 0.6439 - loss: 1.0947\n",
      "Epoch 17/48\n",
      "53/53 - 1s - 16ms/step - accuracy: 0.6439 - loss: 1.0912\n",
      "Epoch 18/48\n",
      "53/53 - 1s - 16ms/step - accuracy: 0.6439 - loss: 1.0880\n",
      "Epoch 19/48\n",
      "53/53 - 1s - 24ms/step - accuracy: 0.6439 - loss: 1.0853\n",
      "Epoch 20/48\n",
      "53/53 - 1s - 16ms/step - accuracy: 0.6439 - loss: 1.0821\n",
      "Epoch 21/48\n",
      "53/53 - 1s - 15ms/step - accuracy: 0.6439 - loss: 1.0795\n",
      "Epoch 22/48\n",
      "53/53 - 1s - 15ms/step - accuracy: 0.6439 - loss: 1.0770\n",
      "Epoch 23/48\n",
      "53/53 - 1s - 23ms/step - accuracy: 0.6439 - loss: 1.0745\n",
      "Epoch 24/48\n",
      "53/53 - 1s - 14ms/step - accuracy: 0.6439 - loss: 1.0720\n",
      "Epoch 25/48\n",
      "53/53 - 1s - 14ms/step - accuracy: 0.6439 - loss: 1.0699\n",
      "Epoch 26/48\n",
      "53/53 - 1s - 14ms/step - accuracy: 0.6439 - loss: 1.0678\n",
      "Epoch 27/48\n",
      "53/53 - 1s - 19ms/step - accuracy: 0.6439 - loss: 1.0651\n",
      "Epoch 28/48\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.6439 - loss: 1.0640\n",
      "Epoch 29/48\n",
      "53/53 - 1s - 16ms/step - accuracy: 0.6439 - loss: 1.0618\n",
      "Epoch 30/48\n",
      "53/53 - 1s - 15ms/step - accuracy: 0.6439 - loss: 1.0602\n",
      "Epoch 31/48\n",
      "53/53 - 1s - 15ms/step - accuracy: 0.6439 - loss: 1.0580\n",
      "Epoch 32/48\n",
      "53/53 - 1s - 15ms/step - accuracy: 0.6439 - loss: 1.0563\n",
      "Epoch 33/48\n",
      "53/53 - 1s - 24ms/step - accuracy: 0.6439 - loss: 1.0544\n",
      "Epoch 34/48\n",
      "53/53 - 1s - 15ms/step - accuracy: 0.6439 - loss: 1.0528\n",
      "Epoch 35/48\n",
      "53/53 - 1s - 15ms/step - accuracy: 0.6439 - loss: 1.0511\n",
      "Epoch 36/48\n",
      "53/53 - 1s - 15ms/step - accuracy: 0.6439 - loss: 1.0494\n",
      "Epoch 37/48\n",
      "53/53 - 1s - 15ms/step - accuracy: 0.6439 - loss: 1.0477\n",
      "Epoch 38/48\n",
      "53/53 - 1s - 24ms/step - accuracy: 0.6440 - loss: 1.0459\n",
      "Epoch 39/48\n",
      "53/53 - 1s - 15ms/step - accuracy: 0.6439 - loss: 1.0445\n",
      "Epoch 40/48\n",
      "53/53 - 1s - 23ms/step - accuracy: 0.6439 - loss: 1.0421\n",
      "Epoch 41/48\n",
      "53/53 - 1s - 23ms/step - accuracy: 0.6439 - loss: 1.0407\n",
      "Epoch 42/48\n",
      "53/53 - 1s - 14ms/step - accuracy: 0.6440 - loss: 1.0390\n",
      "Epoch 43/48\n",
      "53/53 - 1s - 13ms/step - accuracy: 0.6439 - loss: 1.0370\n",
      "Epoch 44/48\n",
      "53/53 - 541s - 10s/step - accuracy: 0.6441 - loss: 1.0352\n",
      "Epoch 45/48\n",
      "53/53 - 2s - 29ms/step - accuracy: 0.6441 - loss: 1.0340\n",
      "Epoch 46/48\n",
      "53/53 - 1s - 26ms/step - accuracy: 0.6444 - loss: 1.0322\n",
      "Epoch 47/48\n",
      "53/53 - 2s - 41ms/step - accuracy: 0.6448 - loss: 1.0302\n",
      "Epoch 48/48\n",
      "53/53 - 1s - 19ms/step - accuracy: 0.6447 - loss: 1.0286\n",
      "14/14 - 0s - 22ms/step\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m0.6476   \u001b[39m | \u001b[39m2.059    \u001b[39m | \u001b[39m261.6    \u001b[39m | \u001b[39m0.2898   \u001b[39m | \u001b[39m0.04837  \u001b[39m | \u001b[39m47.89    \u001b[39m | \u001b[39m2.616    \u001b[39m | \u001b[39m2.267    \u001b[39m | \u001b[39m2.743    \u001b[39m | \u001b[39m0.8056   \u001b[39m | \u001b[39m26.79    \u001b[39m | \u001b[39m0.8926   \u001b[39m | \u001b[39m3.775    \u001b[39m |\n",
      "Epoch 1/27\n",
      "16/16 - 5s - 285ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 2/27\n",
      "16/16 - 2s - 128ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 3/27\n",
      "16/16 - 2s - 131ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 4/27\n",
      "16/16 - 2s - 108ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 5/27\n",
      "16/16 - 2s - 148ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 6/27\n",
      "16/16 - 2s - 154ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 7/27\n",
      "16/16 - 3s - 158ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 8/27\n",
      "16/16 - 1s - 88ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 9/27\n",
      "16/16 - 3s - 157ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 10/27\n",
      "16/16 - 1s - 85ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 11/27\n",
      "16/16 - 2s - 107ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 12/27\n",
      "16/16 - 1s - 90ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 13/27\n",
      "16/16 - 1s - 91ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 14/27\n",
      "16/16 - 1s - 88ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 15/27\n",
      "16/16 - 2s - 156ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 16/27\n",
      "16/16 - 1s - 89ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 17/27\n",
      "16/16 - 2s - 115ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 18/27\n",
      "16/16 - 2s - 108ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 19/27\n",
      "16/16 - 2s - 110ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 20/27\n",
      "16/16 - 2s - 144ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 21/27\n",
      "16/16 - 2s - 111ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 22/27\n",
      "16/16 - 3s - 159ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 23/27\n",
      "16/16 - 2s - 98ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 24/27\n",
      "16/16 - 2s - 99ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 25/27\n",
      "16/16 - 2s - 106ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 26/27\n",
      "16/16 - 2s - 107ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 27/27\n",
      "16/16 - 2s - 123ms/step - accuracy: 0.6440 - loss: nan\n",
      "4/4 - 0s - 109ms/step\n",
      "Epoch 1/27\n",
      "16/16 - 3s - 217ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 2/27\n",
      "16/16 - 2s - 95ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 3/27\n",
      "16/16 - 2s - 111ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 4/27\n",
      "16/16 - 2s - 103ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 5/27\n",
      "16/16 - 2s - 153ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 6/27\n",
      "16/16 - 2s - 109ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 7/27\n",
      "16/16 - 2s - 123ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 8/27\n",
      "16/16 - 2s - 127ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 9/27\n",
      "16/16 - 2s - 128ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 10/27\n",
      "16/16 - 2s - 109ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 11/27\n",
      "16/16 - 2s - 107ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 12/27\n",
      "16/16 - 2s - 102ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 13/27\n",
      "16/16 - 2s - 104ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 14/27\n",
      "16/16 - 2s - 104ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 15/27\n",
      "16/16 - 2s - 103ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 16/27\n",
      "16/16 - 2s - 111ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 17/27\n",
      "16/16 - 2s - 114ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 18/27\n",
      "16/16 - 2s - 138ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 19/27\n",
      "16/16 - 2s - 132ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 20/27\n",
      "16/16 - 2s - 114ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 21/27\n",
      "16/16 - 2s - 103ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 22/27\n",
      "16/16 - 2s - 103ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 23/27\n",
      "16/16 - 2s - 103ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 24/27\n",
      "16/16 - 2s - 102ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 25/27\n",
      "16/16 - 2s - 103ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 26/27\n",
      "16/16 - 2s - 104ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 27/27\n",
      "16/16 - 2s - 103ms/step - accuracy: 0.6440 - loss: nan\n",
      "4/4 - 0s - 95ms/step\n",
      "Epoch 1/27\n",
      "16/16 - 4s - 253ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 2/27\n",
      "16/16 - 3s - 159ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 3/27\n",
      "16/16 - 2s - 106ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 4/27\n",
      "16/16 - 3s - 157ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 5/27\n",
      "16/16 - 2s - 103ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 6/27\n",
      "16/16 - 2s - 108ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 7/27\n",
      "16/16 - 2s - 108ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 8/27\n",
      "16/16 - 1s - 92ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 9/27\n",
      "16/16 - 1s - 92ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 10/27\n",
      "16/16 - 1s - 93ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 11/27\n",
      "16/16 - 1s - 92ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 12/27\n",
      "16/16 - 1s - 92ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 13/27\n",
      "16/16 - 1s - 90ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 14/27\n",
      "16/16 - 1s - 92ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 15/27\n",
      "16/16 - 1s - 92ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 16/27\n",
      "16/16 - 1s - 94ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 17/27\n",
      "16/16 - 1s - 93ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 18/27\n",
      "16/16 - 1s - 90ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 19/27\n",
      "16/16 - 1s - 91ms/step - accuracy: 0.6439 - loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/27\n",
      "16/16 - 3s - 168ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 21/27\n",
      "16/16 - 1s - 89ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 22/27\n",
      "16/16 - 1s - 90ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 23/27\n",
      "16/16 - 1s - 90ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 24/27\n",
      "16/16 - 1s - 89ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 25/27\n",
      "16/16 - 1s - 90ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 26/27\n",
      "16/16 - 1s - 91ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 27/27\n",
      "16/16 - 3s - 158ms/step - accuracy: 0.6439 - loss: nan\n",
      "4/4 - 0s - 76ms/step\n",
      "Epoch 1/27\n",
      "16/16 - 4s - 254ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 2/27\n",
      "16/16 - 2s - 103ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 3/27\n",
      "16/16 - 2s - 155ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 4/27\n",
      "16/16 - 2s - 106ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 5/27\n",
      "16/16 - 1s - 93ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 6/27\n",
      "16/16 - 3s - 160ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 7/27\n",
      "16/16 - 1s - 92ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 8/27\n",
      "16/16 - 1s - 92ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 9/27\n",
      "16/16 - 2s - 118ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 10/27\n",
      "16/16 - 2s - 111ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 11/27\n",
      "16/16 - 1s - 94ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 12/27\n",
      "16/16 - 1s - 88ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 13/27\n",
      "16/16 - 1s - 92ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 14/27\n",
      "16/16 - 2s - 101ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 15/27\n",
      "16/16 - 2s - 107ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 16/27\n",
      "16/16 - 2s - 151ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 17/27\n",
      "16/16 - 2s - 145ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 18/27\n",
      "16/16 - 2s - 130ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 19/27\n",
      "16/16 - 2s - 129ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 20/27\n",
      "16/16 - 2s - 119ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 21/27\n",
      "16/16 - 2s - 154ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 22/27\n",
      "16/16 - 3s - 165ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 23/27\n",
      "16/16 - 2s - 119ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 24/27\n",
      "16/16 - 2s - 126ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 25/27\n",
      "16/16 - 2s - 104ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 26/27\n",
      "16/16 - 2s - 120ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 27/27\n",
      "16/16 - 2s - 98ms/step - accuracy: 0.6440 - loss: nan\n",
      "4/4 - 1s - 148ms/step\n",
      "Epoch 1/27\n",
      "16/16 - 4s - 225ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 2/27\n",
      "16/16 - 2s - 120ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 3/27\n",
      "16/16 - 2s - 100ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 4/27\n",
      "16/16 - 2s - 130ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 5/27\n",
      "16/16 - 2s - 132ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 6/27\n",
      "16/16 - 2s - 110ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 7/27\n",
      "16/16 - 2s - 99ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 8/27\n",
      "16/16 - 1s - 93ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 9/27\n",
      "16/16 - 1s - 91ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 10/27\n",
      "16/16 - 2s - 103ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 11/27\n",
      "16/16 - 2s - 107ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 12/27\n",
      "16/16 - 2s - 108ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 13/27\n",
      "16/16 - 2s - 120ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 14/27\n",
      "16/16 - 2s - 96ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 15/27\n",
      "16/16 - 1s - 88ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 16/27\n",
      "16/16 - 2s - 94ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 17/27\n",
      "16/16 - 2s - 103ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 18/27\n",
      "16/16 - 2s - 94ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 19/27\n",
      "16/16 - 2s - 94ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 20/27\n",
      "16/16 - 1s - 93ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 21/27\n",
      "16/16 - 1s - 88ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 22/27\n",
      "16/16 - 2s - 100ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 23/27\n",
      "16/16 - 2s - 100ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 24/27\n",
      "16/16 - 1s - 92ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 25/27\n",
      "16/16 - 2s - 95ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 26/27\n",
      "16/16 - 1s - 92ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 27/27\n",
      "16/16 - 1s - 83ms/step - accuracy: 0.6439 - loss: nan\n",
      "4/4 - 0s - 86ms/step\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39m0.644    \u001b[39m | \u001b[39m7.267    \u001b[39m | \u001b[39m916.9    \u001b[39m | \u001b[39m0.318    \u001b[39m | \u001b[39m0.03302  \u001b[39m | \u001b[39m26.84    \u001b[39m | \u001b[39m1.854    \u001b[39m | \u001b[39m2.636    \u001b[39m | \u001b[39m2.721    \u001b[39m | \u001b[39m0.01688  \u001b[39m | \u001b[39m55.97    \u001b[39m | \u001b[39m0.4174   \u001b[39m | \u001b[39m1.555    \u001b[39m |\n",
      "Epoch 1/36\n",
      "30/30 - 2s - 79ms/step - accuracy: 0.6224 - loss: 1.3410\n",
      "Epoch 2/36\n",
      "30/30 - 1s - 20ms/step - accuracy: 0.6440 - loss: 1.1680\n",
      "Epoch 3/36\n",
      "30/30 - 1s - 22ms/step - accuracy: 0.6440 - loss: 1.1657\n",
      "Epoch 4/36\n",
      "30/30 - 1s - 22ms/step - accuracy: 0.6440 - loss: 1.1652\n",
      "Epoch 5/36\n",
      "30/30 - 1s - 20ms/step - accuracy: 0.6440 - loss: 1.1663\n",
      "Epoch 6/36\n",
      "30/30 - 1s - 24ms/step - accuracy: 0.6440 - loss: 1.1657\n",
      "Epoch 7/36\n",
      "30/30 - 1s - 22ms/step - accuracy: 0.6440 - loss: 1.1664\n",
      "Epoch 8/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6440 - loss: 1.1646\n",
      "Epoch 9/36\n",
      "30/30 - 1s - 19ms/step - accuracy: 0.6440 - loss: 1.1657\n",
      "Epoch 10/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6440 - loss: 1.1654\n",
      "Epoch 11/36\n",
      "30/30 - 1s - 19ms/step - accuracy: 0.6440 - loss: 1.1651\n",
      "Epoch 12/36\n",
      "30/30 - 1s - 25ms/step - accuracy: 0.6440 - loss: 1.1658\n",
      "Epoch 13/36\n",
      "30/30 - 1s - 24ms/step - accuracy: 0.6440 - loss: 1.1640\n",
      "Epoch 14/36\n",
      "30/30 - 1s - 20ms/step - accuracy: 0.6440 - loss: 1.1643\n",
      "Epoch 15/36\n",
      "30/30 - 1s - 20ms/step - accuracy: 0.6440 - loss: 1.1646\n",
      "Epoch 16/36\n",
      "30/30 - 1s - 19ms/step - accuracy: 0.6440 - loss: 1.1661\n",
      "Epoch 17/36\n",
      "30/30 - 1s - 20ms/step - accuracy: 0.6440 - loss: 1.1643\n",
      "Epoch 18/36\n",
      "30/30 - 1s - 20ms/step - accuracy: 0.6440 - loss: 1.1641\n",
      "Epoch 19/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6440 - loss: 1.1645\n",
      "Epoch 20/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6440 - loss: 1.1630\n",
      "Epoch 21/36\n",
      "30/30 - 1s - 19ms/step - accuracy: 0.6440 - loss: 1.1637\n",
      "Epoch 22/36\n",
      "30/30 - 1s - 21ms/step - accuracy: 0.6440 - loss: 1.1628\n",
      "Epoch 23/36\n",
      "30/30 - 1s - 20ms/step - accuracy: 0.6440 - loss: 1.1622\n",
      "Epoch 24/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6440 - loss: 1.1609\n",
      "Epoch 25/36\n",
      "30/30 - 1s - 17ms/step - accuracy: 0.6440 - loss: 1.1575\n",
      "Epoch 26/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6440 - loss: 1.1522\n",
      "Epoch 27/36\n",
      "30/30 - 1s - 22ms/step - accuracy: 0.6440 - loss: 1.1405\n",
      "Epoch 28/36\n",
      "30/30 - 1s - 19ms/step - accuracy: 0.6440 - loss: 1.1124\n",
      "Epoch 29/36\n",
      "30/30 - 1s - 20ms/step - accuracy: 0.6440 - loss: 1.0766\n",
      "Epoch 30/36\n",
      "30/30 - 1s - 17ms/step - accuracy: 0.6437 - loss: 1.0502\n",
      "Epoch 31/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6404 - loss: 1.0342\n",
      "Epoch 32/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6389 - loss: 1.0245\n",
      "Epoch 33/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6371 - loss: 1.0162\n",
      "Epoch 34/36\n",
      "30/30 - 1s - 26ms/step - accuracy: 0.6431 - loss: 1.0060\n",
      "Epoch 35/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6345 - loss: 0.9992\n",
      "Epoch 36/36\n",
      "30/30 - 1s - 17ms/step - accuracy: 0.6437 - loss: 0.9908\n",
      "8/8 - 0s - 27ms/step\n",
      "Epoch 1/36\n",
      "30/30 - 2s - 72ms/step - accuracy: 0.5785 - loss: 1.4407\n",
      "Epoch 2/36\n",
      "30/30 - 1s - 22ms/step - accuracy: 0.6440 - loss: 1.1691\n",
      "Epoch 3/36\n",
      "30/30 - 1s - 42ms/step - accuracy: 0.6440 - loss: 1.1663\n",
      "Epoch 4/36\n",
      "30/30 - 1s - 26ms/step - accuracy: 0.6440 - loss: 1.1644\n",
      "Epoch 5/36\n",
      "30/30 - 1s - 22ms/step - accuracy: 0.6440 - loss: 1.1654\n",
      "Epoch 6/36\n",
      "30/30 - 1s - 24ms/step - accuracy: 0.6440 - loss: 1.1644\n",
      "Epoch 7/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6440 - loss: 1.1649\n",
      "Epoch 8/36\n",
      "30/30 - 1s - 19ms/step - accuracy: 0.6440 - loss: 1.1654\n",
      "Epoch 9/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6440 - loss: 1.1662\n",
      "Epoch 10/36\n",
      "30/30 - 1s - 19ms/step - accuracy: 0.6440 - loss: 1.1643\n",
      "Epoch 11/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6440 - loss: 1.1647\n",
      "Epoch 12/36\n",
      "30/30 - 1s - 23ms/step - accuracy: 0.6440 - loss: 1.1645\n",
      "Epoch 13/36\n",
      "30/30 - 1s - 20ms/step - accuracy: 0.6440 - loss: 1.1642\n",
      "Epoch 14/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6440 - loss: 1.1626\n",
      "Epoch 15/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6440 - loss: 1.1637\n",
      "Epoch 16/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6440 - loss: 1.1624\n",
      "Epoch 17/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6440 - loss: 1.1628\n",
      "Epoch 18/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6440 - loss: 1.1627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6440 - loss: 1.1599\n",
      "Epoch 20/36\n",
      "30/30 - 1s - 22ms/step - accuracy: 0.6440 - loss: 1.1581\n",
      "Epoch 21/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6440 - loss: 1.1523\n",
      "Epoch 22/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6440 - loss: 1.1354\n",
      "Epoch 23/36\n",
      "30/30 - 1s - 21ms/step - accuracy: 0.6440 - loss: 1.1042\n",
      "Epoch 24/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6440 - loss: 1.0663\n",
      "Epoch 25/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6439 - loss: 1.0437\n",
      "Epoch 26/36\n",
      "30/30 - 1s - 23ms/step - accuracy: 0.6433 - loss: 1.0294\n",
      "Epoch 27/36\n",
      "30/30 - 1s - 26ms/step - accuracy: 0.6419 - loss: 1.0170\n",
      "Epoch 28/36\n",
      "30/30 - 1s - 20ms/step - accuracy: 0.6433 - loss: 1.0072\n",
      "Epoch 29/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6423 - loss: 0.9979\n",
      "Epoch 30/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6417 - loss: 0.9870\n",
      "Epoch 31/36\n",
      "30/30 - 1s - 26ms/step - accuracy: 0.6425 - loss: 0.9764\n",
      "Epoch 32/36\n",
      "30/30 - 1s - 17ms/step - accuracy: 0.6433 - loss: 0.9675\n",
      "Epoch 33/36\n",
      "30/30 - 1s - 21ms/step - accuracy: 0.6422 - loss: 0.9602\n",
      "Epoch 34/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6445 - loss: 0.9474\n",
      "Epoch 35/36\n",
      "30/30 - 1s - 24ms/step - accuracy: 0.6478 - loss: 0.9370\n",
      "Epoch 36/36\n",
      "30/30 - 1s - 17ms/step - accuracy: 0.6523 - loss: 0.9271\n",
      "8/8 - 0s - 50ms/step\n",
      "Epoch 1/36\n",
      "30/30 - 2s - 79ms/step - accuracy: 0.5998 - loss: 1.4010\n",
      "Epoch 2/36\n",
      "30/30 - 1s - 25ms/step - accuracy: 0.6439 - loss: 1.1702\n",
      "Epoch 3/36\n",
      "30/30 - 1s - 34ms/step - accuracy: 0.6439 - loss: 1.1664\n",
      "Epoch 4/36\n",
      "30/30 - 1s - 24ms/step - accuracy: 0.6439 - loss: 1.1673\n",
      "Epoch 5/36\n",
      "30/30 - 1s - 26ms/step - accuracy: 0.6439 - loss: 1.1658\n",
      "Epoch 6/36\n",
      "30/30 - 1s - 21ms/step - accuracy: 0.6439 - loss: 1.1646\n",
      "Epoch 7/36\n",
      "30/30 - 1s - 23ms/step - accuracy: 0.6439 - loss: 1.1656\n",
      "Epoch 8/36\n",
      "30/30 - 1s - 20ms/step - accuracy: 0.6439 - loss: 1.1667\n",
      "Epoch 9/36\n",
      "30/30 - 1s - 21ms/step - accuracy: 0.6439 - loss: 1.1646\n",
      "Epoch 10/36\n",
      "30/30 - 1s - 24ms/step - accuracy: 0.6439 - loss: 1.1645\n",
      "Epoch 11/36\n",
      "30/30 - 1s - 19ms/step - accuracy: 0.6439 - loss: 1.1662\n",
      "Epoch 12/36\n",
      "30/30 - 1s - 24ms/step - accuracy: 0.6439 - loss: 1.1657\n",
      "Epoch 13/36\n",
      "30/30 - 1s - 41ms/step - accuracy: 0.6439 - loss: 1.1643\n",
      "Epoch 14/36\n",
      "30/30 - 1s - 25ms/step - accuracy: 0.6439 - loss: 1.1657\n",
      "Epoch 15/36\n",
      "30/30 - 1s - 20ms/step - accuracy: 0.6439 - loss: 1.1635\n",
      "Epoch 16/36\n",
      "30/30 - 1s - 22ms/step - accuracy: 0.6439 - loss: 1.1655\n",
      "Epoch 17/36\n",
      "30/30 - 1s - 19ms/step - accuracy: 0.6439 - loss: 1.1639\n",
      "Epoch 18/36\n",
      "30/30 - 1s - 19ms/step - accuracy: 0.6439 - loss: 1.1651\n",
      "Epoch 19/36\n",
      "30/30 - 1s - 21ms/step - accuracy: 0.6439 - loss: 1.1631\n",
      "Epoch 20/36\n",
      "30/30 - 1s - 29ms/step - accuracy: 0.6439 - loss: 1.1649\n",
      "Epoch 21/36\n",
      "30/30 - 1s - 25ms/step - accuracy: 0.6439 - loss: 1.1653\n",
      "Epoch 22/36\n",
      "30/30 - 1s - 24ms/step - accuracy: 0.6439 - loss: 1.1637\n",
      "Epoch 23/36\n",
      "30/30 - 1s - 39ms/step - accuracy: 0.6439 - loss: 1.1642\n",
      "Epoch 24/36\n",
      "30/30 - 1s - 21ms/step - accuracy: 0.6439 - loss: 1.1632\n",
      "Epoch 25/36\n",
      "30/30 - 1s - 19ms/step - accuracy: 0.6439 - loss: 1.1624\n",
      "Epoch 26/36\n",
      "30/30 - 1s - 20ms/step - accuracy: 0.6439 - loss: 1.1633\n",
      "Epoch 27/36\n",
      "30/30 - 1s - 20ms/step - accuracy: 0.6439 - loss: 1.1619\n",
      "Epoch 28/36\n",
      "30/30 - 1s - 21ms/step - accuracy: 0.6439 - loss: 1.1617\n",
      "Epoch 29/36\n",
      "30/30 - 1s - 24ms/step - accuracy: 0.6439 - loss: 1.1581\n",
      "Epoch 30/36\n",
      "30/30 - 1s - 21ms/step - accuracy: 0.6439 - loss: 1.1530\n",
      "Epoch 31/36\n",
      "30/30 - 1s - 21ms/step - accuracy: 0.6439 - loss: 1.1407\n",
      "Epoch 32/36\n",
      "30/30 - 1s - 21ms/step - accuracy: 0.6439 - loss: 1.1132\n",
      "Epoch 33/36\n",
      "30/30 - 1s - 20ms/step - accuracy: 0.6439 - loss: 1.0767\n",
      "Epoch 34/36\n",
      "30/30 - 1s - 26ms/step - accuracy: 0.6425 - loss: 1.0526\n",
      "Epoch 35/36\n",
      "30/30 - 1s - 27ms/step - accuracy: 0.6408 - loss: 1.0401\n",
      "Epoch 36/36\n",
      "30/30 - 1s - 24ms/step - accuracy: 0.6379 - loss: 1.0310\n",
      "8/8 - 0s - 38ms/step\n",
      "Epoch 1/36\n",
      "30/30 - 2s - 71ms/step - accuracy: 0.6440 - loss: 1.2650\n",
      "Epoch 2/36\n",
      "30/30 - 1s - 19ms/step - accuracy: 0.6440 - loss: 1.1688\n",
      "Epoch 3/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6440 - loss: 1.1655\n",
      "Epoch 4/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6440 - loss: 1.1651\n",
      "Epoch 5/36\n",
      "30/30 - 1s - 19ms/step - accuracy: 0.6440 - loss: 1.1670\n",
      "Epoch 6/36\n",
      "30/30 - 1s - 20ms/step - accuracy: 0.6440 - loss: 1.1650\n",
      "Epoch 7/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6440 - loss: 1.1656\n",
      "Epoch 8/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6440 - loss: 1.1654\n",
      "Epoch 9/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6440 - loss: 1.1654\n",
      "Epoch 10/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6440 - loss: 1.1659\n",
      "Epoch 11/36\n",
      "30/30 - 1s - 19ms/step - accuracy: 0.6440 - loss: 1.1655\n",
      "Epoch 12/36\n",
      "30/30 - 1s - 20ms/step - accuracy: 0.6440 - loss: 1.1640\n",
      "Epoch 13/36\n",
      "30/30 - 1s - 21ms/step - accuracy: 0.6440 - loss: 1.1645\n",
      "Epoch 14/36\n",
      "30/30 - 1s - 19ms/step - accuracy: 0.6440 - loss: 1.1645\n",
      "Epoch 15/36\n",
      "30/30 - 1s - 19ms/step - accuracy: 0.6440 - loss: 1.1638\n",
      "Epoch 16/36\n",
      "30/30 - 1s - 20ms/step - accuracy: 0.6440 - loss: 1.1648\n",
      "Epoch 17/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6440 - loss: 1.1635\n",
      "Epoch 18/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6440 - loss: 1.1645\n",
      "Epoch 19/36\n",
      "30/30 - 1s - 19ms/step - accuracy: 0.6440 - loss: 1.1637\n",
      "Epoch 20/36\n",
      "30/30 - 1s - 21ms/step - accuracy: 0.6440 - loss: 1.1644\n",
      "Epoch 21/36\n",
      "30/30 - 1s - 25ms/step - accuracy: 0.6440 - loss: 1.1637\n",
      "Epoch 22/36\n",
      "30/30 - 1s - 25ms/step - accuracy: 0.6440 - loss: 1.1632\n",
      "Epoch 23/36\n",
      "30/30 - 1s - 24ms/step - accuracy: 0.6440 - loss: 1.1629\n",
      "Epoch 24/36\n",
      "30/30 - 1s - 26ms/step - accuracy: 0.6440 - loss: 1.1625\n",
      "Epoch 25/36\n",
      "30/30 - 1s - 19ms/step - accuracy: 0.6440 - loss: 1.1615\n",
      "Epoch 26/36\n",
      "30/30 - 1s - 20ms/step - accuracy: 0.6440 - loss: 1.1599\n",
      "Epoch 27/36\n",
      "30/30 - 1s - 22ms/step - accuracy: 0.6440 - loss: 1.1573\n",
      "Epoch 28/36\n",
      "30/30 - 1s - 20ms/step - accuracy: 0.6440 - loss: 1.1533\n",
      "Epoch 29/36\n",
      "30/30 - 1s - 22ms/step - accuracy: 0.6440 - loss: 1.1434\n",
      "Epoch 30/36\n",
      "30/30 - 1s - 20ms/step - accuracy: 0.6440 - loss: 1.1213\n",
      "Epoch 31/36\n",
      "30/30 - 1s - 19ms/step - accuracy: 0.6440 - loss: 1.0880\n",
      "Epoch 32/36\n",
      "30/30 - 1s - 19ms/step - accuracy: 0.6439 - loss: 1.0603\n",
      "Epoch 33/36\n",
      "30/30 - 1s - 23ms/step - accuracy: 0.6398 - loss: 1.0433\n",
      "Epoch 34/36\n",
      "30/30 - 1s - 22ms/step - accuracy: 0.6430 - loss: 1.0308\n",
      "Epoch 35/36\n",
      "30/30 - 1s - 25ms/step - accuracy: 0.6427 - loss: 1.0199\n",
      "Epoch 36/36\n",
      "30/30 - 1s - 23ms/step - accuracy: 0.6422 - loss: 1.0122\n",
      "8/8 - 0s - 27ms/step\n",
      "Epoch 1/36\n",
      "30/30 - 2s - 81ms/step - accuracy: 0.6439 - loss: 1.2748\n",
      "Epoch 2/36\n",
      "30/30 - 1s - 21ms/step - accuracy: 0.6439 - loss: 1.1665\n",
      "Epoch 3/36\n",
      "30/30 - 1s - 22ms/step - accuracy: 0.6439 - loss: 1.1648\n",
      "Epoch 4/36\n",
      "30/30 - 1s - 20ms/step - accuracy: 0.6439 - loss: 1.1646\n",
      "Epoch 5/36\n",
      "30/30 - 1s - 28ms/step - accuracy: 0.6439 - loss: 1.1668\n",
      "Epoch 6/36\n",
      "30/30 - 1s - 30ms/step - accuracy: 0.6439 - loss: 1.1661\n",
      "Epoch 7/36\n",
      "30/30 - 1s - 28ms/step - accuracy: 0.6439 - loss: 1.1648\n",
      "Epoch 8/36\n",
      "30/30 - 1s - 22ms/step - accuracy: 0.6439 - loss: 1.1646\n",
      "Epoch 9/36\n",
      "30/30 - 1s - 20ms/step - accuracy: 0.6439 - loss: 1.1650\n",
      "Epoch 10/36\n",
      "30/30 - 1s - 19ms/step - accuracy: 0.6439 - loss: 1.1650\n",
      "Epoch 11/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6439 - loss: 1.1653\n",
      "Epoch 12/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6439 - loss: 1.1635\n",
      "Epoch 13/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6439 - loss: 1.1642\n",
      "Epoch 14/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6439 - loss: 1.1632\n",
      "Epoch 15/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6439 - loss: 1.1640\n",
      "Epoch 16/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6439 - loss: 1.1622\n",
      "Epoch 17/36\n",
      "30/30 - 1s - 19ms/step - accuracy: 0.6439 - loss: 1.1640\n",
      "Epoch 18/36\n",
      "30/30 - 1s - 21ms/step - accuracy: 0.6439 - loss: 1.1615\n",
      "Epoch 19/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6439 - loss: 1.1587\n",
      "Epoch 20/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6439 - loss: 1.1564\n",
      "Epoch 21/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6439 - loss: 1.1464\n",
      "Epoch 22/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6439 - loss: 1.1289\n",
      "Epoch 23/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6439 - loss: 1.0960\n",
      "Epoch 24/36\n",
      "30/30 - 1s - 20ms/step - accuracy: 0.6437 - loss: 1.0688\n",
      "Epoch 25/36\n",
      "30/30 - 1s - 19ms/step - accuracy: 0.6417 - loss: 1.0531\n",
      "Epoch 26/36\n",
      "30/30 - 1s - 19ms/step - accuracy: 0.6399 - loss: 1.0448\n",
      "Epoch 27/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6384 - loss: 1.0380\n",
      "Epoch 28/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6397 - loss: 1.0300\n",
      "Epoch 29/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6410 - loss: 1.0238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/36\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.6415 - loss: 1.0177\n",
      "Epoch 31/36\n",
      "30/30 - 1s - 20ms/step - accuracy: 0.6390 - loss: 1.0121\n",
      "Epoch 32/36\n",
      "30/30 - 1s - 29ms/step - accuracy: 0.6427 - loss: 1.0061\n",
      "Epoch 33/36\n",
      "30/30 - 1s - 29ms/step - accuracy: 0.6371 - loss: 1.0034\n",
      "Epoch 34/36\n",
      "30/30 - 1s - 33ms/step - accuracy: 0.6426 - loss: 0.9973\n",
      "Epoch 35/36\n",
      "30/30 - 1s - 24ms/step - accuracy: 0.6426 - loss: 0.9932\n",
      "Epoch 36/36\n",
      "30/30 - 1s - 23ms/step - accuracy: 0.6423 - loss: 0.9888\n",
      "8/8 - 0s - 30ms/step\n",
      "| \u001b[39m12       \u001b[39m | \u001b[39m0.6289   \u001b[39m | \u001b[39m1.079    \u001b[39m | \u001b[39m470.1    \u001b[39m | \u001b[39m0.9429   \u001b[39m | \u001b[39m0.09696  \u001b[39m | \u001b[39m35.56    \u001b[39m | \u001b[39m2.406    \u001b[39m | \u001b[39m1.727    \u001b[39m | \u001b[39m2.944    \u001b[39m | \u001b[39m0.9628   \u001b[39m | \u001b[39m32.66    \u001b[39m | \u001b[39m0.4972   \u001b[39m | \u001b[39m2.106    \u001b[39m |\n",
      "Epoch 1/22\n",
      "60/60 - 3s - 54ms/step - accuracy: 0.6478 - loss: 1.1485\n",
      "Epoch 2/22\n",
      "60/60 - 2s - 27ms/step - accuracy: 0.7184 - loss: 0.8151\n",
      "Epoch 3/22\n",
      "60/60 - 1s - 23ms/step - accuracy: 0.7499 - loss: 0.7223\n",
      "Epoch 4/22\n",
      "60/60 - 1s - 23ms/step - accuracy: 0.7707 - loss: 0.6676\n",
      "Epoch 5/22\n",
      "60/60 - 3s - 43ms/step - accuracy: 0.7797 - loss: 0.6308\n",
      "Epoch 6/22\n",
      "60/60 - 2s - 25ms/step - accuracy: 0.7894 - loss: 0.5996\n",
      "Epoch 7/22\n",
      "60/60 - 3s - 54ms/step - accuracy: 0.7975 - loss: 0.5727\n",
      "Epoch 8/22\n",
      "60/60 - 2s - 27ms/step - accuracy: 0.8051 - loss: 0.5466\n",
      "Epoch 9/22\n",
      "60/60 - 1s - 24ms/step - accuracy: 0.8183 - loss: 0.5239\n",
      "Epoch 10/22\n",
      "60/60 - 3s - 42ms/step - accuracy: 0.8229 - loss: 0.5030\n",
      "Epoch 11/22\n",
      "60/60 - 3s - 42ms/step - accuracy: 0.8256 - loss: 0.4899\n",
      "Epoch 12/22\n",
      "60/60 - 1s - 23ms/step - accuracy: 0.8331 - loss: 0.4696\n",
      "Epoch 13/22\n",
      "60/60 - 2s - 26ms/step - accuracy: 0.8401 - loss: 0.4541\n",
      "Epoch 14/22\n",
      "60/60 - 1s - 25ms/step - accuracy: 0.8402 - loss: 0.4449\n",
      "Epoch 15/22\n",
      "60/60 - 1s - 23ms/step - accuracy: 0.8465 - loss: 0.4302\n",
      "Epoch 16/22\n",
      "60/60 - 1s - 25ms/step - accuracy: 0.8489 - loss: 0.4188\n",
      "Epoch 17/22\n",
      "60/60 - 1s - 24ms/step - accuracy: 0.8539 - loss: 0.4077\n",
      "Epoch 18/22\n",
      "60/60 - 2s - 26ms/step - accuracy: 0.8603 - loss: 0.3970\n",
      "Epoch 19/22\n",
      "60/60 - 2s - 37ms/step - accuracy: 0.8617 - loss: 0.3853\n",
      "Epoch 20/22\n",
      "60/60 - 2s - 25ms/step - accuracy: 0.8643 - loss: 0.3759\n",
      "Epoch 21/22\n",
      "60/60 - 1s - 25ms/step - accuracy: 0.8659 - loss: 0.3770\n",
      "Epoch 22/22\n",
      "60/60 - 1s - 24ms/step - accuracy: 0.8693 - loss: 0.3629\n",
      "15/15 - 0s - 20ms/step\n",
      "Epoch 1/22\n",
      "60/60 - 4s - 60ms/step - accuracy: 0.6551 - loss: 1.1407\n",
      "Epoch 2/22\n",
      "60/60 - 2s - 28ms/step - accuracy: 0.7210 - loss: 0.8100\n",
      "Epoch 3/22\n",
      "60/60 - 1s - 25ms/step - accuracy: 0.7460 - loss: 0.7293\n",
      "Epoch 4/22\n",
      "60/60 - 1s - 24ms/step - accuracy: 0.7746 - loss: 0.6651\n",
      "Epoch 5/22\n",
      "60/60 - 1s - 25ms/step - accuracy: 0.7887 - loss: 0.6144\n",
      "Epoch 6/22\n",
      "60/60 - 2s - 25ms/step - accuracy: 0.8010 - loss: 0.5754\n",
      "Epoch 7/22\n",
      "60/60 - 2s - 31ms/step - accuracy: 0.8123 - loss: 0.5426\n",
      "Epoch 8/22\n",
      "60/60 - 2s - 36ms/step - accuracy: 0.8225 - loss: 0.5130\n",
      "Epoch 9/22\n",
      "60/60 - 2s - 31ms/step - accuracy: 0.8313 - loss: 0.4917\n",
      "Epoch 10/22\n",
      "60/60 - 1s - 24ms/step - accuracy: 0.8329 - loss: 0.4774\n",
      "Epoch 11/22\n",
      "60/60 - 1s - 24ms/step - accuracy: 0.8419 - loss: 0.4580\n",
      "Epoch 12/22\n",
      "60/60 - 1s - 23ms/step - accuracy: 0.8460 - loss: 0.4440\n",
      "Epoch 13/22\n",
      "60/60 - 2s - 30ms/step - accuracy: 0.8510 - loss: 0.4301\n",
      "Epoch 14/22\n",
      "60/60 - 2s - 31ms/step - accuracy: 0.8537 - loss: 0.4190\n",
      "Epoch 15/22\n",
      "60/60 - 2s - 29ms/step - accuracy: 0.8580 - loss: 0.4092\n",
      "Epoch 16/22\n",
      "60/60 - 1s - 24ms/step - accuracy: 0.8602 - loss: 0.3963\n",
      "Epoch 17/22\n",
      "60/60 - 3s - 48ms/step - accuracy: 0.8653 - loss: 0.3862\n",
      "Epoch 18/22\n",
      "60/60 - 3s - 50ms/step - accuracy: 0.8660 - loss: 0.3822\n",
      "Epoch 19/22\n",
      "60/60 - 2s - 35ms/step - accuracy: 0.8702 - loss: 0.3719\n",
      "Epoch 20/22\n",
      "60/60 - 2s - 26ms/step - accuracy: 0.8705 - loss: 0.3670\n",
      "Epoch 21/22\n",
      "60/60 - 3s - 42ms/step - accuracy: 0.8738 - loss: 0.3597\n",
      "Epoch 22/22\n",
      "60/60 - 2s - 27ms/step - accuracy: 0.8751 - loss: 0.3531\n",
      "15/15 - 0s - 19ms/step\n",
      "Epoch 1/22\n",
      "60/60 - 3s - 51ms/step - accuracy: 0.6436 - loss: 1.1289\n",
      "Epoch 2/22\n",
      "60/60 - 1s - 25ms/step - accuracy: 0.7041 - loss: 0.8260\n",
      "Epoch 3/22\n",
      "60/60 - 2s - 27ms/step - accuracy: 0.7374 - loss: 0.7404\n",
      "Epoch 4/22\n",
      "60/60 - 2s - 25ms/step - accuracy: 0.7627 - loss: 0.6769\n",
      "Epoch 5/22\n",
      "60/60 - 2s - 33ms/step - accuracy: 0.7800 - loss: 0.6310\n",
      "Epoch 6/22\n",
      "60/60 - 2s - 25ms/step - accuracy: 0.7921 - loss: 0.5919\n",
      "Epoch 7/22\n",
      "60/60 - 1s - 24ms/step - accuracy: 0.8027 - loss: 0.5602\n",
      "Epoch 8/22\n",
      "60/60 - 1s - 23ms/step - accuracy: 0.8147 - loss: 0.5346\n",
      "Epoch 9/22\n",
      "60/60 - 3s - 42ms/step - accuracy: 0.8192 - loss: 0.5081\n",
      "Epoch 10/22\n",
      "60/60 - 1s - 23ms/step - accuracy: 0.8237 - loss: 0.4919\n",
      "Epoch 11/22\n",
      "60/60 - 1s - 23ms/step - accuracy: 0.8359 - loss: 0.4690\n",
      "Epoch 12/22\n",
      "60/60 - 1s - 23ms/step - accuracy: 0.8420 - loss: 0.4482\n",
      "Epoch 13/22\n",
      "60/60 - 1s - 23ms/step - accuracy: 0.8421 - loss: 0.4360\n",
      "Epoch 14/22\n",
      "60/60 - 3s - 48ms/step - accuracy: 0.8478 - loss: 0.4206\n",
      "Epoch 15/22\n",
      "60/60 - 2s - 38ms/step - accuracy: 0.8549 - loss: 0.4070\n",
      "Epoch 16/22\n",
      "60/60 - 1s - 23ms/step - accuracy: 0.8564 - loss: 0.4032\n",
      "Epoch 17/22\n",
      "60/60 - 2s - 26ms/step - accuracy: 0.8630 - loss: 0.3856\n",
      "Epoch 18/22\n",
      "60/60 - 2s - 41ms/step - accuracy: 0.8661 - loss: 0.3857\n",
      "Epoch 19/22\n",
      "60/60 - 1s - 23ms/step - accuracy: 0.8642 - loss: 0.3795\n",
      "Epoch 20/22\n",
      "60/60 - 2s - 25ms/step - accuracy: 0.8698 - loss: 0.3662\n",
      "Epoch 21/22\n",
      "60/60 - 1s - 24ms/step - accuracy: 0.8719 - loss: 0.3649\n",
      "Epoch 22/22\n",
      "60/60 - 3s - 46ms/step - accuracy: 0.8768 - loss: 0.3520\n",
      "15/15 - 0s - 25ms/step\n",
      "Epoch 1/22\n",
      "60/60 - 3s - 56ms/step - accuracy: 0.6442 - loss: 1.1570\n",
      "Epoch 2/22\n",
      "60/60 - 2s - 30ms/step - accuracy: 0.7156 - loss: 0.8161\n",
      "Epoch 3/22\n",
      "60/60 - 2s - 39ms/step - accuracy: 0.7534 - loss: 0.7096\n",
      "Epoch 4/22\n",
      "60/60 - 2s - 32ms/step - accuracy: 0.7787 - loss: 0.6406\n",
      "Epoch 5/22\n",
      "60/60 - 2s - 26ms/step - accuracy: 0.7902 - loss: 0.5979\n",
      "Epoch 6/22\n",
      "60/60 - 2s - 31ms/step - accuracy: 0.7968 - loss: 0.5668\n",
      "Epoch 7/22\n",
      "60/60 - 2s - 32ms/step - accuracy: 0.8089 - loss: 0.5429\n",
      "Epoch 8/22\n",
      "60/60 - 2s - 34ms/step - accuracy: 0.8171 - loss: 0.5147\n",
      "Epoch 9/22\n",
      "60/60 - 2s - 34ms/step - accuracy: 0.8252 - loss: 0.4974\n",
      "Epoch 10/22\n",
      "60/60 - 2s - 26ms/step - accuracy: 0.8325 - loss: 0.4775\n",
      "Epoch 11/22\n",
      "60/60 - 3s - 45ms/step - accuracy: 0.8397 - loss: 0.4542\n",
      "Epoch 12/22\n",
      "60/60 - 2s - 27ms/step - accuracy: 0.8430 - loss: 0.4413\n",
      "Epoch 13/22\n",
      "60/60 - 2s - 33ms/step - accuracy: 0.8500 - loss: 0.4247\n",
      "Epoch 14/22\n",
      "60/60 - 2s - 27ms/step - accuracy: 0.8560 - loss: 0.4093\n",
      "Epoch 15/22\n",
      "60/60 - 2s - 29ms/step - accuracy: 0.8556 - loss: 0.4029\n",
      "Epoch 16/22\n",
      "60/60 - 1s - 25ms/step - accuracy: 0.8620 - loss: 0.3883\n",
      "Epoch 17/22\n",
      "60/60 - 1s - 25ms/step - accuracy: 0.8658 - loss: 0.3756\n",
      "Epoch 18/22\n",
      "60/60 - 2s - 30ms/step - accuracy: 0.8678 - loss: 0.3698\n",
      "Epoch 19/22\n",
      "60/60 - 1s - 25ms/step - accuracy: 0.8698 - loss: 0.3614\n",
      "Epoch 20/22\n",
      "60/60 - 1s - 25ms/step - accuracy: 0.8750 - loss: 0.3538\n",
      "Epoch 21/22\n",
      "60/60 - 1s - 25ms/step - accuracy: 0.8772 - loss: 0.3508\n",
      "Epoch 22/22\n",
      "60/60 - 2s - 26ms/step - accuracy: 0.8826 - loss: 0.3337\n",
      "15/15 - 0s - 18ms/step\n",
      "Epoch 1/22\n",
      "60/60 - 3s - 52ms/step - accuracy: 0.6438 - loss: 1.1578\n",
      "Epoch 2/22\n",
      "60/60 - 1s - 25ms/step - accuracy: 0.7054 - loss: 0.8217\n",
      "Epoch 3/22\n",
      "60/60 - 2s - 28ms/step - accuracy: 0.7329 - loss: 0.7403\n",
      "Epoch 4/22\n",
      "60/60 - 3s - 55ms/step - accuracy: 0.7603 - loss: 0.6765\n",
      "Epoch 5/22\n",
      "60/60 - 3s - 45ms/step - accuracy: 0.7780 - loss: 0.6290\n",
      "Epoch 6/22\n",
      "60/60 - 2s - 40ms/step - accuracy: 0.7923 - loss: 0.5939\n",
      "Epoch 7/22\n",
      "60/60 - 3s - 53ms/step - accuracy: 0.8042 - loss: 0.5618\n",
      "Epoch 8/22\n",
      "60/60 - 2s - 40ms/step - accuracy: 0.8127 - loss: 0.5386\n",
      "Epoch 9/22\n",
      "60/60 - 2s - 31ms/step - accuracy: 0.8199 - loss: 0.5175\n",
      "Epoch 10/22\n",
      "60/60 - 2s - 40ms/step - accuracy: 0.8261 - loss: 0.4986\n",
      "Epoch 11/22\n",
      "60/60 - 2s - 27ms/step - accuracy: 0.8294 - loss: 0.4847\n",
      "Epoch 12/22\n",
      "60/60 - 2s - 28ms/step - accuracy: 0.8346 - loss: 0.4643\n",
      "Epoch 13/22\n",
      "60/60 - 2s - 27ms/step - accuracy: 0.8410 - loss: 0.4493\n",
      "Epoch 14/22\n",
      "60/60 - 3s - 43ms/step - accuracy: 0.8439 - loss: 0.4330\n",
      "Epoch 15/22\n",
      "60/60 - 1s - 25ms/step - accuracy: 0.8514 - loss: 0.4221\n",
      "Epoch 16/22\n",
      "60/60 - 1s - 24ms/step - accuracy: 0.8550 - loss: 0.4096\n",
      "Epoch 17/22\n",
      "60/60 - 1s - 24ms/step - accuracy: 0.8572 - loss: 0.4074\n",
      "Epoch 18/22\n",
      "60/60 - 1s - 25ms/step - accuracy: 0.8613 - loss: 0.3904\n",
      "Epoch 19/22\n",
      "60/60 - 2s - 32ms/step - accuracy: 0.8651 - loss: 0.3824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/22\n",
      "60/60 - 2s - 33ms/step - accuracy: 0.8666 - loss: 0.3762\n",
      "Epoch 21/22\n",
      "60/60 - 2s - 37ms/step - accuracy: 0.8694 - loss: 0.3674\n",
      "Epoch 22/22\n",
      "60/60 - 2s - 27ms/step - accuracy: 0.8751 - loss: 0.3553\n",
      "15/15 - 0s - 24ms/step\n",
      "| \u001b[39m13       \u001b[39m | \u001b[39m0.8241   \u001b[39m | \u001b[39m2.564    \u001b[39m | \u001b[39m229.5    \u001b[39m | \u001b[39m0.6096   \u001b[39m | \u001b[39m0.1508   \u001b[39m | \u001b[39m21.54    \u001b[39m | \u001b[39m1.557    \u001b[39m | \u001b[39m2.817    \u001b[39m | \u001b[39m1.479    \u001b[39m | \u001b[39m0.1534   \u001b[39m | \u001b[39m54.05    \u001b[39m | \u001b[39m0.9857   \u001b[39m | \u001b[39m1.694    \u001b[39m |\n",
      "Epoch 1/31\n",
      "18/18 - 4s - 219ms/step - accuracy: 0.6248 - loss: 1.1834\n",
      "Epoch 2/31\n",
      "18/18 - 2s - 124ms/step - accuracy: 0.7011 - loss: 0.8983\n",
      "Epoch 3/31\n",
      "18/18 - 3s - 149ms/step - accuracy: 0.7257 - loss: 0.8065\n",
      "Epoch 4/31\n",
      "18/18 - 2s - 138ms/step - accuracy: 0.7418 - loss: 0.7551\n",
      "Epoch 5/31\n",
      "18/18 - 2s - 131ms/step - accuracy: 0.7552 - loss: 0.7127\n",
      "Epoch 6/31\n",
      "18/18 - 3s - 141ms/step - accuracy: 0.7388 - loss: 0.7302\n",
      "Epoch 7/31\n",
      "18/18 - 2s - 122ms/step - accuracy: 0.7563 - loss: 0.6950\n",
      "Epoch 8/31\n",
      "18/18 - 2s - 124ms/step - accuracy: 0.7773 - loss: 0.6473\n",
      "Epoch 9/31\n",
      "18/18 - 2s - 120ms/step - accuracy: 0.7797 - loss: 0.6266\n",
      "Epoch 10/31\n",
      "18/18 - 2s - 107ms/step - accuracy: 0.7891 - loss: 0.6011\n",
      "Epoch 11/31\n",
      "18/18 - 2s - 128ms/step - accuracy: 0.7871 - loss: 0.6085\n",
      "Epoch 12/31\n",
      "18/18 - 2s - 133ms/step - accuracy: 0.7701 - loss: 0.6393\n",
      "Epoch 13/31\n",
      "18/18 - 2s - 116ms/step - accuracy: 0.7993 - loss: 0.5676\n",
      "Epoch 14/31\n",
      "18/18 - 2s - 126ms/step - accuracy: 0.8024 - loss: 0.5574\n",
      "Epoch 15/31\n",
      "18/18 - 2s - 107ms/step - accuracy: 0.7977 - loss: 0.5631\n",
      "Epoch 16/31\n",
      "18/18 - 3s - 155ms/step - accuracy: 0.8116 - loss: 0.5301\n",
      "Epoch 17/31\n",
      "18/18 - 2s - 135ms/step - accuracy: 0.8168 - loss: 0.5172\n",
      "Epoch 18/31\n",
      "18/18 - 2s - 111ms/step - accuracy: 0.8173 - loss: 0.5093\n",
      "Epoch 19/31\n",
      "18/18 - 2s - 108ms/step - accuracy: 0.8187 - loss: 0.5086\n",
      "Epoch 20/31\n",
      "18/18 - 2s - 114ms/step - accuracy: 0.8270 - loss: 0.4841\n",
      "Epoch 21/31\n",
      "18/18 - 2s - 119ms/step - accuracy: 0.8292 - loss: 0.4738\n",
      "Epoch 22/31\n",
      "18/18 - 2s - 122ms/step - accuracy: 0.8256 - loss: 0.4853\n",
      "Epoch 23/31\n",
      "18/18 - 2s - 122ms/step - accuracy: 0.8298 - loss: 0.4771\n",
      "Epoch 24/31\n",
      "18/18 - 2s - 127ms/step - accuracy: 0.8388 - loss: 0.4485\n",
      "Epoch 25/31\n",
      "18/18 - 2s - 123ms/step - accuracy: 0.8378 - loss: 0.4444\n",
      "Epoch 26/31\n",
      "18/18 - 2s - 138ms/step - accuracy: 0.8337 - loss: 0.4625\n",
      "Epoch 27/31\n",
      "18/18 - 2s - 104ms/step - accuracy: 0.8425 - loss: 0.4369\n",
      "Epoch 28/31\n",
      "18/18 - 2s - 102ms/step - accuracy: 0.8497 - loss: 0.4157\n",
      "Epoch 29/31\n",
      "18/18 - 3s - 158ms/step - accuracy: 0.8498 - loss: 0.4140\n",
      "Epoch 30/31\n",
      "18/18 - 2s - 107ms/step - accuracy: 0.8480 - loss: 0.4199\n",
      "Epoch 31/31\n",
      "18/18 - 2s - 111ms/step - accuracy: 0.8544 - loss: 0.3994\n",
      "5/5 - 0s - 73ms/step\n",
      "Epoch 1/31\n",
      "18/18 - 5s - 258ms/step - accuracy: 0.5622 - loss: 1.4277\n",
      "Epoch 2/31\n",
      "18/18 - 3s - 145ms/step - accuracy: 0.6971 - loss: 0.9183\n",
      "Epoch 3/31\n",
      "18/18 - 2s - 110ms/step - accuracy: 0.7258 - loss: 0.8276\n",
      "Epoch 4/31\n",
      "18/18 - 2s - 116ms/step - accuracy: 0.7288 - loss: 0.8016\n",
      "Epoch 5/31\n",
      "18/18 - 2s - 117ms/step - accuracy: 0.7518 - loss: 0.7363\n",
      "Epoch 6/31\n",
      "18/18 - 2s - 137ms/step - accuracy: 0.7683 - loss: 0.6946\n",
      "Epoch 7/31\n",
      "18/18 - 2s - 124ms/step - accuracy: 0.7552 - loss: 0.7037\n",
      "Epoch 8/31\n",
      "18/18 - 3s - 175ms/step - accuracy: 0.7774 - loss: 0.6537\n",
      "Epoch 9/31\n",
      "18/18 - 2s - 124ms/step - accuracy: 0.7754 - loss: 0.6483\n",
      "Epoch 10/31\n",
      "18/18 - 2s - 121ms/step - accuracy: 0.7886 - loss: 0.6114\n",
      "Epoch 11/31\n",
      "18/18 - 2s - 133ms/step - accuracy: 0.7897 - loss: 0.5980\n",
      "Epoch 12/31\n",
      "18/18 - 2s - 108ms/step - accuracy: 0.7956 - loss: 0.5793\n",
      "Epoch 13/31\n",
      "18/18 - 2s - 119ms/step - accuracy: 0.7902 - loss: 0.5934\n",
      "Epoch 14/31\n",
      "18/18 - 2s - 122ms/step - accuracy: 0.7991 - loss: 0.5615\n",
      "Epoch 15/31\n",
      "18/18 - 2s - 131ms/step - accuracy: 0.8043 - loss: 0.5498\n",
      "Epoch 16/31\n",
      "18/18 - 2s - 115ms/step - accuracy: 0.8089 - loss: 0.5370\n",
      "Epoch 17/31\n",
      "18/18 - 2s - 130ms/step - accuracy: 0.8111 - loss: 0.5341\n",
      "Epoch 18/31\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Run Bayesian Optimization\u001b[39;00m\n\u001b[1;32m     17\u001b[0m nn_opt \u001b[38;5;241m=\u001b[39m BayesianOptimization(bay_area, params, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m nn_opt\u001b[38;5;241m.\u001b[39mmaximize(init_points\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m) \n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSearch took \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m minutes\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m ((time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/bayes_opt/bayesian_optimization.py:374\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[0;34m(self, init_points, n_iter, acquisition_function, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    372\u001b[0m     x_probe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuggest(util)\n\u001b[1;32m    373\u001b[0m     iteration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobe(x_probe, lazy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bounds_transformer \u001b[38;5;129;01mand\u001b[39;00m iteration \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;66;03m# The bounds transformer should only modify the bounds after\u001b[39;00m\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;66;03m# the init_points points (only for the true iterations)\u001b[39;00m\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_bounds(\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bounds_transformer\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/bayes_opt/bayesian_optimization.py:245\u001b[0m, in \u001b[0;36mBayesianOptimization.probe\u001b[0;34m(self, params, lazy)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue\u001b[38;5;241m.\u001b[39madd(params)\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 245\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space\u001b[38;5;241m.\u001b[39mprobe(params)\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch(Events\u001b[38;5;241m.\u001b[39mOPTIMIZATION_STEP)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/bayes_opt/target_space.py:373\u001b[0m, in \u001b[0;36mTargetSpace.probe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache[_hashable(x\u001b[38;5;241m.\u001b[39mravel())]\n\u001b[1;32m    372\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_keys, x))\n\u001b[0;32m--> 373\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constraint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister(x, target)\n",
      "Cell \u001b[0;32mIn[22], line 45\u001b[0m, in \u001b[0;36mbay_area\u001b[0;34m(neurons, activation, kernel, optimizer, learning_rate, batch_size, epochs, layers1, layers2, normalization, dropout, dropout_rate)\u001b[0m\n\u001b[1;32m     43\u001b[0m nn \u001b[38;5;241m=\u001b[39m KerasClassifier(build_fn\u001b[38;5;241m=\u001b[39mcnn_model, epochs\u001b[38;5;241m=\u001b[39mepochs, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     44\u001b[0m kfold \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m)\n\u001b[0;32m---> 45\u001b[0m score \u001b[38;5;241m=\u001b[39m cross_val_score(nn, X_train, y_train, scoring\u001b[38;5;241m=\u001b[39mscore_acc, cv\u001b[38;5;241m=\u001b[39mkfold, fit_params\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m'\u001b[39m:[es]})\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m score\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:712\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    710\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 712\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m cross_validate(\n\u001b[1;32m    713\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m    714\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m    715\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m    716\u001b[0m     groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[1;32m    717\u001b[0m     scoring\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m: scorer},\n\u001b[1;32m    718\u001b[0m     cv\u001b[38;5;241m=\u001b[39mcv,\n\u001b[1;32m    719\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[1;32m    720\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    721\u001b[0m     fit_params\u001b[38;5;241m=\u001b[39mfit_params,\n\u001b[1;32m    722\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    723\u001b[0m     pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch,\n\u001b[1;32m    724\u001b[0m     error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[1;32m    725\u001b[0m )\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:423\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    422\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 423\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    424\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    425\u001b[0m         clone(estimator),\n\u001b[1;32m    426\u001b[0m         X,\n\u001b[1;32m    427\u001b[0m         y,\n\u001b[1;32m    428\u001b[0m         scorer\u001b[38;5;241m=\u001b[39mscorers,\n\u001b[1;32m    429\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    430\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    431\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    432\u001b[0m         parameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    433\u001b[0m         fit_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit,\n\u001b[1;32m    434\u001b[0m         score_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mscorer\u001b[38;5;241m.\u001b[39mscore,\n\u001b[1;32m    435\u001b[0m         return_train_score\u001b[38;5;241m=\u001b[39mreturn_train_score,\n\u001b[1;32m    436\u001b[0m         return_times\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    437\u001b[0m         return_estimator\u001b[38;5;241m=\u001b[39mreturn_estimator,\n\u001b[1;32m    438\u001b[0m         error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[1;32m    439\u001b[0m     )\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[1;32m    441\u001b[0m )\n\u001b[1;32m    443\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:888\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    886\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 888\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    892\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scikeras/wrappers.py:1501\u001b[0m, in \u001b[0;36mKerasClassifier.fit\u001b[0;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight\n\u001b[1;32m   1500\u001b[0m     sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight, y\u001b[38;5;241m=\u001b[39my)\n\u001b[0;32m-> 1501\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scikeras/wrappers.py:770\u001b[0m, in \u001b[0;36mBaseWrapper.fit\u001b[0;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    765\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit__epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs)\n\u001b[1;32m    767\u001b[0m )\n\u001b[1;32m    768\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 770\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[1;32m    771\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m    772\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m    773\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    774\u001b[0m     warm_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarm_start,\n\u001b[1;32m    775\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    776\u001b[0m )\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scikeras/wrappers.py:938\u001b[0m, in \u001b[0;36mBaseWrapper._fit\u001b[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    934\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_encoder_\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    936\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_model_compatibility(y)\n\u001b[0;32m--> 938\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_keras_model(\n\u001b[1;32m    939\u001b[0m     X,\n\u001b[1;32m    940\u001b[0m     y,\n\u001b[1;32m    941\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    942\u001b[0m     warm_start\u001b[38;5;241m=\u001b[39mwarm_start,\n\u001b[1;32m    943\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[1;32m    944\u001b[0m     initial_epoch\u001b[38;5;241m=\u001b[39minitial_epoch,\n\u001b[1;32m    945\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    946\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scikeras/wrappers.py:535\u001b[0m, in \u001b[0;36mBaseWrapper._fit_keras_model\u001b[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    533\u001b[0m         hist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_\u001b[38;5;241m.\u001b[39mfit(x\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_args)\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 535\u001b[0m     hist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_\u001b[38;5;241m.\u001b[39mfit(x\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_args)\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m warm_start \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m initial_epoch \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory_ \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m    321\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    322\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[1;32m    880\u001b[0m )\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   1501\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1502\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   1503\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1504\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1505\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1506\u001b[0m   )\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "params ={\n",
    "    'neurons': (10, 100),\n",
    "    'kernel': (1, 3),\n",
    "    'activation':(0, 9), \n",
    "    'optimizer':(0,7),\n",
    "    'learning_rate':(0.01, 1),\n",
    "    'batch_size': (200, 1000), \n",
    "    'epochs':(20, 50),\n",
    "    'layers1':(1,3),\n",
    "    'layers2':(1,3),\n",
    "    'normalization':(0,1),\n",
    "    'dropout':(0,1),\n",
    "    'dropout_rate':(0,0.3)\n",
    "}\n",
    "# Run Bayesian Optimization\n",
    "nn_opt = BayesianOptimization(bay_area, params, random_state=42)\n",
    "nn_opt.maximize(init_points=15, n_iter=4) \n",
    "print('Search took %s minutes' % ((time.time() - start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bbb32085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'softsign',\n",
       " 'batch_size': 460,\n",
       " 'dropout': 0.7296061783380641,\n",
       " 'dropout_rate': 0.19126724140656393,\n",
       " 'epochs': 47,\n",
       " 'kernel': 1.9444298503238986,\n",
       " 'layers1': 1,\n",
       " 'layers2': 2,\n",
       " 'learning_rate': 0.7631771981307285,\n",
       " 'neurons': 61,\n",
       " 'normalization': 0.770967179954561,\n",
       " 'optimizer': <keras.src.optimizers.adadelta.Adadelta at 0x10bd87790>}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimum = nn_opt.max['params']\n",
    "learning_rate = optimum['learning_rate']\n",
    "\n",
    "activationL = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu', 'elu', 'exponential', LeakyReLU, 'relu']\n",
    "optimum['activation'] = activationL[round(optimum['activation'])]\n",
    "\n",
    "optimum['batch_size'] = round(optimum['batch_size'])\n",
    "optimum['epochs'] = round(optimum['epochs'])\n",
    "optimum['layers1'] = round(optimum['layers1'])\n",
    "optimum['layers2'] = round(optimum['layers2'])\n",
    "optimum['neurons'] = round(optimum['neurons'])\n",
    "\n",
    "optimizerL = ['Adam', 'SGD', 'RMSprop', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl', 'Adam']\n",
    "optimizerD = {\n",
    "    'Adam': Adam(learning_rate=learning_rate),\n",
    "    'SGD': SGD(learning_rate=learning_rate),\n",
    "    'RMSprop': RMSprop(learning_rate=learning_rate),\n",
    "    'Adadelta': Adadelta(learning_rate=learning_rate),\n",
    "    'Adagrad': Adagrad(learning_rate=learning_rate),\n",
    "    'Adamax': Adamax(learning_rate=learning_rate),\n",
    "    'Nadam': Nadam(learning_rate=learning_rate),\n",
    "    'Ftrl': Ftrl(learning_rate=learning_rate)\n",
    "}\n",
    "optimum['optimizer'] = optimizerD[optimizerL[round(optimum['optimizer'])]]\n",
    "optimum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679580f2",
   "metadata": {},
   "source": [
    "## 6. Running CNN with Optimized Search Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "469273a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model with optimized hyperparameters\n",
    "\n",
    "epochs = 47\n",
    "batch_size = 460\n",
    "\n",
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = 15\n",
    "\n",
    "layers1 = 1\n",
    "layers2 = 2\n",
    "activation = 'softsign'\n",
    "kernel = int(round(1.9444298503238986))  # Rounded kernel size for Conv1D\n",
    "neurons = 61\n",
    "normalization = 0.770967179954561\n",
    "dropout = 0.7296061783380641\n",
    "dropout_rate = 0.19126724140656393\n",
    "optimizer = Adadelta(learning_rate=0.7631771981307285)  # Instantiate RMSprop with learning rate\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(neurons, kernel_size=kernel, activation=activation, input_shape=(timesteps, input_dim)))\n",
    "\n",
    "if normalization > 0.5:\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "for i in range(layers1):\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "\n",
    "if dropout > 0.5:\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "for i in range(layers2):\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(n_classes, activation='softmax')) \n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f83e5dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_67\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_67\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " conv1d_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,159</span> \n",
       "\n",
       " batch_normalization_25           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " dense_345 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,782</span> \n",
       "\n",
       " dropout_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_346 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,782</span> \n",
       "\n",
       " dense_347 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,782</span> \n",
       "\n",
       " max_pooling1d_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " flatten_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">427</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_348 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,420</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " conv1d_67 (\u001b[38;5;33mConv1D\u001b[0m)               (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m61\u001b[0m)                  \u001b[38;5;34m1,159\u001b[0m \n",
       "\n",
       " batch_normalization_25           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m61\u001b[0m)                    \u001b[38;5;34m244\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " dense_345 (\u001b[38;5;33mDense\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m61\u001b[0m)                  \u001b[38;5;34m3,782\u001b[0m \n",
       "\n",
       " dropout_40 (\u001b[38;5;33mDropout\u001b[0m)             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m61\u001b[0m)                      \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_346 (\u001b[38;5;33mDense\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m61\u001b[0m)                  \u001b[38;5;34m3,782\u001b[0m \n",
       "\n",
       " dense_347 (\u001b[38;5;33mDense\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m61\u001b[0m)                  \u001b[38;5;34m3,782\u001b[0m \n",
       "\n",
       " max_pooling1d_67 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m61\u001b[0m)                       \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " flatten_67 (\u001b[38;5;33mFlatten\u001b[0m)             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m427\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_348 (\u001b[38;5;33mDense\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                      \u001b[38;5;34m6,420\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,169</span> (74.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,169\u001b[0m (74.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,047</span> (74.40 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,047\u001b[0m (74.40 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">122</span> (488.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m122\u001b[0m (488.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06a426d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the y_test set back into a one-hot configuration\n",
    "\n",
    "y_train_one_hot = to_categorical(y_train, num_classes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "579f167d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (17212, 15, 9)\n",
      "y_train_one_hot shape: (17212, 15)\n"
     ]
    }
   ],
   "source": [
    "# Check shapes\n",
    "\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'y_train_one_hot shape: {y_train_one_hot.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29e2a1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with categorical_crossentropy\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0479aee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/47\n",
      "38/38 - 3s - 90ms/step - accuracy: 0.5807 - loss: 1.4373\n",
      "Epoch 2/47\n",
      "38/38 - 3s - 67ms/step - accuracy: 0.6932 - loss: 0.9095\n",
      "Epoch 3/47\n",
      "38/38 - 2s - 41ms/step - accuracy: 0.7144 - loss: 0.8258\n",
      "Epoch 4/47\n",
      "38/38 - 2s - 46ms/step - accuracy: 0.7406 - loss: 0.7634\n",
      "Epoch 5/47\n",
      "38/38 - 2s - 46ms/step - accuracy: 0.7538 - loss: 0.7168\n",
      "Epoch 6/47\n",
      "38/38 - 2s - 45ms/step - accuracy: 0.7707 - loss: 0.6781\n",
      "Epoch 7/47\n",
      "38/38 - 2s - 48ms/step - accuracy: 0.7804 - loss: 0.6427\n",
      "Epoch 8/47\n",
      "38/38 - 2s - 46ms/step - accuracy: 0.7877 - loss: 0.6143\n",
      "Epoch 9/47\n",
      "38/38 - 2s - 65ms/step - accuracy: 0.7996 - loss: 0.5851\n",
      "Epoch 10/47\n",
      "38/38 - 2s - 48ms/step - accuracy: 0.8074 - loss: 0.5578\n",
      "Epoch 11/47\n",
      "38/38 - 2s - 43ms/step - accuracy: 0.8150 - loss: 0.5315\n",
      "Epoch 12/47\n",
      "38/38 - 2s - 44ms/step - accuracy: 0.8194 - loss: 0.5166\n",
      "Epoch 13/47\n",
      "38/38 - 1s - 39ms/step - accuracy: 0.8259 - loss: 0.5005\n",
      "Epoch 14/47\n",
      "38/38 - 2s - 42ms/step - accuracy: 0.8322 - loss: 0.4816\n",
      "Epoch 15/47\n",
      "38/38 - 1s - 39ms/step - accuracy: 0.8348 - loss: 0.4719\n",
      "Epoch 16/47\n",
      "38/38 - 2s - 40ms/step - accuracy: 0.8431 - loss: 0.4486\n",
      "Epoch 17/47\n",
      "38/38 - 1s - 39ms/step - accuracy: 0.8456 - loss: 0.4404\n",
      "Epoch 18/47\n",
      "38/38 - 1s - 39ms/step - accuracy: 0.8496 - loss: 0.4392\n",
      "Epoch 19/47\n",
      "38/38 - 1s - 38ms/step - accuracy: 0.8572 - loss: 0.4094\n",
      "Epoch 20/47\n",
      "38/38 - 1s - 39ms/step - accuracy: 0.8627 - loss: 0.3950\n",
      "Epoch 21/47\n",
      "38/38 - 1s - 38ms/step - accuracy: 0.8674 - loss: 0.3877\n",
      "Epoch 22/47\n",
      "38/38 - 2s - 54ms/step - accuracy: 0.8693 - loss: 0.3830\n",
      "Epoch 23/47\n",
      "38/38 - 2s - 52ms/step - accuracy: 0.8708 - loss: 0.3760\n",
      "Epoch 24/47\n",
      "38/38 - 1s - 39ms/step - accuracy: 0.8758 - loss: 0.3602\n",
      "Epoch 25/47\n",
      "38/38 - 1s - 39ms/step - accuracy: 0.8713 - loss: 0.3744\n",
      "Epoch 26/47\n",
      "38/38 - 2s - 45ms/step - accuracy: 0.8836 - loss: 0.3373\n",
      "Epoch 27/47\n",
      "38/38 - 2s - 45ms/step - accuracy: 0.8875 - loss: 0.3300\n",
      "Epoch 28/47\n",
      "38/38 - 2s - 48ms/step - accuracy: 0.8861 - loss: 0.3228\n",
      "Epoch 29/47\n",
      "38/38 - 1s - 39ms/step - accuracy: 0.8896 - loss: 0.3244\n",
      "Epoch 30/47\n",
      "38/38 - 1s - 38ms/step - accuracy: 0.8928 - loss: 0.3136\n",
      "Epoch 31/47\n",
      "38/38 - 1s - 39ms/step - accuracy: 0.8929 - loss: 0.3094\n",
      "Epoch 32/47\n",
      "38/38 - 1s - 39ms/step - accuracy: 0.8994 - loss: 0.2959\n",
      "Epoch 33/47\n",
      "38/38 - 1s - 38ms/step - accuracy: 0.8994 - loss: 0.2914\n",
      "Epoch 34/47\n",
      "38/38 - 3s - 71ms/step - accuracy: 0.9019 - loss: 0.2874\n",
      "Epoch 35/47\n",
      "38/38 - 2s - 46ms/step - accuracy: 0.9002 - loss: 0.2874\n",
      "Epoch 36/47\n",
      "38/38 - 2s - 40ms/step - accuracy: 0.9036 - loss: 0.2827\n",
      "Epoch 37/47\n",
      "38/38 - 1s - 39ms/step - accuracy: 0.9052 - loss: 0.2768\n",
      "Epoch 38/47\n",
      "38/38 - 1s - 38ms/step - accuracy: 0.9051 - loss: 0.2718\n",
      "Epoch 39/47\n",
      "38/38 - 1s - 39ms/step - accuracy: 0.9106 - loss: 0.2644\n",
      "Epoch 40/47\n",
      "38/38 - 1s - 38ms/step - accuracy: 0.9116 - loss: 0.2558\n",
      "Epoch 41/47\n",
      "38/38 - 2s - 45ms/step - accuracy: 0.9126 - loss: 0.2559\n",
      "Epoch 42/47\n",
      "38/38 - 2s - 61ms/step - accuracy: 0.9140 - loss: 0.2487\n",
      "Epoch 43/47\n",
      "38/38 - 1s - 39ms/step - accuracy: 0.9168 - loss: 0.2411\n",
      "Epoch 44/47\n",
      "38/38 - 2s - 44ms/step - accuracy: 0.9162 - loss: 0.2506\n",
      "Epoch 45/47\n",
      "38/38 - 2s - 44ms/step - accuracy: 0.9220 - loss: 0.2309\n",
      "Epoch 46/47\n",
      "38/38 - 2s - 41ms/step - accuracy: 0.9235 - loss: 0.2293\n",
      "Epoch 47/47\n",
      "38/38 - 2s - 51ms/step - accuracy: 0.9220 - loss: 0.2319\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x14c9ac0d0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the data\n",
    "\n",
    "model.fit(X_train, y_train_one_hot, batch_size=batch_size, epochs=epochs, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeab4853",
   "metadata": {},
   "source": [
    "## 7. Creating Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d221445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define list of stations names\n",
    "\n",
    "stations = {\n",
    "0: 'BASEL',\n",
    "1: 'BELGRADE',\n",
    "2: 'BUDAPEST',\n",
    "3: 'DEBILT',\n",
    "4: 'DUSSELDORF',\n",
    "5: 'HEATHROW',\n",
    "6: 'KASSEL',\n",
    "7: 'LJUBLJANA',\n",
    "8: 'MAASTRICHT',\n",
    "9: 'MADRID',\n",
    "10: 'MUNCHENB',\n",
    "11: 'OSLO',\n",
    "12: 'SONNBLICK',\n",
    "13: 'STOCKHOLM',\n",
    "14: 'VALENTIA'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34460ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(y_true, y_pred, stations):\n",
    "    # Check if y_true and y_pred are one-hot encoded or already class indices\n",
    "    if y_true.ndim == 1:\n",
    "        y_true_labels = y_true\n",
    "    else:\n",
    "        y_true_labels = np.argmax(y_true, axis=1)\n",
    "    \n",
    "    if y_pred.ndim == 1:\n",
    "        y_pred_labels = y_pred\n",
    "    else:\n",
    "        y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "        \n",
    "    # Map numeric labels to activity names\n",
    "    y_true_series = pd.Series([stations[y] for y in y_true_labels])\n",
    "    y_pred_series = pd.Series([stations[y] for y in y_pred_labels])\n",
    "    \n",
    "    return pd.crosstab(y_true_series, y_pred_series, rownames=['True'], colnames=['Pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f18d11b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m180/180\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0e999feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred        BASEL  BELGRADE  BUDAPEST  DEBILT  DUSSELDORF  HEATHROW  KASSEL  \\\n",
      "True                                                                          \n",
      "BASEL        3517        93        11       4           3         3       1   \n",
      "BELGRADE      105       987         0       0           0         0       0   \n",
      "BUDAPEST       28        36       148       2           0         0       0   \n",
      "DEBILT         14         6        27      35           0         0       0   \n",
      "DUSSELDORF      5         2         6       5           5         5       0   \n",
      "HEATHROW       10         2         4       3           2        60       0   \n",
      "KASSEL          0         3         1       0           1         1       2   \n",
      "LJUBLJANA      11         6         4       0           0         4       0   \n",
      "MAASTRICHT      8         0         0       0           0         0       0   \n",
      "MADRID         26        19        13       1           2        25       0   \n",
      "MUNCHENB        5         1         0       0           0         0       0   \n",
      "OSLO            1         0         0       1           0         0       0   \n",
      "STOCKHOLM       1         0         1       0           0         1       0   \n",
      "VALENTIA        0         0         0       0           0         1       0   \n",
      "\n",
      "Pred        LJUBLJANA  MAASTRICHT  MADRID  MUNCHENB  OSLO  \n",
      "True                                                       \n",
      "BASEL               5           1      44         0     0  \n",
      "BELGRADE            0           0       0         0     0  \n",
      "BUDAPEST            0           0       0         0     0  \n",
      "DEBILT              0           0       0         0     0  \n",
      "DUSSELDORF          0           0       1         0     0  \n",
      "HEATHROW            0           0       1         0     0  \n",
      "KASSEL              2           1       0         0     0  \n",
      "LJUBLJANA          34           0       2         0     0  \n",
      "MAASTRICHT          0           1       0         0     0  \n",
      "MADRID             11           0     361         0     0  \n",
      "MUNCHENB            0           0       1         1     0  \n",
      "OSLO                0           0       0         0     3  \n",
      "STOCKHOLM           0           0       0         0     1  \n",
      "VALENTIA            0           0       0         0     0  \n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred, stations))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
